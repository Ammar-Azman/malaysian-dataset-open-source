{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('mesolitica/finetune-translation-t5-small-standard-bahasa-cased')\n",
    "model = T5ForConditionalGeneration.from_pretrained('mesolitica/finetune-translation-t5-small-standard-bahasa-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zhang and Parker proposed a new Bio-Inspired predictive orientation decomposition representation, which was inspired by the biological research in human anatomy.',\n",
       " 'Zhang and Parker implemented a Bio-Inspired predictive orientation decomposition using Mid-Level features to construct representations of people from 3D skeleton Trajectories, which is inspired by biological research in human anatomy.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('true-case-parasci-arxiv-test.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zhang and Parker proposed a new Bio-Inspired predictive orientation decomposition representation, which was inspired by the biological research in human anatomy.',\n",
       " 'Zhang and Parker implemented a Bio-Inspired predictive orientation decomposition using Mid-Level features to construct representations of people from 3D skeleton Trajectories, which is inspired by biological research in human anatomy.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [b for b in data[0] if len(b.split()) <= 256]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zhang dan Parker mencadangkan perwakilan penguraian orientasi ramalan yang baru, yang diilhamkan oleh penyelidikan biologi dalam anatomi manusia.',\n",
       " 'Zhang dan Parker melaksanakan penguraian orientasi ramalan Bio-Inspirasi menggunakan ciri-ciri Mid-Level untuk membina perwakilan orang dari Trajectories rangka 3D, yang diilhamkan oleh penyelidikan biologi dalam anatomi manusia.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ['terjemah Inggeris ke Melayu: ' + b for b in batch]\n",
    "inputs = tokenizer(t, return_tensors=\"pt\", padding = True)\n",
    "for k in inputs.keys():\n",
    "    inputs[k] = inputs[k].cuda()\n",
    "\n",
    "translated_tokens = model.generate(**inputs, max_length=500)\n",
    "decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2549/2549 [03:27<00:00, 12.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "translated_train_examples = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    batch = [b for b in data[i] if len(b.split()) <= 256]\n",
    "    t = ['terjemah Inggeris ke Melayu: ' + b for b in batch]\n",
    "    inputs = tokenizer(t, return_tensors=\"pt\", padding = True)\n",
    "    for k in inputs.keys():\n",
    "        inputs[k] = inputs[k].cuda()\n",
    "\n",
    "    translated_tokens = model.generate(**inputs, max_length=500)\n",
    "    decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    translated_train_examples.append(\n",
    "        {\n",
    "            'en': data[i],\n",
    "            'ms': decoded,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': ['Zhang and Parker proposed a new Bio-Inspired predictive orientation decomposition representation, which was inspired by the biological research in human anatomy.',\n",
       "  'Zhang and Parker implemented a Bio-Inspired predictive orientation decomposition using Mid-Level features to construct representations of people from 3D skeleton Trajectories, which is inspired by biological research in human anatomy.'],\n",
       " 'ms': ['Zhang dan Parker mencadangkan perwakilan penguraian orientasi ramalan yang baru, yang diilhamkan oleh penyelidikan biologi dalam anatomi manusia.',\n",
       "  'Zhang dan Parker melaksanakan penguraian orientasi ramalan Bio-Inspirasi menggunakan ciri-ciri Mid-Level untuk membina perwakilan orang dari Trajectories rangka 3D, yang diilhamkan oleh penyelidikan biologi dalam anatomi manusia.']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_train_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('parasci-arxiv-test.json', 'w') as fopen:\n",
    "    json.dump(translated_train_examples, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Despite the higher layers in deep neural network can involve the spatial context information around the objects due to the large receptive field, Zhou et al have shown that the practical receptive field is actually much smaller than the theoretical one.',\n",
       " 'Although the wider receptive filed allows us to gather more context, Zhou et al showed that the actual size of the receptive fields in a CNN is much smaller than the theoretical size, especially in higher level layers.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('true-case-parasci-arxiv-val.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3680/3680 [04:51<00:00, 12.62it/s]\n"
     ]
    }
   ],
   "source": [
    "translated_train_examples = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    batch = [b for b in data[i] if len(b.split()) <= 256]\n",
    "    t = ['terjemah Inggeris ke Melayu: ' + b for b in batch]\n",
    "    inputs = tokenizer(t, return_tensors=\"pt\", padding = True)\n",
    "    for k in inputs.keys():\n",
    "        inputs[k] = inputs[k].cuda()\n",
    "\n",
    "    translated_tokens = model.generate(**inputs, max_length=500)\n",
    "    decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    translated_train_examples.append(\n",
    "        {\n",
    "            'en': data[i],\n",
    "            'ms': decoded,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parasci-arxiv-val.json', 'w') as fopen:\n",
    "    json.dump(translated_train_examples, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We find the optimal alignment of the original manifold and the Oose manifold via Procrustes analysis and apply the resulting Translational, Rotational, and Scaling components on the Oose manifold.',\n",
       " 'We find the optimal alignment of the clean and noisy Embeddings via Procrustes analysis and apply the resulting Translational, Rotational, and Scaling components on the Oose points.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('true-case-parasci-arxiv-train.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████         | 220862/309834 [5:01:48<1:46:23, 13.94it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translated_train_examples = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    batch = [b for b in data[i] if len(b.split()) <= 256]\n",
    "    t = ['terjemah Inggeris ke Melayu: ' + b for b in batch]\n",
    "    inputs = tokenizer(t, return_tensors=\"pt\", padding = True)\n",
    "    for k in inputs.keys():\n",
    "        inputs[k] = inputs[k].cuda()\n",
    "\n",
    "    translated_tokens = model.generate(**inputs, max_length=500)\n",
    "    decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    translated_train_examples.append(\n",
    "        {\n",
    "            'en': data[i],\n",
    "            'ms': decoded,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parasci-arxiv-train.json', 'w') as fopen:\n",
    "    json.dump(translated_train_examples, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
