{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm multinli_1.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multinli_1.0/multinli_1.0_dev_matched.jsonl',\n",
       " 'multinli_1.0/multinli_1.0_dev_mismatched.jsonl',\n",
       " 'multinli_1.0/multinli_1.0_train.jsonl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = sorted(glob('multinli_1.0/*.jsonl'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open(files[-1]) as fopen:\n",
    "    for l in fopen:\n",
    "        data.append(json.loads(l))\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotator_labels': ['neutral'],\n",
       " 'genre': 'government',\n",
       " 'gold_label': 'neutral',\n",
       " 'pairID': '31193n',\n",
       " 'promptID': '31193',\n",
       " 'sentence1': 'Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       " 'sentence1_binary_parse': '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )',\n",
       " 'sentence1_parse': '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))',\n",
       " 'sentence2': 'Product and geography are what make cream skimming work. ',\n",
       " 'sentence2_binary_parse': '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )',\n",
       " 'sentence2_parse': '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('mesolitica/finetune-translation-t5-small-standard-bahasa-cased')\n",
    "model = T5ForConditionalGeneration.from_pretrained('mesolitica/finetune-translation-t5-small-standard-bahasa-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.3 ms, sys: 1.28 ms, total: 95.6 ms\n",
      "Wall time: 94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch = [data[0]['sentence1'], data[0]['sentence2']]\n",
    "t = ['terjemah Inggeris ke Melayu: ' + b for b in batch]\n",
    "inputs = tokenizer(t, return_tensors=\"pt\", padding = True)\n",
    "for k in inputs.keys():\n",
    "    inputs[k] = inputs[k].cuda()\n",
    "translated_tokens = model.generate(**inputs, max_length=500)\n",
    "decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                             | 54567/392702 [2:20:20<42:11:06,  2.23it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 392702/392702 [16:33:54<00:00,  6.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open('translated-mnli-train.jsonl', 'w') as fopenl:\n",
    "    for d in tqdm(data):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch = [d['sentence1'], d['sentence2']]\n",
    "        t = ['terjemah Inggeris ke Melayu: ' + b for b in batch]\n",
    "        inputs = tokenizer(t, return_tensors=\"pt\", padding = True)\n",
    "        for k in inputs.keys():\n",
    "            inputs[k] = inputs[k].cuda()\n",
    "        translated_tokens = model.generate(**inputs, max_length=500)\n",
    "        decoded = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        d['translate'] = decoded\n",
    "        fopenl.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
