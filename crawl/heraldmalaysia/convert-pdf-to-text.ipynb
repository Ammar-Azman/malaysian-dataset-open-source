{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TIKA_LOG_PATH'] = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=d0ee39c66d7a7333091982c088267692d0011daf1dc4b96738239bccfa8a5520\n",
      "  Stored in directory: /Users/cobra/Library/Caches/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.2 bs4-0.0.1 soupsieve-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tika import parser\n",
    "from bs4.element import Comment\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "TIKA_HOST = 'http://localhost:9998'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfs = glob('*/*.pdf')\n",
    "len(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body, is_html=True):\n",
    "    if is_html:\n",
    "        soup = BeautifulSoup(body, 'html.parser')\n",
    "    else:\n",
    "        soup = body\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    return '\\n'.join(t.strip() for t in visible_texts).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tika(filename):\n",
    "    raw_xml = parser.from_file(filename, TIKA_HOST, xmlContent=True)\n",
    "    body = BeautifulSoup(raw_xml['content']).find('body')\n",
    "    t = []\n",
    "    for b in body:\n",
    "        try:\n",
    "            t_ = text_from_html(b, is_html=False)\n",
    "            t.append(t_)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf json\n",
    "!mkdir json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def loop(pdfs):\n",
    "    pdfs, _ = pdfs\n",
    "    for f in tqdm(pdfs):\n",
    "        filename = os.path.join('json', f.replace('/', '-') + '.json')\n",
    "        if os.path.exists(filename):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            b = parse_tika(f)\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(b, fopen)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:00<?, ?it/s]/var/folders/1n/9gz34qrs54l8n_v747_v5trw0000gn/T/ipykernel_93141/2886899813.py:14: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  texts = soup.findAll(text=True)\n",
      "100%|██████████| 407/407 [00:54<00:00,  7.44it/s]\n"
     ]
    }
   ],
   "source": [
    "loop((pdfs,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39M\tjson\n"
     ]
    }
   ],
   "source": [
    "!du -hs json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a6dff08b59a19f3a7991d6b1a25ce78202074b92e7b5fecc75ddcfc737a043e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
