{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65389"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('url/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 65389/65389 [00:00<00:00, 106988.07it/s]\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "for f in tqdm(files):\n",
    "    with open(f) as fopen:\n",
    "        urls.extend(json.load(fopen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url, filename):\n",
    "    if os.path.exists(filename):\n",
    "        return True\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    try:\n",
    "        title = soup.find('h2', {'class': 'main-title'}).text\n",
    "    except:\n",
    "        title = None\n",
    "    try:\n",
    "        p = [p_.text for p_ in (soup.find('article').find_all('p'))]\n",
    "    except:\n",
    "        p = None\n",
    "    \n",
    "    data = {\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'p': p,\n",
    "    }\n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(data, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘page’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf page\n",
    "!mkdir page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281766"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = sorted(list(set(urls)))\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████          | 20171/28177 [1:53:56<55:35,  2.40it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████████████████████████████▊| 28064/28177 [2:57:50<00:46,  2.43it/s]"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "max_worker = 10\n",
    "\n",
    "for i in tqdm(range(0, len(urls), max_worker)):\n",
    "    aranged = np.arange(i, i + max_worker)\n",
    "    urls_ = [(urls[a], os.path.join('page', f'{a}.json')) for a in aranged]\n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(crawl, url[0], url[1]): url for url in urls_}\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl(urls[10000], 'page/1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(urls[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTERI kehilangan seorang warga emas berusia 87 tahun sejak dua hari lepas terungkai selepas orang awam menemui mayatnya terapung dalam longkang sawah di Parit 8, Chikus, di Teluk Intan petang semalam.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('article').find_all('p')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mayat warga emas ditemui dalam longkang sawah',\n",
       " ['MISTERI kehilangan seorang warga emas berusia 87 tahun sejak dua hari lepas terungkai selepas orang awam menemui mayatnya terapung dalam longkang sawah di Parit 8, Chikus, di Teluk Intan petang semalam.',\n",
       "  'Ketua Polis Daerah Hilir Perak, ACP Mohd Marzukhi Mohd Mokhtar berkata Hamidah Hussin dari Kampung Sungai Tukang Sidin, Langkap, pada mulanya dilaporkan hilang selepas keluar dari rumahnya di Parit 8 sekitar pukul 7.00 malam Sabtu lalu.'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find('h2', {'class': 'main-title'}).text\n",
    "p = [p_.text for p_ in (soup.find('article').find_all('p'))]\n",
    "title, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
