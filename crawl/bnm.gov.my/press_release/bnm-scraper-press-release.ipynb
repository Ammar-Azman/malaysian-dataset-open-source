{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from random import randint\n",
    "import time #delay\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm\n",
    " \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Links for BNM Press Release (English & Malay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get English Content URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of pages where links of available press release\n",
    "\n",
    "date=[]\n",
    "title=[]\n",
    "link=[]\n",
    "\n",
    "for year in list(range(2015,2025)):\n",
    "    url='https://www.bnm.gov.my/press-release-'+str(year)\n",
    "    print(url)\n",
    "    driver.get(url)\n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    press_release_list=soup.find('table',attrs={'class':'Press-table table'}).find_all('tr')[1:]\n",
    "\n",
    "    for press_release in press_release_list:\n",
    "        date.append(press_release.find_all('p')[0].text)\n",
    "        title.append(press_release.find_all('p')[1].text)\n",
    "        link.append(press_release.find_all('p')[1])\n",
    "        \n",
    "    time.sleep(random.randint(5,10))      \n",
    "\n",
    "df=pd.DataFrame({'date':date , 'title':title , 'link':link})\n",
    "df['link']=df['link'].astype(str).str.extract('(\"https.+\")')\n",
    "df['link']=df['link'].apply(lambda x: x.replace('\"',''))\n",
    "\n",
    "df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('link1en.csv',index=False)\n",
    "# df.to_csv('link2en.csv',index=False)\n",
    "# df.to_csv('link3en.csv',index=False) # final retries 2015-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get PDF (English) Links within Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]\n",
    "pdf_links=[]\n",
    "\n",
    "df=pd.read_csv('link1en.csv')\n",
    "\n",
    "for url in df['link'].to_list():\n",
    "    print(url)\n",
    "    link.append(url)\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(url)\n",
    "    time.sleep(random.randint(5,10))\n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    # Find all 'a' tags (which define hyperlinks)   \n",
    "    a_tags = soup.find_all('a')\n",
    "    \n",
    "    file=[]\n",
    "    for tag in a_tags:\n",
    "        try:\n",
    "            check_pdf=re.search('documents.+\\.pdf', tag['href'])[0]\n",
    "            check_pdf=check_pdf.replace('%2F','/') \n",
    "            #check_pdf in tag['href']\n",
    "            file.append(check_pdf)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    file=list(set(file))\n",
    "    \n",
    "    # Filter the 'a' tags to get only those that link to a .pdf file\n",
    "    pdf_links.append(file)\n",
    "    \n",
    "    df=pd.DataFrame({'link':link, 'pdf_links':pdf_links})\n",
    "    df.to_csv('link-pdf-en.csv',index=False) # ref file 2\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Malay Content URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "title=[]\n",
    "link=[]\n",
    "\n",
    "\n",
    "for year in list(range(2000,2025)):\n",
    "    url='https://www.bnm.gov.my/press-release-'+str(year)\n",
    "    #print(url)\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(random.randint(5,10))\n",
    "    \n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    link_bm = soup.find('a',attrs={'lang':'ms-MY'})\n",
    "    link_bm = \"https://www.bnm.gov.my\"+(re.search('/.+languageId=ms_MY',str(link_bm)).group(0).replace('&amp;','&'))\n",
    "    \n",
    "    driver.get(link_bm)\n",
    "    \n",
    "    time.sleep(random.randint(5,10))\n",
    "    \n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    press_release_list=soup.find('table',attrs={'class':'Press-table table'}).find_all('tr')[1:]\n",
    "\n",
    "    for press_release in press_release_list:\n",
    "        date.append(press_release.find_all('p')[0].text)\n",
    "        title.append(press_release.find_all('p')[1].text)\n",
    "        link.append(press_release.find_all('p')[1])\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    \n",
    "df=pd.DataFrame({'date':date , 'title':title , 'link':link})\n",
    "df['link']=df['link'].astype(str).str.extract('(\"https.+\")')\n",
    "df['link']=df['link'].apply(lambda x: x.replace('\"',''))\n",
    "df['link']=df['link'].str.replace(r'(->.+)','-',regex=True)\n",
    "df.to_csv('link1ms.csv',index=False)\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get PDF (Malay) Links within Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]\n",
    "pdf_links=[]\n",
    "\n",
    "df=pd.read_csv('link1ms.csv')\n",
    "\n",
    "#link=pd.read_csv('link-pdf-ms.csv')['link'].to_list()\n",
    "#pdf_links=pd.read_csv('link-pdf-ms.csv')['pdf_links'].to_list()\n",
    "\n",
    "#for url in df['link'].to_list():\n",
    "\n",
    "for url in tqdm([x for x in df['link'].to_list() if x not in link]):\n",
    "    try:\n",
    "        #print(url)\n",
    "        link.append(url)\n",
    "        driver = webdriver.Edge()\n",
    "        driver.get(url)\n",
    "        time.sleep(random.randint(5,10))\n",
    "        soup=BeautifulSoup(driver.page_source)\n",
    "        \n",
    "        \n",
    "        link_bm = soup.find('a',attrs={'lang':'ms-MY'})\n",
    "        link_bm = \"https://www.bnm.gov.my\"+(re.search('/.+languageId=ms_MY',str(link_bm)).group(0).replace('&amp;','&'))\n",
    "        print(link_bm)\n",
    "        link_bm = link_bm.replace('%2F','/')\n",
    "        \n",
    "        driver.get(link_bm)\n",
    "        time.sleep(random.randint(5,6))\n",
    "        \n",
    "        soup=BeautifulSoup(driver.page_source)\n",
    "        \n",
    "        # Find all 'a' tags (which define hyperlinks)   \n",
    "        a_tags = soup.find_all('a')\n",
    "        \n",
    "        file=[]\n",
    "        for tag in a_tags:\n",
    "            try:\n",
    "                check_pdf=re.search('documents.+\\.pdf', tag['href'])[0]\n",
    "                #print(check_pdf)\n",
    "                check_pdf=check_pdf.replace('%2F','/') \n",
    "                #check_pdf in tag['href']\n",
    "                file.append(check_pdf)\n",
    "                print(file)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        file=list(set(file))\n",
    "        \n",
    "        # Filter the 'a' tags to get only those that link to a .pdf file\n",
    "        pdf_links.append(file)\n",
    "        \n",
    "        df=pd.DataFrame({'link':link, 'pdf_links':pdf_links})\n",
    "        df.to_csv('link-pdf-ms.csv',index=False) # ref file 4\n",
    "        \n",
    "        driver.close()\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print('failed at ',url)\n",
    "        \n",
    "        file=[]\n",
    "        pdf_links.append(file)\n",
    "        \n",
    "        df=pd.DataFrame({'link':link, 'pdf_links':pdf_links})\n",
    "        df.to_csv('link-pdf-ms.csv',index=False) # ref file 4\n",
    "        \n",
    "        driver.close()\n",
    "        time.sleep(random.randint(5, 10))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pdf links ref. table (Malay + English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_links=pd.concat([pd.merge(pd.read_csv('link1ms.csv'),pd.read_csv('link-pdf-ms.csv'),how='left',on='link'),pd.merge(pd.read_csv('link1en.csv'),pd.read_csv('link-pdf-en.csv'),how='left',on='link')]).reset_index(drop=True)\n",
    "pdf_links=pdf_links[~(pdf_links['link'].str.contains('%'))]\n",
    "pdf_links=pdf_links.drop_duplicates('link').reset_index(drop=True)\n",
    "pdf_links['link']=np.where(pdf_links['link'].str.endswith('.'),pdf_links['link'].str[:-1],pdf_links['link'])\n",
    "pdf_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "title=[]\n",
    "link=[]\n",
    "links=[]\n",
    "\n",
    "for x in list(range(len(pdf_links))):\n",
    "    \n",
    "    date.append(pdf_links['date'][x])\n",
    "    title.append(pdf_links['title'][x])\n",
    "    link.append(pdf_links['link'][x])\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        pdf=\"\"\n",
    "\n",
    "        for row_link in re.search(r\"'documents.+\\.pdf'\",pdf_links['pdf_links'][x])[0].replace(\"'\",\"\").split(\",\"):\n",
    "            pdf=pdf+'https://www.bnm.gov.my/'+row_link.strip()+\", \"\n",
    "\n",
    "        pdf=pdf[:-2]\n",
    "        \n",
    "        links.append(pdf)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        pdf=\"\"\n",
    "        links.append(pdf)\n",
    "    \n",
    "df=pd.DataFrame({'date':date, 'title':title, 'link':link, 'pdf_links':links})\n",
    "\n",
    "pdf_links=pd.merge(pdf_links.drop(columns=['pdf_links']), df, on=['date','title','link'], how='left')\n",
    "pdf_links=pdf_links.drop_duplicates().reset_index(drop=True)\n",
    "pdf_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Content Based on Links (English & Malay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all links (english) csv files\n",
    "\n",
    "files=os.listdir()\n",
    "files=list(filter(lambda k: 'en.csv' in k, files))\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df=pd.concat([df,(pd.read_csv(file))])\n",
    "\n",
    "content=[]\n",
    "link=[]\n",
    "\n",
    "for url in tqdm([x for x in df['link'].to_list() if x not in link]):\n",
    "    try:\n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        \n",
    "        time.sleep(random.randint(5,10))\n",
    "        \n",
    "        data=driver.page_source\n",
    "        soup=BeautifulSoup(data)\n",
    "        \n",
    "        content.append(soup.find('div',attrs={'class':'journal-content-article'}).text)\n",
    "        link.append(url)\n",
    "        \n",
    "        dfContent=pd.DataFrame({'link':link , 'content':content})\n",
    "        dfContent.to_csv('content1.csv', index=False)\n",
    "    except:\n",
    "        print('failed at ',url)\n",
    "        time.sleep(random.randint(10, 20))\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_release_english=pd.merge(df,dfContent,left_on='link',right_on='link')\n",
    "press_release_english.to_csv('press_release_english.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('link1ms.csv')\n",
    "\n",
    "#link=pd.read_csv('content2.csv')['link'].to_list()\n",
    "#link_opt=pd.read_csv('content2.csv')['link_opt'].to_list()\n",
    "#content=pd.read_csv('content2.csv')['content'].to_list()\n",
    "\n",
    "#link=link\n",
    "#link_opt=link_opt\n",
    "#content=content\n",
    "\n",
    "content=[]\n",
    "link=[]\n",
    "link_opt=[]\n",
    "\n",
    "\n",
    "for url in tqdm([x for x in df['link'].to_list() if x not in link]):\n",
    "    try:\n",
    "        print(url)\n",
    "        driver = webdriver.Edge()\n",
    "        driver.get(url)\n",
    "        \n",
    "        time.sleep(random.randint(5,6))\n",
    "        \n",
    "        data=driver.page_source\n",
    "        soup=BeautifulSoup(data)\n",
    "        \n",
    "        \n",
    "        link_bm = soup.find('a',attrs={'lang':'ms-MY'})\n",
    "        link_bm = \"https://www.bnm.gov.my\"+(re.search('/.+languageId=ms_MY',str(link_bm)).group(0).replace('&amp;','&'))\n",
    "        \n",
    "        driver.get(link_bm)\n",
    "        \n",
    "        time.sleep(random.randint(5,6))\n",
    "        \n",
    "        soup=BeautifulSoup(driver.page_source)\n",
    "        \n",
    "        content.append(soup.find('div',attrs={'class':'journal-content-article'}).text)\n",
    "        link.append(url)\n",
    "        link_opt.append(link_bm)\n",
    "        \n",
    "        driver.close()\n",
    "        \n",
    "        df=pd.DataFrame({'link':link , 'link_opt':link_opt , 'content':content})\n",
    "        df.to_csv('content2.csv',index=False)\n",
    "\n",
    "    except:\n",
    "        print('failed at ',url)\n",
    "        time.sleep(random.randint(10,20))\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.merge(pd.read_csv('link1en.csv'),pd.read_csv('content1.csv'),how='left',on='link')).to_csv('press_release_english.csv',index=False)\n",
    "(pd.merge(pd.read_csv('link1ms.csv'),pd.read_csv('content2.csv'),how='left',on='link')).to_csv('press_release_malay.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine English & Malay Content + Add in Category Column as \"Press Release\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm_data=pd.concat([pd.read_csv('press_release_english.csv'),pd.read_csv('press_release_malay.csv')])\n",
    "bnm_data['category']='Press Release'\n",
    "bnm_data=bnm_data.reset_index(drop=True)\n",
    "bnm_data['link']=bnm_data['link'].str.strip()\n",
    "bnm_data=bnm_data[~(bnm_data['link'].str.contains('%'))]\n",
    "bnm_data=bnm_data.drop_duplicates('link')\n",
    "bnm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm_data['content']=bnm_data['content'].str.replace('\\r\\n\\r\\n\\r\\n\\r\\n','')\n",
    "bnm_data['content']=bnm_data['content'].str.replace('\\r\\n\\r\\n\\r\\n','\\r\\n')\n",
    "bnm_data['content']=bnm_data['content'].str.replace('\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n','')\n",
    "bnm_data['content']=bnm_data['content'].str.replace('Shares\\r\\n','')\n",
    "bnm_data['content']=bnm_data['content'].str.replace('  Share:','Share:')\n",
    "bnm_data['content']=bnm_data['content'].str.replace('      ','')\n",
    "bnm_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm_data=pd.merge(pdf_links,bnm_data,how='left',left_on=['date','title','link'],right_on=['date','title','link']).drop_duplicates()\n",
    "bnm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.options import Options\n",
    "import pyautogui\n",
    "import pyperclip\n",
    "\n",
    "\n",
    "link = []\n",
    "pdf_links = []\n",
    "\n",
    "# Filter the DataFrame once and reset the index\n",
    "\n",
    "'''\n",
    "filtered_data = bnm_data[bnm_data['pdf_links'] != ''].reset_index(drop=True)\n",
    "downloaded=pd.DataFrame({'link':link,'pdf_links':pdf_links})[['link']].drop_duplicates()\n",
    "downloaded['tag']='yes'\n",
    "filtered_data=pd.merge(filtered_data,downloaded,how='left',on='link')\n",
    "filtered_data=filtered_data[filtered_data['tag'].isnull()]\n",
    "filtered_data=filtered_data.drop(columns=['tag'])\n",
    "filtered_data=filtered_data.reset_index(drop=True)\n",
    "'''\n",
    "\n",
    "filtered_data = bnm_data[bnm_data['pdf_links'] != ''].reset_index(drop=True)\n",
    "filtered_data = filtered_data[['link','pdf_links']]\n",
    "filtered_data['pdf_links']=(filtered_data['pdf_links'].str.split(', ',expand=False))\n",
    "filtered_data = filtered_data.explode('pdf_links')\n",
    "filtered_data['filename']=filtered_data['pdf_links'].str.split('/').str[-1]\n",
    "os.chdir('/Users/izard/Documents/GitHub/bimb-osint-development/back-end/bnm/press_release/pdf/')\n",
    "filtered_data=pd.merge(filtered_data,pd.DataFrame({'filename':os.listdir(),'downloaded':'yes'}),how='left',on='filename')\n",
    "filtered_data=filtered_data[filtered_data['downloaded'].isnull()].drop(columns=['downloaded'])\n",
    "filtered_data=filtered_data.reset_index(drop=True)\n",
    "\n",
    "# Setup Edge options\n",
    "edge_options = Options()\n",
    "\n",
    "# Initialize the driver once\n",
    "driver = webdriver.Edge(options=edge_options)\n",
    "\n",
    "for row in tqdm(range(len(filtered_data))):\n",
    "    current_link = filtered_data['link'][row]\n",
    "    pdf_list = filtered_data['pdf_links'][row].split(', ')\n",
    "    \n",
    "    for pdf in pdf_list:\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            link.append(current_link)\n",
    "            pdf_links.append(pdf)\n",
    "            driver.get(pdf)\n",
    "            \n",
    "            time.sleep(30)  # Wait for the page to load\n",
    "            pyautogui.hotkey('ctrl', 's')  # Simulate Ctrl + S (save)\n",
    "            time.sleep(10)  # Wait for the save dialog to appear\n",
    "            path_and_filename = 'c:\\\\Users\\\\izard\\\\Documents\\\\GitHub\\\\bimb-osint-development\\\\back-end\\\\bnm\\\\press_release\\\\pdf\\\\'+pdf.split('/')[-1]\n",
    "            pyperclip.copy(path_and_filename)\n",
    "            pyautogui.hotkey('ctrl', 'v')\n",
    "            pyautogui.press('enter')  # Press Enter to save the file\n",
    "            pyautogui.press('enter')  # Press Enter to save the file\n",
    "            \n",
    "            time.sleep(random.randint(10,20))\n",
    "            \n",
    "            print('success')\n",
    "        \n",
    "        except:\n",
    "            print('unsuccess')\n",
    "            pass\n",
    "\n",
    "# Close the driver after processing all rows\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = bnm_data[bnm_data['pdf_links'] != ''].reset_index(drop=True)\n",
    "pdf_files = pdf_files[['link','pdf_links']]\n",
    "pdf_files['pdf_links']=(pdf_files['pdf_links'].str.split(', ',expand=False))\n",
    "pdf_files = pdf_files.explode('pdf_links')\n",
    "pdf_files['filename']=pdf_files['pdf_links'].str.split('/').str[-1]\n",
    "os.chdir('/Users/izard/Documents/GitHub/bimb-osint-development/back-end/bnm/press_release/pdf/')\n",
    "pdf_files=pd.merge(pdf_files,pd.DataFrame({'filename':os.listdir(),'downloaded':'yes'}),how='left',on='filename')\n",
    "pdf_files=pdf_files[pdf_files['downloaded'].notnull()].drop(columns=['downloaded'])\n",
    "pdf_files=pdf_files.reset_index(drop=True)\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tika server , check at http://localhost:9998/\n",
    "\n",
    "os.chdir('/Users/izard/') # change directory to where tika-server-standard-2.6.0.jar is located\n",
    "\n",
    "! java -jar tika-server-standard-2.6.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/izard/Documents/GitHub/bimb-osint-development/back-end/bnm/press_release/pdf/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika\n",
    "from tika import parser\n",
    "from tqdm import tqdm\n",
    "\n",
    "downloaded_files=os.listdir() # get list of downloaded files\n",
    "\n",
    "tika.initVM()\n",
    "print('start..')\n",
    "\n",
    "filename=[]\n",
    "Document_Text=[]\n",
    "\n",
    "for file in tqdm(downloaded_files):\n",
    "\n",
    "    try:\n",
    "        print('parsing...',file)\n",
    "        \n",
    "        text=parser.from_file(file)['content']\n",
    "        \n",
    "        filename.append(file)\n",
    "        Document_Text.append(text)\n",
    "                \n",
    "    except:\n",
    "        print('unsuccess...',file)\n",
    "        filename.append(file)\n",
    "        Document_Text.append('')\n",
    "        pass\n",
    "    \n",
    "pdf_to_text=pd.DataFrame({'filename':filename, 'Document_Text':Document_Text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update pdf_files with text extracted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files=pd.merge(pdf_files,pdf_to_text,how='left',on='filename')\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Only to PDF to Text Valid Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files['Document_Text']=np.where((pdf_files['Document_Text']=='')|(pdf_files['Document_Text'].isnull()),'N/A',pdf_files['Document_Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat PDF to Text Extracted with Same Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files=pdf_files[['link','Document_Text']].groupby(['link']).agg({'Document_Text':'sum'}).reset_index()\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Main Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm_data=pd.merge(bnm_data,pdf_files,how='left',on='link')[['date', 'title', 'link', 'pdf_links', 'link_opt', 'content', 'Document_Text', 'category']]\n",
    "os.chdir('/Users/izard/Documents/GitHub/bimb-osint-development/back-end/bnm/press_release/')\n",
    "bnm_data.to_csv('bnm_data_press_release.csv',index=False)\n",
    "bnm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the timestamp\n",
    "os.chdir('/Users/izard/Documents/GitHub/bimb-osint-development/back-end/bnm/press_release/')\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "bnm_data=pd.read_csv('bnm_data_press_release.csv')\n",
    "bnm_data['date']=np.where(bnm_data['date'].str.contains('Dis'),bnm_data['date'].str.replace('Dis','Dec'),bnm_data['date'])\n",
    "bnm_data['date']=np.where(bnm_data['date'].str.contains('Okt'),bnm_data['date'].str.replace('Okt','Oct'),bnm_data['date'])\n",
    "bnm_data['date']=np.where(bnm_data['date'].str.contains('Ogos'),bnm_data['date'].str.replace('Ogos','Aug'),bnm_data['date'])\n",
    "bnm_data['date']=np.where(bnm_data['date'].str.contains('Mei'),bnm_data['date'].str.replace('Mei','May'),bnm_data['date'])\n",
    "bnm_data['date']=np.where(bnm_data['date'].str.contains('Mac'),bnm_data['date'].str.replace('Mac','Mar'),bnm_data['date'])\n",
    "bnm_data['date']=np.where(bnm_data['date'].str.contains('Mac'),bnm_data['date'].str.replace('Mac','Mar'),bnm_data['date'])\n",
    "bnm_data['date']=pd.to_datetime(bnm_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_created</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>pdf_URL</th>\n",
       "      <th>URL_opt</th>\n",
       "      <th>Content</th>\n",
       "      <th>Document_Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Penggabungan dan Pengukuhan Institusi Perbanka...</td>\n",
       "      <td>https://www.bnm.gov.my/-/penggabungan-dan-peng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.bnm.gov.my/c/portal/update_languag...</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nPenggabungan dan Pengukuha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-12-30</td>\n",
       "      <td>Makluman Terperinci bagi Rizab Antarabangsa pa...</td>\n",
       "      <td>https://www.bnm.gov.my/-/makluman-terperinci-b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.bnm.gov.my/c/portal/update_languag...</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nMakluman Terperinci bagi R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-12-26</td>\n",
       "      <td>Expansion and Enlargement of the ASEAN Swap Ar...</td>\n",
       "      <td>https://www.bnm.gov.my/-/expansion-and-enlarge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-12-22</td>\n",
       "      <td>Rizab Antarabangsa BNM pada 15 Dis 2000</td>\n",
       "      <td>https://www.bnm.gov.my/-/rizab-antarabangsa-bn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.bnm.gov.my/c/portal/update_languag...</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nRizab Antarabangsa BNM pad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-12-08</td>\n",
       "      <td>Rizab Antarabangsa BNM pada 30 Nov 2000</td>\n",
       "      <td>https://www.bnm.gov.my/-/rizab-antarabangsa-bn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.bnm.gov.my/c/portal/update_languag...</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nRizab Antarabangsa BNM pad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>Memorandum of Understanding between Bank Negar...</td>\n",
       "      <td>https://www.bnm.gov.my/-/mou-csm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nMemorandum of Understandin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>Monetary Policy Statement</td>\n",
       "      <td>https://www.bnm.gov.my/-/monetary-policy-state...</td>\n",
       "      <td>https://www.bnm.gov.my/documents/20124/1323546...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nMonetary Policy Statement\\...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>International Reserves of Bank Negara Malaysia...</td>\n",
       "      <td>https://www.bnm.gov.my/-/international-reserve...</td>\n",
       "      <td>https://www.bnm.gov.my/documents/20124/6118085...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nInternational Reserves of ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>Statement on Claims Relating to Quantum Metal ...</td>\n",
       "      <td>https://www.bnm.gov.my/-/pr-qmsb</td>\n",
       "      <td>https://www.bnm.gov.my/documents/20124/60360/F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nStatement on Claims Relati...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>International Reserves of Bank Negara Malaysia...</td>\n",
       "      <td>https://www.bnm.gov.my/-/international-reserve...</td>\n",
       "      <td>https://www.bnm.gov.my/documents/20124/6118085...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r\\n\\r\\nReading:\\r\\nInternational Reserves of ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>Press Release</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4676 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_created                                              Title  \\\n",
       "0      2000-12-31  Penggabungan dan Pengukuhan Institusi Perbanka...   \n",
       "1      2000-12-30  Makluman Terperinci bagi Rizab Antarabangsa pa...   \n",
       "2      2000-12-26  Expansion and Enlargement of the ASEAN Swap Ar...   \n",
       "3      2000-12-22            Rizab Antarabangsa BNM pada 15 Dis 2000   \n",
       "4      2000-12-08            Rizab Antarabangsa BNM pada 30 Nov 2000   \n",
       "...           ...                                                ...   \n",
       "4671   2024-01-26  Memorandum of Understanding between Bank Negar...   \n",
       "4672   2024-01-24                          Monetary Policy Statement   \n",
       "4673   2024-01-22  International Reserves of Bank Negara Malaysia...   \n",
       "4674   2024-01-22  Statement on Claims Relating to Quantum Metal ...   \n",
       "4675   2024-01-08  International Reserves of Bank Negara Malaysia...   \n",
       "\n",
       "                                                    URL  \\\n",
       "0     https://www.bnm.gov.my/-/penggabungan-dan-peng...   \n",
       "1     https://www.bnm.gov.my/-/makluman-terperinci-b...   \n",
       "2     https://www.bnm.gov.my/-/expansion-and-enlarge...   \n",
       "3     https://www.bnm.gov.my/-/rizab-antarabangsa-bn...   \n",
       "4     https://www.bnm.gov.my/-/rizab-antarabangsa-bn...   \n",
       "...                                                 ...   \n",
       "4671                   https://www.bnm.gov.my/-/mou-csm   \n",
       "4672  https://www.bnm.gov.my/-/monetary-policy-state...   \n",
       "4673  https://www.bnm.gov.my/-/international-reserve...   \n",
       "4674                   https://www.bnm.gov.my/-/pr-qmsb   \n",
       "4675  https://www.bnm.gov.my/-/international-reserve...   \n",
       "\n",
       "                                                pdf_URL  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4671                                                NaN   \n",
       "4672  https://www.bnm.gov.my/documents/20124/1323546...   \n",
       "4673  https://www.bnm.gov.my/documents/20124/6118085...   \n",
       "4674  https://www.bnm.gov.my/documents/20124/60360/F...   \n",
       "4675  https://www.bnm.gov.my/documents/20124/6118085...   \n",
       "\n",
       "                                                URL_opt  \\\n",
       "0     https://www.bnm.gov.my/c/portal/update_languag...   \n",
       "1     https://www.bnm.gov.my/c/portal/update_languag...   \n",
       "2                                                   NaN   \n",
       "3     https://www.bnm.gov.my/c/portal/update_languag...   \n",
       "4     https://www.bnm.gov.my/c/portal/update_languag...   \n",
       "...                                                 ...   \n",
       "4671                                                NaN   \n",
       "4672                                                NaN   \n",
       "4673                                                NaN   \n",
       "4674                                                NaN   \n",
       "4675                                                NaN   \n",
       "\n",
       "                                                Content  \\\n",
       "0     \\r\\n\\r\\nReading:\\r\\nPenggabungan dan Pengukuha...   \n",
       "1     \\r\\n\\r\\nReading:\\r\\nMakluman Terperinci bagi R...   \n",
       "2                                                   NaN   \n",
       "3     \\r\\n\\r\\nReading:\\r\\nRizab Antarabangsa BNM pad...   \n",
       "4     \\r\\n\\r\\nReading:\\r\\nRizab Antarabangsa BNM pad...   \n",
       "...                                                 ...   \n",
       "4671  \\r\\n\\r\\nReading:\\r\\nMemorandum of Understandin...   \n",
       "4672  \\r\\n\\r\\nReading:\\r\\nMonetary Policy Statement\\...   \n",
       "4673  \\r\\n\\r\\nReading:\\r\\nInternational Reserves of ...   \n",
       "4674  \\r\\n\\r\\nReading:\\r\\nStatement on Claims Relati...   \n",
       "4675  \\r\\n\\r\\nReading:\\r\\nInternational Reserves of ...   \n",
       "\n",
       "                                          Document_Text       Category  \n",
       "0                                                   NaN  Press Release  \n",
       "1                                                   NaN  Press Release  \n",
       "2                                                   NaN            NaN  \n",
       "3                                                   NaN  Press Release  \n",
       "4                                                   NaN  Press Release  \n",
       "...                                                 ...            ...  \n",
       "4671                                                NaN  Press Release  \n",
       "4672  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  Press Release  \n",
       "4673  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  Press Release  \n",
       "4674  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  Press Release  \n",
       "4675  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  Press Release  \n",
       "\n",
       "[4676 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnm_data=bnm_data.rename(columns={'date':'Date_created','title':'Title','link':'URL','pdf_links':'pdf_URL','link_opt':'URL_opt','content':'Content','category':'Category'})\n",
    "bnm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=bnm_data.to_json(orient = \"records\",date_format='iso')\n",
    "\n",
    "with open('bnm_data_press_release.json', 'w') as f:\n",
    "       f.write(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
