{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8fccf2-75c1-4f87-87ff-c0f45c6bf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "778717a2-10b2-4a1c-bb09-589caf9fe17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36',\n",
    "           'Referer':'https://www.motomalaysia.com/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b1bbbad-d1f5-46bb-a92e-cba5778c0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('motor_models.jsonl') as fopen:\n",
    "    models = [line.strip().strip('\"') for line in fopen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba48fd69-74aa-4a3f-8a80-313d5b43d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)\n",
    "from unidecode import unidecode\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc81fbde-f4b2-4ee8-b913-ab93b3a9a4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping from Unicode characters to strings\n",
    "unicode_to_string = {\n",
    "    '\\u2013': '-',\n",
    "    '\\u00a0': ' ',\n",
    "    '\\u2588': '',\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "input_char = '\\u2588'  # This would be your input character\n",
    "\n",
    "# Convert the Unicode character to the corresponding string\n",
    "output_string = unicode_to_string.get(input_char, input_char)\n",
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "154de50d-81a1-4c19-b885-621afe03bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(x):\n",
    "    try:\n",
    "        url = x\n",
    "        r = requests.get(url,headers = headers)\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    \n",
    "        name_list = []\n",
    "        value_list = []\n",
    "        combined_list = []\n",
    "        moto_data = []\n",
    "        overviews = [] \n",
    "        \n",
    "        attr = {}\n",
    "        model_name = soup.find('h1' ,{'class': 'entry-title'}).text\n",
    "        attr['model_name'] = model_name\n",
    "        \n",
    "        overview = soup.find('div' ,{'class': 'textdesc2'}).find_all('p')\n",
    "        \n",
    "        for i in overview:\n",
    "            overviews.append(i.text)\n",
    "        attr['overviews'] = overviews\n",
    "        \n",
    "        # cost = soup.find('table' ,{'id': 'isipost'}).find_all('td', {'class': 'lapistengah'})\n",
    "        # print(url + \" : \" + str(cost))\n",
    "        # costs = [f\"Price : {cost[0].text}\", f\"Monthly (5 Years) : {cost[1].text}\", f\"Monthly (7 Years) : {cost[2].text}\", f\"Monthly (9 Years) : {cost[3].text}\"]\n",
    "        # attr['costs'] = costs\n",
    "        prices_name = []\n",
    "        for i in soup.find('table' ,{'id': 'isipost'}).find_all('th'):\n",
    "            if i.get('id') == 'bghitam':\n",
    "                continue\n",
    "            else:\n",
    "                prices_name.append((i.text).replace('\\n', ' '))\n",
    "                \n",
    "        prices_value = []\n",
    "        for i in soup.find('table' ,{'id': 'isipost'}).find_all('td', {'class': 'lapistengah'}):\n",
    "            prices_value.append(i.text)\n",
    "    \n",
    "        combined_list_price = [] \n",
    "        for name, value in zip(prices_name, prices_value):\n",
    "                combined_list_price.append(f\"{name}: {value}\")\n",
    "     \n",
    "        try:\n",
    "            for i in soup.find('table', {'class': 'specscsstable varianmodel'}).find_all('td', {'class': 'lapissatu'}):\n",
    "                values = unidecode(i.text)\n",
    "                values = values.replace('### -', '')\n",
    "                # values = values.replace('\\n', '')\n",
    "                values = values.replace('#', '')\n",
    "                name_list.append(values)\n",
    "        except:\n",
    "            val = soup.find_all('table', {'id': 'isipost'})\n",
    "            for i in val[1].find_all('td', {'class': 'lapissatu'}):\n",
    "                values = unidecode(i.text)\n",
    "                values = values.replace('### -', '')\n",
    "                # values = values.replace('\\n', '')\n",
    "                values = values.replace('#', '')\n",
    "                name_list.append(values)\n",
    "        \n",
    "        try:\n",
    "            for i in soup.find('table', {'class': 'specscsstable varianmodel'}).find_all('td'):\n",
    "                if i.get('class') == None:\n",
    "                    values = unidecode(i.text)\n",
    "                    values = values.replace('### -', '')\n",
    "                    # values = values.replace('\\n', '')\n",
    "                    values = values.replace('#', '')\n",
    "                    value_list.append(values)\n",
    "        except:\n",
    "            val = soup.find_all('table', {'id': 'isipost'})\n",
    "            for i in val[1].find_all('td'):\n",
    "                if i.get('class') == None:\n",
    "                    values = unidecode(i.text)\n",
    "                    values = values.replace('### -', '')\n",
    "                    # values = values.replace('\\n', '')\n",
    "                    values = values.replace('#', '')\n",
    "                    value_list.append(values)\n",
    "        \n",
    "        for name, value in zip(name_list, value_list):\n",
    "            combined_list.append(f\"{name}: {value}\")\n",
    "        attr['specs'] = combined_list\n",
    "        \n",
    "        count=0\n",
    "        \n",
    "        for i in soup.find('table', {'id':'kotakgambar'}).find_all('img'):\n",
    "            img_dict = {}\n",
    "            url_image = i.get('src')\n",
    "            img_file = os.path.join('pic', f\"{attr['model_name']}_{count}.jpg\")\n",
    "            with open(img_file, 'wb') as fopen:\n",
    "                r = requests.get(url_image)\n",
    "                fopen.write(r.content)\n",
    "        \n",
    "            img_dict['img_url'] = url_image\n",
    "            img_dict['local_image'] = img_file\n",
    "            img_dict['specs'] = attr\n",
    "            moto_data.append(img_dict)\n",
    "            count += 1\n",
    "    \n",
    "        return moto_data\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(url)\n",
    "        print(e)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "098b9baa-883f-4f24-a7c0-4c2d4c1474e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 224/224 [00:24<00:00,  9.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_workers = 10\n",
    "urls = []\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(crawl, x) for x in models]\n",
    "    \n",
    "    for future in tqdm(futures, total=len(models)):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            for x in result:\n",
    "                with open('motomalaysia-data.jsonl', 'a') as f:\n",
    "                    json.dump(x, f)\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa60d3be-9a22-4762-95c9-fe2a89b5a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('motomalaysia-data.jsonl') as fopen:\n",
    "    datas = [line.strip().strip('\"') for line in fopen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4291b22-c5cf-46d0-a5b0-514bd84512e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e878d-2bf7-436a-bb02-23eb5b7ade71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c6f30-0047-4cd1-8281-478407314bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524f557-2d33-4e34-beab-b1230358a4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bbb1b-9e10-4715-b4ba-3746d95e1861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b433b-3a8b-4215-b746-3ba95ac18752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
