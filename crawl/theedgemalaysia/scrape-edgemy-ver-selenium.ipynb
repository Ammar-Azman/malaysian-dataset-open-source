{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Scraping **The Edge Malaysia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE:** This version has code used to get content (date the article was published) that's locked behind Javascript using Selenium. However, I decided to just go with requests and bs4 due to selenium being so slow! Nonetheless, I thought someone with better internet may benefit from this code.*\n",
    "\n",
    "For [The Edge Malaysia](https://theedgemalaysia.com/), each of their articles seem to have a unique ID, e.g., \"https://theedgemalaysia.com/node/677590\". Hence, since we won't be able to do this by month, page no., etc., we'll use a **brute force** approach that tests every combination of numbers, such that we'll only scrape from a valid url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Cache-Control\": \"max-age=0\",\n",
    "    }\n",
    "\n",
    "# for selenium\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "\n",
    "\"\"\"\n",
    "We open the website before loading the cookies into the driver\n",
    "to avoid the InvalidCookieDomainException.\n",
    "\"\"\"\n",
    "def save_cookie(driver, path):\n",
    "    with open(path, 'wb') as filehandler:\n",
    "        pickle.dump(driver.get_cookies(), filehandler)\n",
    "\n",
    "save_cookie(driver,'cookies.pkl')\n",
    "\n",
    "cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get text and metadata from url\n",
    "def process_url(x):\n",
    "    while True:\n",
    "        webpage = f'https://theedgemalaysia.com/node/{x}'\n",
    "        try:\n",
    "            r = requests.get(webpage, headers=headers)\n",
    "            driver.get(webpage)\n",
    "            for cookie in cookies:\n",
    "                    driver.add_cookie(cookie)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            time.sleep(5.0)\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    \n",
    "    # Wait for a specific element to be present, e.g., an element with class 'dynamic-content'\n",
    "    WebDriverWait(driver, 3) \\\n",
    "        .until(EC.presence_of_element_located((By.CLASS_NAME, \n",
    "                                               'news-detail_newsInfo__dv0be')))\n",
    "    page_source = driver.page_source\n",
    "    soup_sel = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        headline = soup.find('title').text\n",
    "        h = soup.find('div', class_=\"news-detail_newsTextDataWrap__PkAu5\") \n",
    "        content_list = [p.text for p in h.find_all(\"p\")]\n",
    "        content_str = ' '.join(content_list)\n",
    "        if 'English version' in content_str:\n",
    "            language = 'Mandarin'\n",
    "        else:\n",
    "            language = 'English'\n",
    "\n",
    "        div_date = soup_sel.find('div', class_=\"news-detail_newsInfo__dv0be\")\n",
    "        date_published = div_date.find('span').text\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    data = {'url': f'https://theedgemalaysia.com/node/{x}', \n",
    "            'headline': headline,\n",
    "            'date_published': date_published,\n",
    "            'language': language,\n",
    "            'content': content_str}\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10082023)\n",
    "batch1 = [str(x) for x in np.random.randint(0, 100000, size=20000)]\n",
    "batch2 = [str(x) for x in np.random.randint(100001, 200000, size=20000)]\n",
    "batch3 = [str(x) for x in np.random.randint(200001, 300000, size=20000)]\n",
    "batch4 = [str(x) for x in np.random.randint(300001, 400000, size=20000)]\n",
    "batch5 = [str(x) for x in np.random.randint(400001, 500000, size=20000)]\n",
    "batch6 = [str(x) for x in np.random.randint(500001, 600000, size=20000)]\n",
    "batch7 = [str(x) for x in np.random.randint(600001, 700000, size=20000)]\n",
    "\n",
    "# let's just try batch1 first.\n",
    "batches = [batch1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate links and get texts\n",
    "max_workers = 30\n",
    "\n",
    "for i, urls in enumerate(batches):\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_url, x) for x in urls]\n",
    "\n",
    "        for future in tqdm(futures, total=len(urls)):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                with open(f'theedgemalaysia--complete-batch-{i+1}.jsonl', 'a') as f:\n",
    "                    json.dump(result, f)\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Final checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of articles: 234\n",
      "                                      url  \\\n",
      "0  https://theedgemalaysia.com/node/33730   \n",
      "1  https://theedgemalaysia.com/node/71781   \n",
      "2  https://theedgemalaysia.com/node/20831   \n",
      "\n",
      "                                            headline         date_published  \\\n",
      "0     Corporate: Tough times ahead for steel players  09 Mar 2009, 11:52 am   \n",
      "1  IIA urges mandatory adoption of internal audit...  09 Mar 2009, 11:52 am   \n",
      "2                                  Privatisation 2.0  09 Mar 2009, 11:52 am   \n",
      "\n",
      "  language                                            content  \n",
      "0  English  Higher raw material costs and uncertainties ov...  \n",
      "1  English  KUALA LUMPUR: The Institute of Internal Audito...  \n",
      "2  English  ONE of the policy objectives desired to be ach...  \n"
     ]
    }
   ],
   "source": [
    "test1 = pd.read_json('theedgemalaysia--complete-batch-1.jsonl', lines=True)\n",
    "print(f'No. of articles: {len(test1)}')\n",
    "print(test1.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
