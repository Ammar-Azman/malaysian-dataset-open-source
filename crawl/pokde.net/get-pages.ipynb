{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14159"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('url/*.json')\n",
    "urls = []\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        urls.extend(json.load(fopen))\n",
    "urls = sorted(list(set(urls)))\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘page’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(urls[0])\n",
    "soup = BeautifulSoup(r.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 minutes email – Stop getting junk just because you signed up to that website!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nSo you find a rather interesting website that has content that totally excites you but they wont allow you to read it unless you sign up to their service, and suddenly, the next thing you know, you’re receiving countless unwanted junk from that website. Sounds familiar? I’ve been in the same position too in the past and used to be rather annoyed by this. Until I discovered 10 minutes emails (click here to go there. This\\xa0is NOT an\\xa0affiliate link whatsoever. We use our URL shortener just to track clicks).\\n\\nOnce you get to the website, a unique email address will be immediately generated for you. You can then use this email for 10 minutes to sign up to whatever services you want to. As most of these services require email address confirmation, your confirmation email will land right into this page automatically. Since it’s AJAXified, you do not really have to refresh the page. Once the email is in, it will automatically appear there. Click on your confirmation link, and you’re all good to go.\\n\\n Join Pokde Telegram Channel\\n\\nJust thought we’d share with you because I was surprised how people didn’t know about the existence of this awesome service when I told them about it. Feel free to share it with your friends too :)\\nClick here to visit 10 minutes email website.\\nSpread the PokdeLoveClick to share on Facebook (Opens in new window)Click to share on Twitter (Opens in new window)Click to share on WhatsApp (Opens in new window)Click to share on Telegram (Opens in new window)Click to share on Skype (Opens in new window)Click to share on Reddit (Opens in new window)\\n\\nRelated\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', {'id': 'content-anchor-inner'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14159it [24:42:45,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for no, url in tqdm(enumerate(urls)):\n",
    "    filename = os.path.join('page', f'{no}.json')\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "    try:\n",
    "        title = soup.find('h1').text\n",
    "    except Exception as e:\n",
    "        title = None\n",
    "\n",
    "    try:\n",
    "        body = soup.find('div', {'id': 'content-anchor-inner'}).text\n",
    "    except Exception as e:\n",
    "        body = None\n",
    "\n",
    "    data = {\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'body': body,\n",
    "    }\n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(data, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
