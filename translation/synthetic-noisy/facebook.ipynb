{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e77cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-noisy-translation-facebook/resolve/main/processed-facebook.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b6be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc004c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'mesolitica/translation-t5-small-standard-bahasa-cased-v2',\n",
    "    use_fast=False\n",
    ")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    'mesolitica/translation-t5-small-standard-bahasa-cased-v2'\n",
    ")\n",
    "all_special_ids = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e512178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26109b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean(string):\n",
    "    string = re.sub(\n",
    "        'http\\\\S+|www.\\\\S+',\n",
    "        '',\n",
    "        ' '.join(\n",
    "            [\n",
    "                word\n",
    "                for word in string.split()\n",
    "                if word.find('#') < 0 and word.find('@') < 0\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6a0137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141851it [00:00, 244178.36it/s]\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "with open('processed-facebook.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        l['cleaned'] = clean(l['left'])\n",
    "        ls.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09572ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': 'Kalau UMNOBN berkuasa, petrol tentu tidak dah subsidi. .. .',\n",
       " 'en': 'If UMNOBN is in power, there will definitely be no petrol subsidy...',\n",
       " 'ms': 'Jika UMNOBN berkuasa, pasti tidak akan ada subsidi petrol...',\n",
       " 'cleaned': 'Kalau UMNOBN berkuasa, petrol tentu tidak dah subsidi. .. .'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e14d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf facebook-predict\n",
    "!mkdir facebook-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0897db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {\n",
    "    'en': 'Manglish',\n",
    "    'ms': 'pasar Melayu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972df6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████                                                                                | 13067/141851 [1:17:28<5:56:46,  6.02it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|███████████▍                                                                            | 18535/141851 [1:49:46<7:01:08,  4.88it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 26%|██████████████████████▎                                                                | 36443/141851 [3:33:29<20:31:56,  1.43it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 58%|███████████████████████████████████████████████████                                     | 82323/141851 [8:04:37<3:51:30,  4.29it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 88%|███████████████████████████████████████████████████████████████████████████▌          | 124623/141851 [12:19:37<1:10:15,  4.09it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(ls))):\n",
    "    filename = os.path.join('facebook-predict', f'{i}.json')\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "        \n",
    "    results = {'original': ls[i]}\n",
    "        \n",
    "    for lang, prefix in pairs.items():\n",
    "    \n",
    "        if ls[i][lang] and len(ls[i][lang]) > 5:\n",
    "            s = ls[i][lang]\n",
    "            input_ids = tokenizer.encode(f'terjemah ke {prefix}: {s}', return_tensors = 'pt')\n",
    "            outputs = model.generate(input_ids.cuda(), max_length = 256, do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                num_return_sequences=5, temperature = 0.7, output_scores = True, return_dict_in_generate = True)\n",
    "            logits = torch.stack(outputs.scores, dim=1)\n",
    "            score = logits.max(dim = -1).values.mean(dim = -1).detach().cpu().numpy().tolist()\n",
    "            seqs = []\n",
    "            for o in outputs.sequences:\n",
    "                o = tokenizer.decode([i for i in o if i not in all_special_ids], \n",
    "                                     spaces_between_special_tokens = False)\n",
    "                seqs.append(o)\n",
    "            \n",
    "            results[lang] = {\n",
    "                'score': score,\n",
    "                'sequences': seqs\n",
    "            }\n",
    "        \n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(results, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f0b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8173719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124623"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('facebook-predict/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effaa45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 124623/124623 [00:18<00:00, 6807.49it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for f in tqdm(files):\n",
    "    try:\n",
    "        with open(f) as fopen:\n",
    "            l = json.load(fopen)\n",
    "        predicted.append(l)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5830e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': {'left': 'tolong lah yang lain bongkarkan kesalahan ahli-ahli PAKATAN HARAPAN pula. . tak dengar lagi di mana-mana ini. .',\n",
       "  'en': \"Please, let others point out the mistakes of PH members too. I haven't heard it from anywhere else.\",\n",
       "  'ms': 'Tolonglah biarkan orang lain menunjukkan kesalahan ahli-ahli PH juga. Saya belum mendengarnya dari mana-mana lagi.',\n",
       "  'cleaned': 'tolong lah yang lain bongkarkan kesalahan ahli-ahli PAKATAN HARAPAN pula. . tak dengar lagi di mana-mana ini. .'},\n",
       " 'en': {'score': [29.973703384399414,\n",
       "   28.232908248901367,\n",
       "   28.72986602783203,\n",
       "   29.54612922668457,\n",
       "   28.832304000854492],\n",
       "  'sequences': ['please lah let others point out the mistakes of ph members too i have not heard from anywhere else',\n",
       "   'please let others point out the mistakes of ph members too i dun heard liao',\n",
       "   'please let others point out the mistake of ph members too lah i never heard from anywhere',\n",
       "   'please let others point out the mistakes of ph members also lah i havent heard it from anywhere',\n",
       "   'please let others point out the mistakes of ph members also lah i never heard from everywhere']},\n",
       " 'ms': {'score': [28.217470169067383,\n",
       "   29.343158721923828,\n",
       "   28.570518493652344,\n",
       "   29.061372756958008,\n",
       "   32.10454559326172],\n",
       "  'sequences': ['Tolong lah cakap salah ahli ph jugak. tak dengar dari mana2 lagi',\n",
       "   \"Tolong lah orang lain tunjuk kesalahan ahli PH juga. I haven't heard it from anywhere yet.\",\n",
       "   'Tolong la bagi orang tunjuk salah ahli PH pun tak dengar lagi',\n",
       "   'tolong la bg org lain tunjuk salah dgn ahli2 PH ni..tak dengar pun dr mana2 lagi..',\n",
       "   'tolonglah cakap kat org lain yg salah member2 PAKATAN HARAPAN jgk. aku xdgr pun dari mana2 dah']}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c98bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 124623/124623 [00:01<00:00, 122999.84it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('noisy-augmentation-facebook.jsonl', 'w') as fopen:\n",
    "    for p in tqdm(predicted):\n",
    "        fopen.write(f'{json.dumps(p)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c6d9ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283dfa296db64fb4ad838f6c08a90c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noisy-augmentation-facebook.jsonl:   0%|          | 0.00/148M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/noisy-augmentation/commit/9f8d68771053d9dcc6a9355556311673d780794d', commit_message='Upload noisy-augmentation-facebook.jsonl with huggingface_hub', commit_description='', oid='9f8d68771053d9dcc6a9355556311673d780794d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='noisy-augmentation-facebook.jsonl',\n",
    "    path_in_repo='noisy-augmentation-facebook.jsonl',\n",
    "    repo_id='mesolitica/noisy-augmentation',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c80e70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranged = range(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77494c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlap(string1, string2):\n",
    "    l = set([w for w in clean(string1).split() if len(w) > 2])\n",
    "    r = set([w for w in clean(string2).split() if len(w) > 2])\n",
    "    return len(l & r) / len(l)\n",
    "\n",
    "overlap(ls[0]['left'], ls[1]['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed54c6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Teruskan berangan PM tepi selamanya',\n",
       " 'DSAI mantap',\n",
       " 'Rudy Ahmad jangan risau. kalau tengok kat tik tok, banyak anak-anak muda celik mata depa ke arah PN',\n",
       " 'Azidie Rahim haha kena lipakk pulok ',\n",
       " 'Didi Zahari Muhd Hafiz mari join sini']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sampled = random.sample(ranged, 100)\n",
    "negs = []\n",
    "for s in sampled:\n",
    "    overlapped = overlap(ls[0]['ms'], ls[s]['ms'])\n",
    "    if overlapped < 0.05:\n",
    "        negs.append(ls[s]['left'])\n",
    "    if len(negs) >= 5:\n",
    "        break\n",
    "        \n",
    "negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797243bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jika UMNOBN berkuasa, pasti tidak akan ada subsidi petrol...'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[0]['ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80643bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mining-facebook\n",
    "!mkdir mining-facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426930c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def loop(rows):\n",
    "    rows, index = rows\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        filename = os.path.join('mining-facebook', f'{i}-{index}.json')\n",
    "        if os.path.exists(filename):\n",
    "            continue\n",
    "        \n",
    "        sampled = random.sample(ranged, 100)\n",
    "        negs = []\n",
    "        for s in sampled:\n",
    "            try:\n",
    "                overlapped = overlap(rows[i]['original']['ms'], ls[s]['ms'])\n",
    "            except:\n",
    "                continue\n",
    "            if overlapped < 0.05:\n",
    "                negs.append(ls[s]['left'])\n",
    "            if len(negs) >= 5:\n",
    "                break\n",
    "                \n",
    "        en = rows[i]['original']['en']\n",
    "        ms = rows[i]['original']['ms']\n",
    "        \n",
    "        en_augmentation = []\n",
    "        try:\n",
    "            for no, score in enumerate(rows[i]['en']['score']):\n",
    "                if score > 30:\n",
    "                    en_augmentation.append(rows[i]['en']['sequences'][no])\n",
    "            en_augmentation = list(set(en_augmentation))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ms_augmentation = []\n",
    "        try:\n",
    "            for no, score in enumerate(rows[i]['ms']['score']):\n",
    "                if score > 30:\n",
    "                    ms_augmentation.append(rows[i]['ms']['sequences'][no])\n",
    "            ms_augmentation = list(set(ms_augmentation))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            d = {\n",
    "                'negs': negs,\n",
    "                'pos': list(set([en, ms] + en_augmentation + ms_augmentation)),\n",
    "                'query': rows[i]['original']['left'],\n",
    "            }\n",
    "\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(d, fopen)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1990406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8936.70it/s]\n"
     ]
    }
   ],
   "source": [
    "loop((predicted[:1000],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a90b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e7aa0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 9976.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 9089.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 8737.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 9033.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 8976.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 8864.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 8970.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 8947.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 6043.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 8798.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12462/12462 [00:01<00:00, 9070.41it/s]\n"
     ]
    }
   ],
   "source": [
    "mp.multiprocessing(predicted, loop, cores = 10, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47d39cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124623"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('mining-facebook/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "211f15f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 124623/124623 [00:01<00:00, 69441.22it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('mining-facebook.jsonl', 'w') as fopen_l:\n",
    "    for f in tqdm(files):\n",
    "        try:\n",
    "            with open(f) as fopen:\n",
    "                data = json.load(fopen)\n",
    "            fopen_l.write(f'{json.dumps(data)}\\n')\n",
    "            fopen_l.flush()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fb37688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc90a7ef1f934de3b3a86413089cf7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mining-facebook.jsonl:   0%|          | 0.00/90.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/title-context-pair/commit/54a8f97f79728f3c6fd4255416c1509b402bc967', commit_message='Upload mining-facebook.jsonl with huggingface_hub', commit_description='', oid='54a8f97f79728f3c6fd4255416c1509b402bc967', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='mining-facebook.jsonl',\n",
    "    path_in_repo='mining-facebook.jsonl',\n",
    "    repo_id='mesolitica/title-context-pair',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
