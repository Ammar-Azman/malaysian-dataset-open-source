{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf88f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-noisy-translation-b.cari.com.my/resolve/main/processed-b.cari.com.my.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8842a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16327ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'mesolitica/translation-t5-small-standard-bahasa-cased-v2',\n",
    "    use_fast=False\n",
    ")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    'mesolitica/translation-t5-small-standard-bahasa-cased-v2'\n",
    ")\n",
    "all_special_ids = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a6f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea2e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean(string):\n",
    "    string = re.sub(\n",
    "        'http\\\\S+|www.\\\\S+',\n",
    "        '',\n",
    "        ' '.join(\n",
    "            [\n",
    "                word\n",
    "                for word in string.split()\n",
    "                if word.find('#') < 0 and word.find('@') < 0\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84d1885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "631727it [00:04, 142827.45it/s]\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "with open('processed-b.cari.com.my.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        l['cleaned'] = clean(l['left'])\n",
    "        ls.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb7b451",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': 'bagusla mawi bagi peluang kat junior2 dia yang berbakat tak kira lelaki atau perempuan untuk tonjolkan bakat, bila appear dgn mawi ada la orang tertarik nak ambik lagi',\n",
       " 'en': \"It's good that Mawi gives opportunities to talented juniors regardless of gender to showcase their talents. When they appear with Mawi, there are people who are interested in taking them on again.\",\n",
       " 'ms': 'Baguslah Mawi memberi peluang kepada junior-junior yang berbakat tanpa mengira jantina untuk menonjolkan bakat mereka. Apabila mereka muncul bersama Mawi, terdapat orang yang berminat untuk mengambil mereka lagi.',\n",
       " 'cleaned': 'bagusla mawi bagi peluang kat junior2 dia yang berbakat tak kira lelaki atau perempuan untuk tonjolkan bakat, bila appear dgn mawi ada la orang tertarik nak ambik lagi'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ecc2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# s = 'Dalam hujan lebat some more'\n",
    "# input_ids = tokenizer.encode(f'terjemah ke pasar Melayu: {s}', return_tensors = 'pt')\n",
    "# outputs = model.generate(input_ids.cuda(), max_length = 100, do_sample=True,\n",
    "#     top_k=50,\n",
    "#     top_p=0.95,\n",
    "#     num_return_sequences=5, temperature = 1.0, output_scores = True, return_dict_in_generate = True)\n",
    "# seqs = []\n",
    "# for o in outputs.sequences:\n",
    "#     o = tokenizer.decode([i for i in o if i not in all_special_ids], \n",
    "#                          spaces_between_special_tokens = False)\n",
    "#     seqs.append(o)\n",
    "# seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e02b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf b.cari.com.my-predict\n",
    "!mkdir b.cari.com.my-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1330066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {\n",
    "    'en': 'Manglish',\n",
    "    'ms': 'pasar Melayu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a86898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████                                                                            | 73602/631727 [18:17:54<55:19:31,  2.80it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 15%|█████████████▏                                                                        | 96486/631727 [24:00:35<48:49:28,  3.05it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|███████████████                                                                      | 111878/631727 [27:49:21<84:45:23,  1.70it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|███████████████▋                                                                     | 116771/631727 [29:00:29<96:39:59,  1.48it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 20%|████████████████▋                                                                   | 125517/631727 [31:11:21<102:57:29,  1.37it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(ls))):\n",
    "    filename = os.path.join('b.cari.com.my-predict', f'{i}.json')\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "        \n",
    "    results = {'original': ls[i]}\n",
    "        \n",
    "    for lang, prefix in pairs.items():\n",
    "    \n",
    "        if ls[i][lang] and len(ls[i][lang]) > 5:\n",
    "            s = ls[i][lang]\n",
    "            input_ids = tokenizer.encode(f'terjemah ke {prefix}: {s}', return_tensors = 'pt')\n",
    "            outputs = model.generate(input_ids.cuda(), max_length = 256, do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                num_return_sequences=5, temperature = 0.7, output_scores = True, return_dict_in_generate = True)\n",
    "            logits = torch.stack(outputs.scores, dim=1)\n",
    "            score = logits.max(dim = -1).values.mean(dim = -1).detach().cpu().numpy().tolist()\n",
    "            seqs = []\n",
    "            for o in outputs.sequences:\n",
    "                o = tokenizer.decode([i for i in o if i not in all_special_ids], \n",
    "                                     spaces_between_special_tokens = False)\n",
    "                seqs.append(o)\n",
    "            \n",
    "            results[lang] = {\n",
    "                'score': score,\n",
    "                'sequences': seqs\n",
    "            }\n",
    "        \n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(results, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa54905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb3c23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125517"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('b.cari.com.my-predict/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e084346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 125517/125517 [00:02<00:00, 49503.23it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for f in tqdm(files):\n",
    "    try:\n",
    "        with open(f) as fopen:\n",
    "            l = json.load(fopen)\n",
    "        predicted.append(l)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52228fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': {'left': 'jangan pakai hub.. kalu boleh pakai switch.. lebih laju..  hub ader jual lagi ker skarang ni? mcm dah takder .. paling minimum pun 5 port switch',\n",
       "  'en': \"Don't use a hub, if possible use a switch, it's faster. Are hubs still being sold now? It seems like they're not available anymore. At the very least, a switch should have a minimum of 5 ports.\",\n",
       "  'ms': 'Jangan gunakan hub, jika boleh gunakan switch, ia lebih pantas. Adakah hub masih dijual sekarang? Nampaknya sudah tiada lagi. Sekurang-kurangnya, satu switch perlu mempunyai 5 port.',\n",
       "  'cleaned': 'jangan pakai hub.. kalu boleh pakai switch.. lebih laju.. hub ader jual lagi ker skarang ni? mcm dah takder .. paling minimum pun 5 port switch'},\n",
       " 'en': {'score': [32.21791076660156,\n",
       "   27.90170669555664,\n",
       "   27.39642333984375,\n",
       "   30.034753799438477,\n",
       "   27.076414108276367],\n",
       "  'sequences': [\"Don't use hub, if possible use switch faster. Are hubs still being sold now? Looks like they are no more. At the very least a switch should have a minimum of 5 ports.\",\n",
       "   'dun use hub if can use switch faster hub still selling liao machiam no more at least a switch should have at least gt of 5 ports',\n",
       "   'dont use hub lah if can use switch faster are hubs still sold now like shit and at least sg should be at least 5 ports',\n",
       "   'Dont use hub if can use switch faster is hub still sold now? Seems like theyre not available anymore. At least a switch should have 5 ports minimum',\n",
       "   'dont use hub if can use switch faster hub still selling liao lor look like no more at least can have minimum 5 ports']},\n",
       " 'ms': {'score': [28.93027114868164,\n",
       "   28.778968811035156,\n",
       "   29.106645584106445,\n",
       "   27.771217346191406,\n",
       "   28.867475509643555],\n",
       "  'sequences': ['tak pakai hub lah kalo blh pakai switch lagi laju.. hub skrg masih jual ke?  mcm dah xde dah.. at least satu switch kena ada 5 port..',\n",
       "   'jgn wat hub, kalau boleh guna switch lagi pantas..  hub skang ni masih jual kan? mcm dah takde dah..  at least satu switch kena ada 5 port..',\n",
       "   'tak guna hub, kalau boleh guna switch, lagi laju. hub masih jual ke sekarang?  macam dah tak ada dah. at least 1 switch kena ada 5 port.',\n",
       "   'jgn pakai hub kalo blh pakai switch laju la.. hub ni x jual lagi ke skang ni..  mcm dah takde dah dah.. sekurang2nya ss kena ada 5 port',\n",
       "   'tak pakai hub, kalau boleh pakai switch, faster..  hub skrg masih jual? mcm dah takde.. at least, satu switch tu kena 5 port..']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4cf60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 125517/125517 [00:01<00:00, 94741.06it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('noisy-augmentation-b.cari.com.my.jsonl', 'w') as fopen:\n",
    "    for p in tqdm(predicted):\n",
    "        fopen.write(f'{json.dumps(p)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e7ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423c013ff09d400f960e35968845cacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noisy-augmentation-b.cari.com.my.jsonl:   0%|          | 0.00/322M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/noisy-augmentation/commit/74be23b8780098b8f67fb5e10af0cb95767df4e6', commit_message='Upload noisy-augmentation-b.cari.com.my.jsonl with huggingface_hub', commit_description='', oid='74be23b8780098b8f67fb5e10af0cb95767df4e6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='noisy-augmentation-b.cari.com.my.jsonl',\n",
    "    path_in_repo='noisy-augmentation-b.cari.com.my.jsonl',\n",
    "    repo_id='mesolitica/noisy-augmentation',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ae10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranged = range(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4040a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlap(string1, string2):\n",
    "    l = set([w for w in clean(string1).split() if len(w) > 2])\n",
    "    r = set([w for w in clean(string2).split() if len(w) > 2])\n",
    "    return len(l & r) / len(l)\n",
    "\n",
    "overlap(ls[0]['left'], ls[1]['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ffe4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Haaaa proper sikit. Even hasil curi;p  Haha.. iols tak redha curi2 nih..',\n",
       " 'check in..nih apa?? rumah ker pondok kayu???  comeynyer!!!~',\n",
       " 'CUma patut ada verse khas utk gitar solo Slash.',\n",
       " 'TERmoneng..',\n",
       " 'same goes to malaysia yg mane anak2 bangla dan indon akan makin ramai']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sampled = random.sample(ranged, 100)\n",
    "negs = []\n",
    "for s in sampled:\n",
    "    overlapped = overlap(ls[0]['ms'], ls[s]['ms'])\n",
    "    if overlapped < 0.05:\n",
    "        negs.append(ls[s]['left'])\n",
    "    if len(negs) >= 5:\n",
    "        break\n",
    "        \n",
    "negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f38d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mining-b.cari.com.my\n",
    "!mkdir mining-b.cari.com.my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ac869a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def loop(rows):\n",
    "    rows, index = rows\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        filename = os.path.join('mining-b.cari.com.my', f'{i}-{index}.json')\n",
    "        if os.path.exists(filename):\n",
    "            continue\n",
    "        \n",
    "        sampled = random.sample(ranged, 100)\n",
    "        negs = []\n",
    "        for s in sampled:\n",
    "            try:\n",
    "                overlapped = overlap(rows[i]['original']['ms'], ls[s]['ms'])\n",
    "            except:\n",
    "                continue\n",
    "            if overlapped < 0.05:\n",
    "                negs.append(ls[s]['left'])\n",
    "            if len(negs) >= 5:\n",
    "                break\n",
    "                \n",
    "        en = rows[i]['original']['en']\n",
    "        ms = rows[i]['original']['ms']\n",
    "        \n",
    "        en_augmentation = []\n",
    "        try:\n",
    "            for no, score in enumerate(rows[i]['en']['score']):\n",
    "                if score > 30:\n",
    "                    en_augmentation.append(rows[i]['en']['sequences'][no])\n",
    "            en_augmentation = list(set(en_augmentation))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ms_augmentation = []\n",
    "        try:\n",
    "            for no, score in enumerate(rows[i]['ms']['score']):\n",
    "                if score > 30:\n",
    "                    ms_augmentation.append(rows[i]['ms']['sequences'][no])\n",
    "            ms_augmentation = list(set(ms_augmentation))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            d = {\n",
    "                'negs': negs,\n",
    "                'pos': list(set([en, ms] + en_augmentation + ms_augmentation)),\n",
    "                'query': rows[i]['original']['left'],\n",
    "            }\n",
    "\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(d, fopen)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "438353f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4609.28it/s]\n"
     ]
    }
   ],
   "source": [
    "loop((predicted[:1000],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50b3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c9748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4918.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4431.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4378.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4282.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4365.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4424.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 4108.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4443.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4437.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4465.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12551/12551 [00:02<00:00, 4597.56it/s]\n"
     ]
    }
   ],
   "source": [
    "mp.multiprocessing(predicted, loop, cores = 10, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b4e9c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125517"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('mining-b.cari.com.my/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fbe8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 125517/125517 [00:02<00:00, 57616.98it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('mining-b.cari.com.my.jsonl', 'w') as fopen_l:\n",
    "    for f in tqdm(files):\n",
    "        try:\n",
    "            with open(f) as fopen:\n",
    "                data = json.load(fopen)\n",
    "            fopen_l.write(f'{json.dumps(data)}\\n')\n",
    "            fopen_l.flush()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b76d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb4662b4d7d40ed8a045793d67279b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mining-b.cari.com.my.jsonl:   0%|          | 0.00/245M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/title-context-pair/commit/c4ec90de6434a3e6742342219a4b70716f83d342', commit_message='Upload mining-b.cari.com.my.jsonl with huggingface_hub', commit_description='', oid='c4ec90de6434a3e6742342219a4b70716f83d342', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='mining-b.cari.com.my.jsonl',\n",
    "    path_in_repo='mining-b.cari.com.my.jsonl',\n",
    "    repo_id='mesolitica/title-context-pair',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
