{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/dev/malaya/malaya/tokenizer.py:208: FutureWarning: Possible nested set at position 3372\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:208: FutureWarning: Possible nested set at position 3890\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya.text.rules import rules_normalizer, rules_compound_normalizer\n",
    "from malaya.text.normalization import _is_number_regex\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = '!\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}~'\n",
    "\n",
    "def case_of(text):\n",
    "    return (\n",
    "        str.upper\n",
    "        if text.isupper()\n",
    "        else str.lower\n",
    "        if text.islower()\n",
    "        else str.title\n",
    "        if text.istitle()\n",
    "        else str\n",
    "    )\n",
    "\n",
    "def strip_punct(word):\n",
    "    left = []\n",
    "    right = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if word[i] in PUNCTUATION:\n",
    "            left.append(word[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    i = len(word) - 1\n",
    "    while i > 0:\n",
    "        if word[i] in PUNCTUATION:\n",
    "            right.append(word[i])\n",
    "            i -= 1\n",
    "        else:\n",
    "            break\n",
    "    left = ''.join(left)\n",
    "    right = ''.join(right[::-1])\n",
    "    if len(right):\n",
    "        word_ = word[:-len(right)]\n",
    "    else:\n",
    "        word_ = word\n",
    "    word_ = word_[len(left):]\n",
    "    return left, right, word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/husein/translation/alignment.alignment') as fopen:\n",
    "    for i in fopen:\n",
    "        data = json.loads(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I will fight with them till they become like us.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['left'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_punct(left_word, right_word):\n",
    "    left_left, left_right, left_word = strip_punct(left_word)\n",
    "    right_left, right_right, right_word = strip_punct(right_word)\n",
    "    return f'{left_left}{right_word}{left_right}'\n",
    "\n",
    "def random_replace_alignment(left, right, alignment, min_replace = 5, max_replace = 15):\n",
    "    splitted_left = left.split()\n",
    "    splitted_right = right.split()\n",
    "    \n",
    "    selected_alignment = []\n",
    "    for s in alignment:\n",
    "        l = s[0]\n",
    "        r = s[1]\n",
    "        if _is_number_regex(splitted_left[l].replace(',', '').replace('.', '')) or _is_number_regex(splitted_right[r].replace(',', '').replace('.', '')):\n",
    "            continue\n",
    "        elif splitted_left[l].isupper() or splitted_right[r].isupper():\n",
    "            continue\n",
    "        elif splitted_left[l].istitle() or splitted_right[r].istitle():\n",
    "            continue\n",
    "        elif splitted_left[l] == splitted_right[r]:\n",
    "            continue\n",
    "        elif splitted_right[r].lower() in ['the', 'a', 'an', 'it', 'is', 'are']:\n",
    "            continue\n",
    "        else:\n",
    "            selected_alignment.append((l, r))\n",
    "    \n",
    "    count_replace = random.randint(min_replace, min(max_replace, len(selected_alignment)))\n",
    "    \n",
    "    selected = random.sample(selected_alignment, count_replace)\n",
    "    for s in selected:\n",
    "        splitted_left[s[0]] = replace_words_punct(splitted_left[s[0]], splitted_right[s[1]])\n",
    "    \n",
    "    return ' '.join(splitted_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "\n",
    "def augment(left, right, alignment):\n",
    "    \n",
    "    left = random_replace_alignment(left, right, alignment)\n",
    "    \n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Except Iblis, he pula terhadap berlaku dari the kalangan shalih.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "alignment = data['forward'][k]\n",
    "left = data['left'][k]\n",
    "right = data['right'][k]\n",
    "augment(left, right, alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "736635it [05:34, 2201.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open('en-ms-augment-v3.jsonl', 'w') as fwrite:\n",
    "    with open('/home/husein/translation/alignment.alignment') as fopen:\n",
    "        for i in tqdm(fopen):\n",
    "            try:\n",
    "                data = json.loads(i)\n",
    "                result = []\n",
    "                for k in range(len(data['right'])):\n",
    "                    alignment = data['forward'][k]\n",
    "                    left = data['left'][k]\n",
    "                    right = data['right'][k]\n",
    "                    try:\n",
    "                        augmented = augment(left, right, alignment)\n",
    "                        result.append({'left': left, 'right': right, 'augmented': augmented})\n",
    "                    except:\n",
    "                        pass\n",
    "                fwrite.write(f'{json.dumps(result)}\\n')\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
