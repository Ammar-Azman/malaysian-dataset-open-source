{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya\n",
    "normalizer = malaya.normalize.normalizer(date = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def translate(text):\n",
    "    r = requests.post('http://localhost:8999/api', timeout=5, json={\n",
    "        'text': text,\n",
    "        'from': 'ms',\n",
    "        'to': 'en',\n",
    "        'lite': True,\n",
    "    })\n",
    "    r = r.json()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm filtered-dumping-cleaned-common-crawl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/dumping/clean/filtered-dumping-cleaned-common-crawl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65082254 filtered-dumping-cleaned-common-crawl.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l filtered-dumping-cleaned-common-crawl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = set(['aku', 'kau', 'tak nak', 'taknak', 'tknk', 'aq', 'awk', 'hg', 'harini', 'jugak',\n",
    "               'jer', 'bodoh', 'lembab', 'hotak', 'bangang', 'bengap', 'kepala otak', 'diorang'])\n",
    "\n",
    "selected = set(['promo', 'promosi', 'promotion', 'kampeni', 'tau', 'kroni', 'menyorok',\n",
    "               'ipaq', 'awek', 'balaq', 'xkan', 'takkan', 'macamana', 'lepaih', 'akai', 'perabih',\n",
    "               'depa', 'sapa', 'kecek', 'pakwe', 'mimin'])\n",
    "\n",
    "selected = set(['bodo', 'bengap', 'mangkuk', 'sial', 'boroi', 'lepak', 'bengong', 'bingung',\n",
    "               'kje', 'keje', 'pun', 'punn', 'mane', 'ade', 'sapa', 'kawen',\n",
    "               'aku', 'kau', 'tak nak', 'taknak', 'tknk', 'aq', 'awk', 'hg', 'harini', 'jugak',\n",
    "               'jer', 'bodoh', 'lembab', 'hotak', 'bangang', 'bengap', 'kepala otak', 'diorang',\n",
    "               'promo', 'promosi', 'promotion', 'kampeni', 'tau', 'kroni', 'menyorok',\n",
    "               'ipaq', 'awek', 'balaq', 'xkan', 'takkan', 'macamana', 'lepaih', 'akai', 'perabih',\n",
    "               'depa', 'sapa', 'kecek', 'pakwe', 'mimin', 'xpe', 'saye', 'jer', 'pandai', 'cekang',\n",
    "               'dlm', 'dtg', 'cintai', 'syg', 'pakwa', 'makwa', 'laki', 'pmpuan', 'perempuan',\n",
    "               'habaq', 'teloq', 'sedih', 'gembira', 'cerdik', 'bongok', 'pandai', 'melatah',\n",
    "               'kepala', 'lutut', 'kangkang', 'kaki', 'xpa', 'xper', 'xpaa', 'xpaham', 'xfaham',\n",
    "               'faham', 'lah', 'gak', 'ayaq', 'air'])\n",
    "\n",
    "rejected = set(['bogel', 'comel', 'porn', 'porno', 'hisap', 'main', 'pantat', 'batang', 'kencing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/huseinzol05/98974ae8c6c7a65d4bc0af9f5003786a/raw/5aa5257608b61e8fcc828e99fbd070d5ca7358e3/mp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "def cleaning(s):\n",
    "    s = s.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(s)).strip()\n",
    "\n",
    "def remove(s):\n",
    "    s = re.sub('[^A-Za-z ]+', ' ', s)\n",
    "    return re.sub(r'[ ]+', ' ', s.lower()).strip()\n",
    "\n",
    "def fix_spacing_punct(string):\n",
    "    string = string.replace(' , ', ', ').replace(' !', '!').replace(' . ', '. ').replace('( ', '(') \\\n",
    "    .replace(' )', ')')\n",
    "    return re.sub(r'[ ]+', ' ', string).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65082254it [00:36, 1799276.52it/s]\n"
     ]
    }
   ],
   "source": [
    "f = []\n",
    "already = set()\n",
    "with open('filtered-dumping-cleaned-common-crawl.txt') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = l.strip()\n",
    "        if not len(l):\n",
    "            continue\n",
    "            \n",
    "        if l.isupper():\n",
    "            continue\n",
    "            \n",
    "        if len(l.split()) > 100:\n",
    "            continue\n",
    "            \n",
    "        if len(l.split()) < 2:\n",
    "            continue\n",
    "        \n",
    "        f.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(texts):\n",
    "    texts, _ = texts\n",
    "    f = []\n",
    "    already = set()\n",
    "    for l in tqdm(texts):\n",
    "    \n",
    "        lower = remove(l)\n",
    "        splitted = set(lower.split())\n",
    "        \n",
    "        if len(splitted & rejected):\n",
    "            continue\n",
    "        \n",
    "        if lower not in already:\n",
    "            f.append(cleaning(l))\n",
    "            already.add(lower)\n",
    "            \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 6493409/6493409 [00:34<00:00, 188188.17it/s]\n",
      "100%|██████████████████████████████████████████| 5/5 [00:00<00:00, 22453.45it/s]\n",
      "100%|█████████████████████████████| 6493409/6493409 [00:33<00:00, 192153.66it/s]\n",
      "100%|█████████████████████████████| 6493409/6493409 [00:32<00:00, 198793.68it/s]\n",
      "100%|█████████████████████████████| 6493409/6493409 [00:32<00:00, 197581.22it/s]\n",
      "100%|█████████████████████████████| 6493409/6493409 [00:32<00:00, 199001.57it/s]\n",
      "100%|█████████████████████████████| 6493409/6493409 [00:32<00:00, 197886.64it/s]\n"
     ]
    }
   ],
   "source": [
    "r_ = mp.multiprocessing(f, loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38960459, 12873088)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f), len(r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(texts):\n",
    "    texts, _ = texts\n",
    "    r = []\n",
    "    for l in tqdm(texts):\n",
    "        lower = remove(l)\n",
    "        \n",
    "        if any([len(w) > 30 for w in lower.split()]):\n",
    "            continue\n",
    "        \n",
    "        splitted = set(lower.split())\n",
    "        \n",
    "        if len(splitted & selected):\n",
    "            \n",
    "            l = cleaning(l)\n",
    "            \n",
    "            try:\n",
    "                normalized = normalizer.normalize(\n",
    "                    l, normalize_hingga = False, normalize_cardinal = False,\n",
    "                    normalize_ordinal = False, normalize_pada_hari_bulan = False,\n",
    "                    normalize_fraction = False, normalize_money = False, normalize_date = False,\n",
    "                    normalize_time = False, normalize_ic = False,\n",
    "                    normalize_units = False,\n",
    "                    normalize_url = False, normalize_percent=False, normalize_telephone = False,\n",
    "                    not_a_word_threshold = 1e-9,\n",
    "                )['normalize']\n",
    "\n",
    "                normalized = fix_spacing_punct(normalized)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                normalized = l\n",
    "                \n",
    "            # normalized = l\n",
    "            \n",
    "            r.append({'original': l, 'normalized': normalized})\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop((r_[:10000],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 1072757/1072757 [01:28<00:00, 12091.89it/s]\n",
      "100%|██████████████████████████████████████████| 4/4 [00:00<00:00, 14873.42it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:30<00:00, 11832.23it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:34<00:00, 11399.34it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:37<00:00, 10977.78it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:37<00:00, 11037.05it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:36<00:00, 11073.28it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:38<00:00, 10912.31it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:41<00:00, 10530.67it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:42<00:00, 10507.25it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:43<00:00, 10331.52it/s]\n",
      "100%|██████████████████████████████| 1072757/1072757 [01:42<00:00, 10499.41it/s]\n",
      "100%|███████████████████████████████| 1072757/1072757 [01:47<00:00, 9950.55it/s]\n"
     ]
    }
   ],
   "source": [
    "r__ = mp.multiprocessing(r_, loop, cores = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958756"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 958756/958756 [00:01<00:00, 531779.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('filtered-common-crawl-v3.jsonl', 'w') as fopen:\n",
    "    for d in tqdm(r__):\n",
    "        fopen.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -l 50000 -d --additional-suffix=.splitted filtered-common-crawl-v3.jsonl filtered-common-crawl-v3.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "958756 // 50000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
