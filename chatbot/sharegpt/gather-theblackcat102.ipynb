{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texts-theblackcat102.jsonl14.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl07.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl06.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl04.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl05.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl09.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl08.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl11.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl13.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl03.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl00.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl12.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl10.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl01.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl02.splitted.requested']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "files = glob('texts-theblackcat102.jsonl*.splitted.requested')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6660it [00:00, 158673.00it/s]\n",
      "49552it [00:00, 159634.76it/s]\n",
      "49495it [00:00, 168219.98it/s]\n",
      "49453it [00:00, 174874.50it/s]\n",
      "49334it [00:00, 172525.69it/s]\n",
      "49492it [00:00, 168257.91it/s]\n",
      "49415it [00:00, 172263.46it/s]\n",
      "49419it [00:00, 168491.01it/s]\n",
      "49488it [00:00, 169921.45it/s]\n",
      "49328it [00:00, 163248.93it/s]\n",
      "49467it [00:00, 170768.93it/s]\n",
      "49545it [00:00, 177882.81it/s]\n",
      "49474it [00:00, 172191.35it/s]\n",
      "49464it [00:00, 165565.03it/s]\n",
      "49500it [00:00, 172736.07it/s]\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            data = json.loads(l)\n",
    "            if 'Source text\\nclear\\nLook up details' in data['r']['result']:\n",
    "                continue\n",
    "            if 'clear\\nLook up details' in data['r']['result']:\n",
    "                continue\n",
    "            if data['r']['result'].startswith('Source text\\n'):\n",
    "                continue\n",
    "                \n",
    "            mapping[data['src']] = data['r']['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('train.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        data.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for k in range(len(data[i]['conversations'])):\n",
    "        ms = mapping.get(data[i]['conversations'][k]['text'])\n",
    "        data[i]['conversations'][k]['text_ms'] = ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gather-theblackcat102.jsonl', 'w') as fopen:\n",
    "    for d in data:\n",
    "        fopen.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_at = [\n",
    "    'help.openai.com',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 50496/50496 [00:00<00:00, 68424.47it/s]\n"
     ]
    }
   ],
   "source": [
    "all_texts = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    texts = []\n",
    "    for c in data[i]['conversations']:\n",
    "        if c['user'] == 'human':\n",
    "            t = '<manusia>: '\n",
    "            n = c['text_ms'] if random.random() < 0.6 and c['text_ms'] else c['text']\n",
    "            n = n.strip()\n",
    "            if len(n) < 3:\n",
    "                break\n",
    "            t += n\n",
    "        else:\n",
    "            if c['text_ms'] is None:\n",
    "                break\n",
    "            if any([b in c['text_ms'].lower() for b in break_at]):\n",
    "                # print(c['text_ms'], '\\n-----\\n')\n",
    "                break\n",
    "            n = c['text_ms']\n",
    "            n = n.strip()\n",
    "            if len(n) < 3:\n",
    "                break\n",
    "            t = '<bot>: ' + n\n",
    "        texts.append(t)\n",
    "    if len(texts) % 2 != 0:\n",
    "        texts = texts[:-1]\n",
    "    if not len(texts):\n",
    "        continue\n",
    "    while len(texts) and texts[-1].startswith('<manusia>'):\n",
    "        texts = texts[:-1]\n",
    "    if not len(texts):\n",
    "        continue\n",
    "    if not texts[0].startswith('<manusia>'):\n",
    "        continue\n",
    "    all_texts.append('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41530"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('theblackcat102-all_texts.jsonl', 'w') as fopen:\n",
    "    for t in all_texts:\n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('theblackcat102-all_texts.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        if 'Source text' in l:\n",
    "            print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
