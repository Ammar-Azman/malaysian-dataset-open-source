{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texts-theblackcat102.jsonl14.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl07.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl06.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl04.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl05.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl09.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl08.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl11.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl13.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl03.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl00.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl12.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl10.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl01.splitted.requested',\n",
       " 'texts-theblackcat102.jsonl02.splitted.requested']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "files = glob('texts-theblackcat102.jsonl*.splitted.requested')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6660it [00:00, 141413.24it/s]\n",
      "49552it [00:00, 166466.15it/s]\n",
      "49495it [00:00, 139645.55it/s]\n",
      "49453it [00:00, 132582.90it/s]\n",
      "49334it [00:00, 114573.75it/s]\n",
      "49492it [00:00, 143103.20it/s]\n",
      "49415it [00:00, 143611.59it/s]\n",
      "49419it [00:00, 133630.00it/s]\n",
      "49488it [00:00, 168237.08it/s]\n",
      "49328it [00:00, 163090.26it/s]\n",
      "49467it [00:00, 172519.15it/s]\n",
      "49545it [00:00, 176544.32it/s]\n",
      "49474it [00:00, 176592.73it/s]\n",
      "49464it [00:00, 160466.31it/s]\n",
      "49500it [00:00, 177403.56it/s]\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            data = json.loads(l)\n",
    "            mapping[data['src']] = data['r']['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506044"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('train.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        data.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for k in range(len(data[i]['conversations'])):\n",
    "        ms = mapping.get(data[i]['conversations'][k]['text'])\n",
    "        data[i]['conversations'][k]['text_ms'] = ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gather-theblackcat102.jsonl', 'w') as fopen:\n",
    "    for d in data:\n",
    "        fopen.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_at = [\n",
    "    'help.openai.com',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████▌                                                                                      | 7281/50496 [00:00<00:01, 36829.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com.\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com.\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Pelayan mengalami ralat semasa memproses permintaan anda. Maaf tentang itu! Anda boleh mencuba semula permintaan anda atau hubungi kami melalui pusat bantuan kami di help.openai.com jika ralat berterusan. \n",
      "-----\n",
      "\n",
      "Pelayan mengalami ralat semasa memproses permintaan anda. Maaf tentang itu! Anda boleh mencuba semula permintaan anda atau hubungi kami melalui pusat bantuan kami di help.openai.com jika ralat berterusan. \n",
      "-----\n",
      "\n",
      "Model itu pada masa ini terlalu sarat dengan permintaan lain. Anda boleh mencuba semula permintaan anda atau hubungi kami melalui pusat bantuan kami di help.openai.com jika ralat berterusan. (Sila sertakan ID permintaan 48392fadd323c505d7efc95e68a9b46d dalam mesej anda.) \n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████▉                                                         | 21708/50496 [00:00<00:00, 46067.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com.\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Anda meminta model yang tidak serasi dengan enjin ini. Sila hubungi kami melalui pusat bantuan kami di help.openai.com untuk pertanyaan lanjut. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Pelayan mengalami ralat semasa memproses permintaan anda. Maaf tentang itu! Anda boleh mencuba semula permintaan anda atau hubungi kami melalui pusat bantuan kami di help.openai.com jika ralat berterusan. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Model itu pada masa ini terlalu sarat dengan permintaan lain. Anda boleh mencuba semula permintaan anda atau hubungi kami melalui pusat bantuan kami di help.openai.com jika ralat berterusan. (Sila sertakan ID permintaan 3c12bb49b2666a09d9287a528d8dc35f dalam mesej anda.) \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Anda meminta model yang tidak serasi dengan enjin ini. Sila hubungi kami melalui pusat bantuan kami di help.openai.com untuk pertanyaan lanjut. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████████▋                                   | 32665/50496 [00:00<00:00, 50891.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 50496/50496 [00:01<00:00, 50266.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com.\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n",
      "Ralat berlaku. Jika isu ini berterusan, sila hubungi kami melalui pusat bantuan kami di help.openai.com. \n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_texts = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    texts = []\n",
    "    for c in data[i]['conversations']:\n",
    "        if c['user'] == 'human':\n",
    "            t = '<manusia>: '\n",
    "            n = c['text_ms'] if random.random() < 0.6 and c['text_ms'] else c['text']\n",
    "            n = n.strip()\n",
    "            if len(n) < 3:\n",
    "                break\n",
    "            t += n\n",
    "        else:\n",
    "            if c['text_ms'] is None:\n",
    "                break\n",
    "            if any([b in c['text_ms'].lower() for b in break_at]):\n",
    "                print(c['text_ms'], '\\n-----\\n')\n",
    "                break\n",
    "            n = c['text_ms']\n",
    "            n = n.strip()\n",
    "            if len(n) < 3:\n",
    "                break\n",
    "            t = '<bot>: ' + n\n",
    "        texts.append(t)\n",
    "    if len(texts) % 2 != 0:\n",
    "        texts = texts[:-1]\n",
    "    if not len(texts):\n",
    "        continue\n",
    "    while len(texts) and texts[-1].startswith('<manusia>'):\n",
    "        texts = texts[:-1]\n",
    "    if not len(texts):\n",
    "        continue\n",
    "    if not texts[0].startswith('<manusia>'):\n",
    "        continue\n",
    "    all_texts.append('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<bot>:' in all_texts[0].split('<manusia>:')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in all_texts:\n",
    "#     inputs, outputs = [], []\n",
    "#     splitted = t.split('<bot>:')\n",
    "#     for i in range(len(splitted) - 1):\n",
    "#         if i == 0:\n",
    "#             human = splitted[i].replace('<manusia>:', '')\n",
    "#         else:\n",
    "#             human = splitted[i].split('<manusia>:')[1]\n",
    "#         bot = splitted[i + 1].split('<manusia>:')[0]\n",
    "#         if len(human.strip()) < 5 or len(bot.strip()) < 5:\n",
    "#             print('human', human.strip())\n",
    "#             print('bot', bot.strip())\n",
    "#             print('-------')\n",
    "#             break\n",
    "#         inputs.append(human.strip())\n",
    "#         outputs.append(bot.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('theblackcat102-all_texts.jsonl', 'w') as fopen:\n",
    "    for t in all_texts:\n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
