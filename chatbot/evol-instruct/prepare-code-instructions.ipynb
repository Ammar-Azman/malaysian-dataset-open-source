{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce09644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/TokenBender/unnatural_code_instructions_20M/resolve/main/unnatural_training_data_unique.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3891879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import malaya\n",
    "from pydantic import BaseModel, Field\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import random\n",
    "\n",
    "minimum_len = 15\n",
    "\n",
    "def simple_cleaning(string):\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(string).replace('\\n', ' ').replace('--', ' ').replace('/', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8357901",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://husein-ai4-aiservices834896161.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = ''\n",
    "\n",
    "engine = 'gpt-35-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7425447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt, max_tokens = 1024):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "       \n",
    "    ]\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=engine,\n",
    "            messages=messages,\n",
    "            temperature=1.0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        return response.choices[0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f79b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112345"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = []\n",
    "with open('unnatural_training_data_unique.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        l = l['text'].split('### Response')[0].split('### Instruction:')[1].strip().replace('\\\\n', '').strip()\n",
    "        instructions.append(l)\n",
    "        \n",
    "len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f8da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from depth import createConstraintsPrompt, createDeepenPrompt, createConcretizingPrompt, createReasoningPrompt\n",
    "from breadth import createBreadthPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe24fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘code-instructions’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir code-instructions\n",
    "# !rm output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb23806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction, index):\n",
    "    filename = f'code-instructions/{index}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        evol_prompts = []\n",
    "        evol_prompts.append(createConstraintsPrompt(instruction))\n",
    "        evol_prompts.append(createDeepenPrompt(instruction))\n",
    "        evol_prompts.append(createConcretizingPrompt(instruction))\n",
    "        evol_prompts.append(createReasoningPrompt(instruction))\n",
    "        evol_prompts.append(createBreadthPrompt(instruction))\n",
    "\n",
    "        selected_evol_prompt = random.choice(evol_prompts)\n",
    "        ins = predict(selected_evol_prompt)\n",
    "        answer = predict(ins + ', jawab dalam bahasa melayu', max_tokens = 2048)\n",
    "        d = {\"instruction\":ins,\"output\":answer}\n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(d, fopen)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684f5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(instructions[5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4724eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████▌                         | 2910/9362 [00:00<00:00, 9707.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "unsupported operand type(s) for +: 'NoneType' and 'str'\n",
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "unsupported operand type(s) for +: 'NoneType' and 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████▏            | 5932/9362 [4:01:28<9:03:19,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████▍        | 6874/9362 [7:26:44<132:02:53, 191.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out: HTTPSConnectionPool(host='husein-ai4-aiservices834896161.openai.azure.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████▏       | 7265/9362 [8:42:28<8:26:14, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "unsupported operand type(s) for +: 'NoneType' and 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████▎      | 7572/9362 [9:47:15<7:24:01, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 9362/9362 [16:28:15<00:00,  6.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_worker = 3\n",
    "for i in tqdm(range(0, len(instructions) // 4, max_worker)):\n",
    "    b = instructions[i: i + max_worker]\n",
    "    b = [(ins, i + no) for no, ins in enumerate(b)]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate, f[0], f[1]): f for f in b}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c21b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
