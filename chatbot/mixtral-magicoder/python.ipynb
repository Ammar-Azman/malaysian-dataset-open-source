{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5925f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/malaysia-ai/starcoderdata-sample/resolve/main/python.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbdc708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffb61fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200000it [00:11, 17301.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "198298"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = []\n",
    "\n",
    "with open('python.jsonl.1') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        try:\n",
    "            l = json.loads(l)\n",
    "            if len(l['content'].split()) > 5e3:\n",
    "                continue\n",
    "            ls.append(l['content'])\n",
    "            if len(ls) > 200000:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b256678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    '', timeout = 120\n",
    ")\n",
    "\n",
    "\n",
    "def format_prompt(message, history):\n",
    "  prompt = \"<s>\"\n",
    "  for user_prompt, bot_response in history:\n",
    "    prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "    prompt += f\" {bot_response}</s> \"\n",
    "  prompt += f\"[INST] {message} [/INST]\"\n",
    "  return prompt\n",
    "\n",
    "def format_user(history):\n",
    "    prompt = \"<s>\"\n",
    "    for user_prompt, bot_response in history:\n",
    "        prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "        prompt += f\" {bot_response}</s> \"\n",
    "    prompt += f\"[INST]\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a041c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = dict(\n",
    "    temperature=1.0,\n",
    "    max_new_tokens=5120,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.0,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf50ad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘mixtral-python’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir mixtral-python\n",
    "# !rm -rf mixtral-python/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9225ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(q, i):\n",
    "    filename = f'mixtral-python/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "    # for _ in range(5):\n",
    "        try:\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "Please gain inspiration from the following random code snippet to create a high-quality Python problem. Present your output in two distinct sections: [Problem Description] and [Solution].\n",
    "\n",
    "Python snippet for inspiration:\n",
    "```\n",
    "{q}\n",
    "```\n",
    "\n",
    "Guidelines for each section:\n",
    "\n",
    "1. [Problem Description]: This should be **completely self-contained**, providing all the contextual information one needs to understand and solve the problem. Assume common programming knowledge, but ensure that any specific context, variables, or code snippets pertinent to this problem are explicitly included.\n",
    "\n",
    "2. [Solution]: Offer a comprehensive, **correct** solution that accurately addresses the [Problem Description] you provided.\n",
    "\"\"\".strip()\n",
    "            formatted_prompt = format_prompt(prompt, [])\n",
    "            stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "            output = stream.generated_text\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(output, fopen)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if 'tokens + `max_new_tokens`' in str(e):\n",
    "                with open(filename, 'w') as fopen:\n",
    "                    json.dump(False, fopen)\n",
    "                break\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c282de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5eba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "queue = Queue()\n",
    "questions = ls\n",
    "urls = [(q, no) for no, q in enumerate(questions)]\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cbef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d73de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **[Problem Description]**\n",
      "\n",
      "The `serializers.py` file provided is part of a Django application that uses the Django Rest Framework (DRF) and the `rest_framework_gis` package to create a GeoJSON API. This application is used to serialize various GeoJSON models related to land use and land cover data.\n",
      "\n",
      "In this problem, you are required to fix the issues with the `ZonesBaties2018Serializer` class, which is currently missing the `get_couverture` and `get_usage` methods. These methods are essential for generating the correct serialized output as they provide the corresponding labels for the `couverture` and `usage` fields.\n",
      "\n",
      "**Input:**\n",
      "\n",
      "The input to the serializer is a model instance of `ZonesBaties2018` class, which has the following fields:\n",
      "\n",
      "* `id`\n",
      "* `couverture` (foreign key to `CouvertureSol`)\n",
      "* `usage` (foreign key to `UsageSol`)\n",
      "* `surface`\n",
      "\n",
      "**Output:**\n",
      "\n",
      "The expected output of the serializer should be a serialized GeoJSON object, which includes the `couverture` and `usage` fields with their corresponding labels. The label can be obtained by calling the `get_label` method with `code` and `label` attributes of the related `CouvertureSol` and `UsageSol` instances.\n",
      "\n",
      "**[Solution]**\n",
      "\n",
      "In order to fix the `ZonesBaties2018Serializer`, add the missing `get_couverture` and `get_usage` SerializerMethodField methods.\n",
      "\n",
      "```python\n",
      "class ZonesBaties2018Serializer(serializers.GeoFeatureModelSerializer):\n",
      "    couverture = s.SerializerMethodField()\n",
      "    usage = s.SerializerMethodField()\n",
      "\n",
      "    def get_couverture(self, obj):\n",
      "        return get_label(code=obj.couverture.code, label=obj.couverture.label)\n",
      "\n",
      "    def get_usage(self, obj):\n",
      "        return get_label(code=obj.usage.code, label=obj.usage.label)\n",
      "\n",
      "    class Meta:\n",
      "        fields = (\n",
      "            \"id\",\n",
      "            \"couverture\",\n",
      "            \"usage\",\n",
      "            \"surface\",\n",
      "        )\n",
      "        geo_field = \"mpoly\"\n",
      "        model = ZonesBaties2018\n",
      "```\n",
      "\n",
      "By adding these methods, the serializer can now correctly generate the serialized GeoJSON object with the `couverture` and `usage` fields and their corresponding labels.\n"
     ]
    }
   ],
   "source": [
    "with open('mixtral-python/0.json') as fopen:\n",
    "    print(json.loads(fopen.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475dd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▋                                                                                         | 15750/198298 [7:54:04<156:52:23,  3.09s/it]"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ae3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
