{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03975148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6965e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaysian-youtube-whisper-large-v3/resolve/main/pseudolabel.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17bfe621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2221856it [00:09, 240134.92it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "with open('pseudolabel.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        if l['score_ms'] < 8:\n",
    "            continue\n",
    "        t = l['predict_ms'][42:-13].strip()\n",
    "        if len(t.split()) < 70:\n",
    "            continue\n",
    "        texts.append((l['audio_filename'], t))\n",
    "        \n",
    "        if l['score_en'] < 8:\n",
    "            continue\n",
    "        t = l['predict_en'][42:-13].strip()\n",
    "        if len(t.split()) < 70:\n",
    "            continue\n",
    "        \n",
    "        texts.append((l['audio_filename'], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e1b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514126"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398a8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "generate_kwargs = dict(\n",
    "    temperature=1.0,\n",
    "    max_new_tokens=4096,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.0,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d8a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    \"\", timeout = 40\n",
    ")\n",
    "\n",
    "\n",
    "def format_prompt(message, history):\n",
    "  prompt = \"<s>\"\n",
    "  for user_prompt, bot_response in history:\n",
    "    prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "    prompt += f\" {bot_response}</s> \"\n",
    "  prompt += f\"[INST] {message} [/INST]\"\n",
    "  return prompt\n",
    "\n",
    "def format_user(history):\n",
    "    prompt = \"<s>\"\n",
    "    for user_prompt, bot_response in history:\n",
    "        prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "        prompt += f\" {bot_response}</s> \"\n",
    "    prompt += f\"[INST]\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b71f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘mixtral-audio-instruction’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir mixtral-audio-instruction\n",
    "# !rm mixtral-factual-wrong-v2/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccec8381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output-audio/1-0-0.mp3',\n",
       " 'anda tahu keuntungan boleh lebih tinggi daripada keuntungan kewangan rumah maka saya tidak akan mencari dalam akaun saya akan mencari ke dalam ethereum atau beberapa crypto punks bergantung pada faktor risiko anda kerana rumah kajang dihantar tidak mengganggu dsr saya sejauh ini jadi sekarang apa posisi saya untuk mendapatkan kewangan ketiga jadi mungkin setelah melihat sekeliling saya menemui seorang penjual yang dapat menutupi perhubungan tetapi bank hanya menerima 70% dari itu saya boleh membayar perbezaan dengan menggunakan wang ini kerana sekali lagi ia menyusahkan saya dan aset tetapi jika anda tidak selesa dengan mencari')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bcc273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = texts[0][1]\n",
    "# prompt = f'{c}\\n\\ngenerate questions based on context above'\n",
    "# formatted_prompt = format_prompt(prompt, [])\n",
    "# stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "# output = stream.generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e34f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514126"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = []\n",
    "for c in texts:\n",
    "    prompt = (c[0], c[1], f'{c[1]}\\n\\ngenerate questions based on context above')\n",
    "    prompts.append(prompt)\n",
    "    \n",
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b1a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(q, i):\n",
    "    filename = f'mixtral-audio-instruction/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            prompt = q[2]\n",
    "            formatted_prompt = format_prompt(prompt, [])\n",
    "            stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "            output = stream.generated_text\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump((q[0], q[1], output), fopen)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6308660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_worker = 250\n",
    "\n",
    "# questions = prompts\n",
    "# for i in tqdm(range(0, len(questions), max_worker)):\n",
    "#     urls_ = [(q, no + i) for no, q in enumerate(questions[i: i + max_worker])]\n",
    "    \n",
    "#     with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "#         futures = {executor.submit(answer, url[0], url[1]): url for url in urls_}\n",
    "\n",
    "#         for future in as_completed(futures):\n",
    "#             future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c9a0687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248499"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "files = sorted(glob('mixtral-audio-instruction/*.json'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "506b453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "questions = []\n",
    "for f in tqdm(files):\n",
    "    index = int(os.path.split(f)[1].replace('.json', ''))\n",
    "    filename = texts[index][0]\n",
    "    with open(f) as fopen:\n",
    "        data = json.load(fopen)\n",
    "    if len(data) == 3:\n",
    "        ind = 1\n",
    "    else:\n",
    "        ind = 0\n",
    "    splitted = data[-1].strip().split('\\n')\n",
    "    splitted = [s for s in splitted if '.' if s and '?' in s]\n",
    "    splitted = ['.'.join(s.split('.')[1:]).strip() for s in splitted]\n",
    "    splitted = [s for s in splitted if len(s) > 3]\n",
    "    splitted = [s[1:] if s[0] == '\"' else s for s in splitted]\n",
    "    splitted = [s[:-1] if s[-1] == '\"' else s for s in splitted]\n",
    "    splitted = splitted[:5]\n",
    "    splitted = [(filename, data[ind], s.strip()) for s in splitted]\n",
    "    questions.extend(splitted)\n",
    "    \n",
    "questions = [s for s in questions if len(s[2]) > 20]\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33b96d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘answer-mixtral-audio-instruction’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir answer-mixtral-audio-instruction\n",
    "# !rm answer-mixtral-audio-instruction/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f32ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(q, i):\n",
    "    filename = f'answer-mixtral-audio-instruction/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    question = f'{q[1]}\\n{q[2]}'\n",
    "    formatted_prompt = format_prompt(question, [])\n",
    "    while True:\n",
    "        try:\n",
    "            stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "            answer = stream.generated_text.strip()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass \n",
    "    \n",
    "    history = [(question, answer)]\n",
    "\n",
    "    for _ in range(random.randint(1, 2)):\n",
    "        formatted_prompt = format_user(history)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                stream = client.text_generation(formatted_prompt, **generate_kwargs, stop_sequences = ['\\n', '?', '[/INST]'], stream=False, details=True, return_full_text=False)\n",
    "                u = stream.generated_text.strip()\n",
    "                break\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "        \n",
    "        formatted_prompt = format_prompt(u, history)\n",
    "        while True:\n",
    "            try:\n",
    "                stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "                a = stream.generated_text.strip()\n",
    "                break\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "            \n",
    "        history.append((u, a))\n",
    "        \n",
    "    d = {\n",
    "        'filename': q[0],\n",
    "        'context': q[1],\n",
    "        'question': q[2],\n",
    "        'answer': answer,\n",
    "        'multiturn': history\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(d, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79041be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(questions[10000], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bccaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6532f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "queue = Queue()\n",
    "urls = [(q, no) for no, q in enumerate(questions)]\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02055f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████▊                     | 294193/1217727 [5:31:52<205:09:46,  1.25it/s]"
     ]
    }
   ],
   "source": [
    "max_worker = 500\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(consumers)):\n",
    "    consumers[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f1f820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293753"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = sorted(glob('answer-mixtral-audio-instruction/*.json'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13fac9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 293753/293753 [00:16<00:00, 18145.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1483960"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = []\n",
    "for f in tqdm(files):\n",
    "    try:\n",
    "        with open(f) as fopen:\n",
    "            data = json.load(fopen)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    all_texts.append(data['question'])\n",
    "    all_texts.append(data['answer'])\n",
    "        \n",
    "    for d in data['multiturn'][1:]:\n",
    "        all_texts.extend(d)\n",
    "    \n",
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30b2517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mixtral-audio-instruction.texts', 'w') as fopen:\n",
    "    for t in set(all_texts):\n",
    "        if not len(t):\n",
    "            continue\n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "291f285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469270 mixtral-audio-instruction.texts\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l mixtral-audio-instruction.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6cc5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp mixtral-audio-instruction.texts ../translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e1847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1469242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "mapping = {}\n",
    "for f in glob('/home/husein/ssd3/translation/mixtral-audio-instruction.texts*.splitted.requested'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            if 'Source text\\nclear\\nLook up details' in l['r']['result']:\n",
    "                continue\n",
    "            if 'clear\\nLook up details' in l['r']['result']:\n",
    "                continue\n",
    "            if l['r']['result'].startswith('Source text\\n'):\n",
    "                continue\n",
    "\n",
    "            n = l['r']['result']\n",
    "            hypens = re.findall('\\w+ -\\w+', n)\n",
    "            for h in hypens:\n",
    "                splitted = h.split('-')\n",
    "                if len(splitted) != 2:\n",
    "                    continue\n",
    "                splitted = [s.strip() for s in splitted]\n",
    "                splitted = '-'.join(splitted)\n",
    "                n = n.replace(h, splitted)\n",
    "            mapping[l['src']] = n\n",
    "            \n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ba38eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 293753/293753 [00:23<00:00, 12353.09it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('mixtral-audio-instruction.jsonl', 'w') as fopen_l:\n",
    "    for f in tqdm(files):\n",
    "        try:\n",
    "            with open(f) as fopen:\n",
    "                data = json.load(fopen)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        chat = [\n",
    "            {'role': 'user', 'content': data['question'], 'content_ms': mapping.get(data['question'])},\n",
    "            {'role': 'assistant', 'content': data['answer'], 'content_ms': mapping.get(data['answer'])}\n",
    "        ]\n",
    "        for d in data['multiturn'][1:]:\n",
    "            chat.extend([\n",
    "                {'role': 'user', 'content': d[0], 'content_ms': mapping.get(d[0])},\n",
    "                {'role': 'assistant', 'content': d[1], 'content_ms': mapping.get(d[1])}\n",
    "            ])\n",
    "\n",
    "        d = {\n",
    "            'context': data['context'],\n",
    "            'chat': chat,\n",
    "            'filename': data['filename']\n",
    "        }\n",
    "        fopen_l.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606573de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94342d01f784c818fd3e7808a322eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mixtral-audio-instruction.jsonl:   0%|          | 0.00/2.01G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='mixtral-audio-instruction.jsonl',\n",
    "    path_in_repo='mixtral-audio-instruction.jsonl',\n",
    "    repo_id='mesolitica/malaysian-youtube-audio-instructions',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4947371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
