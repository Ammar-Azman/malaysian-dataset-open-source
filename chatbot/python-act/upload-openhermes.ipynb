{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85925465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "304d33ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10434"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('openhermes/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e474282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('python-openhermes.jsonl', 'w') as fopen_l:\n",
    "    for f in files:\n",
    "        with open(f) as fopen:\n",
    "            data = json.load(fopen)\n",
    "        \n",
    "        if data['result'] is None:\n",
    "            continue\n",
    "        if len(data['result']) == 3:\n",
    "            continue\n",
    "        if 'I have reached the maximum number of executions' in data['result'][-1]['content']:\n",
    "            continue\n",
    "        fopen_l.write(f'{json.dumps(data)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ed22170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130 python-openhermes.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l python-openhermes.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfea3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c7437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2a40068fdd414ba82b3dd8d9d795c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "python-openhermes.jsonl:   0%|          | 0.00/28.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/python-act/commit/beef7e65a36422284f5c1e417664f7c53fa5de25', commit_message='Upload python-openhermes.jsonl with huggingface_hub', commit_description='', oid='beef7e65a36422284f5c1e417664f7c53fa5de25', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj='python-openhermes.jsonl',\n",
    "    path_in_repo='python-openhermes.jsonl',\n",
    "    repo_id='mesolitica/python-act',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ba451da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"original\": \"Write a function that takes in two numbers and returns the sum.\", \"result\": [{\"role\": \"system\", \"content\": \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nThe assistant can interact with an interactive Python (Jupyter Notebook) environment and receive the corresponding output when needed. The code should be enclosed using \\\"<execute>\\\" tag, for example: <execute> print(\\\"Hello World!\\\") </execute>.\\nThe assistant should attempt fewer things at a time instead of putting too much code in one <execute> block. The assistant can install packages through PIP by <execute> !pip install [package needed] </execute> and should always import packages and define variables before starting to use them.\\nThe assistant should stop <execute> and provide an answer when they have already obtained the answer from the execution result. Whenever possible, execute the code for the user using <execute> instead of providing it.\\nThe assistant's response should be concise, but do express their thoughts.\\n\"}, {\"role\": \"user\", \"content\": \"Write a function that takes in two numbers and returns the sum.\"}, {\"role\": \"assistant\", \"content\": \"Here is a function that takes in two numbers and returns their sum:\\n\\n<execute>\\ndef add_numbers(a, b):\\n  return a + b\\n\\nprint(add_numbers(2, 3))\\n</execute>\"}, {\"role\": \"user\", \"content\": \"Execution Output:\\n5\\n\\n\"}, {\"role\": \"assistant\", \"content\": \"The function `add_numbers(a, b)` takes in two numbers `a` and `b`, adds them together, and returns the result. When called with `add_numbers(2, 3)`, it returns the sum of 2 and 3, which is 5. \\n\"}]}\r\n",
      "{\"original\": \"How can I maintain multiple independent celery queues with distinct tasks and workers in the same Redis database? I am following the celery tutorial and trying to duplicate everything with slightly modified names/queues, but I am encountering errors. I tried to change all instances of tasks to blue_tasks or red_tasks, but when I queue blue_tasks, the red_tasks workers start trying to work on them. I also attempted to use default queues with the following code, but it didn't work:\\n\\n```python\\nCELERY_DEFAULT_QUEUE = 'red'\\nCELERY_QUEUES = (\\n    Queue('red', Exchange('red'), routing_key='red'),\\n)\\n```\\nAdditionally, I am confused about why `celery worker` errors out with celery attempting to connect to a default amqp instance, while `celery -A tasks worker` instructs celery to connect to Redis. What task code is `celery worker` trying to run on the worker if nothing has been specified?\", \"result\": [{\"role\": \"system\", \"content\": \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nThe assistant can interact with an interactive Python (Jupyter Notebook) environment and receive the corresponding output when needed. The code should be enclosed using \\\"<execute>\\\" tag, for example: <execute> print(\\\"Hello World!\\\") </execute>.\\nThe assistant should attempt fewer things at a time instead of putting too much code in one <execute> block. The assistant can install packages through PIP by <execute> !pip install [package needed] </execute> and should always import packages and define variables before starting to use them.\\nThe assistant should stop <execute> and provide an answer when they have already obtained the answer from the execution result. Whenever possible, execute the code for the user using <execute> instead of providing it.\\nThe assistant's response should be concise, but do express their thoughts.\\n\"}, {\"role\": \"user\", \"content\": \"How can I maintain multiple independent celery queues with distinct tasks and workers in the same Redis database? I am following the celery tutorial and trying to duplicate everything with slightly modified names/queues, but I am encountering errors. I tried to change all instances of tasks to blue_tasks or red_tasks, but when I queue blue_tasks, the red_tasks workers start trying to work on them. I also attempted to use default queues with the following code, but it didn't work:\\n\\n```python\\nCELERY_DEFAULT_QUEUE = 'red'\\nCELERY_QUEUES = (\\n    Queue('red', Exchange('red'), routing_key='red'),\\n)\\n```\\nAdditionally, I am confused about why `celery worker` errors out with celery attempting to connect to a default amqp instance, while `celery -A tasks worker` instructs celery to connect to Redis. What task code is `celery worker` trying to run on the worker if nothing has been specified?\"}, {\"role\": \"assistant\", \"content\": \"To maintain multiple independent Celery queues with distinct tasks and workers in the same Redis database, you can follow these steps:\\n\\n1. Use separate modules for tasks:\\n\\nCreate separate modules for your blue and red tasks, for example `blue_tasks.py` and `red_tasks.py`. This will help you keep track of the tasks for each queue independently.\\n\\n1. Configure Celery with separate queues:\\n\\nIn your Celery configuration file, you can configure separate queues for blue and red tasks. Make sure you have the required packages installed:\\n<execute>\\n!pip install celery[redis]\\n</execute>\"}, {\"role\": \"user\", \"content\": \"Execution Output:\\nCollecting celery[redis]\\r\\n  Downloading celery-5.3.6-py3-none-any.whl.metadata (21 kB)\\r\\nCollecting billiard<5.0,>=4.2.0 (from celery[redis])\\r\\n  Downloading billiard-4.2.0-py3-none-any.whl.metadata (4.4 kB)\\r\\nCollecting click-didyoumean>=0.3.0 (from celery[redis])\\r\\n  Downloading click_didyoumean-0.3.0-py3-none-any.whl.metadata (495 bytes)\\r\\nCollecting click-plugins>=1.1.1 (from celery[redis])\\r\\n  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\\r\\nCollecting click-repl>=0.2.0 (from celery[redis])\\r\\n  Downloading click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\\r\\nRequirement already satisfied: click<9.0,>=8.1.2 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (8.1.7)\\r\\nCollecting kombu<6.0,>=5.3.4 (from celery[redis])\\r\\n  Downloading kombu-5.3.5-py3-none-any.whl.metadata (3.1 kB)\\r\\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (2.8.2)\\r\\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (2023.3)\\r\\nCollecting vine<6.0,>=5.1.0 (from celery[redis])\\r\\n  Downloading vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\\r\\nCollecting redis!=4.5.5,<6.0.0,>=4.5.2 (from celery[redis])\\r\\n  Downloading redis-5.0.3-py3-none-any.whl.metadata (9.3 kB)\\r\\nRequirement already satisfied: prompt-toolkit>=3.0.36 in /opt/conda/lib/python3.11/site-packages (from click-repl>=0.2.0->celery[redis]) (3.0.39)\\r\\nCollecting amqp<6.0.0,>=5.1.1 (from kombu<6.0,>=5.3.4->celery[redis])\\r\\n  Downloading amqp-5.2.0-py3-none-any.whl.metadata (8.9 kB)\\r\\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->celery[redis]) (1.16.0)\\r\\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery[redis]) (0.2.8)\\r\\nDownloading billiard-4.2.0-py3-none-any.whl (86 kB)\\r\\n\\u001b[?25l   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 0.0/86.7 kB ? eta -:--:--\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 86.7/86.7 kB 2.8 MB/s eta 0:00:00\\r\\n\\u001b[?25hDownloading click_didyoumean-0.3.0-py3-none-any.whl (2.7 kB)\\r\\nDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\\r\\nDownloading click_repl-0.3.0-py3-none-any.whl (10 kB)\\r\\nDownloading kombu-5.3.5-py3-none-any.whl (200 kB)\\r\\n\\u001b[?25l   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 0.0/200.0 kB ? eta -:--:--\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2578\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 112.6/200.0 kB 3.5 MB/s eta 0:00:01\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 200.0/200.0 kB 3.1 MB/s eta 0:00:00\\r\\n\\u001b[?25hDownloading redis-5.0.3-py3-none-any.whl (251 kB)\\r\\n\\u001b[?25l   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 0.0/251.8 kB ? eta -:--:--\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2578\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 122.9/251.8 kB 3.6 MB/s eta 0:00:01\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u257a 245.8/251.8 kB 3.7 MB/s eta 0:00:01\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 251.8/251.8 kB 3.6 MB/s eta 0:00:00\\r\\n\\u001b[?25hDownloading vine-5.1.0-py3-none-any.whl (9.6 kB)\\r\\nDownloading celery-5.3.6-py3-none-any.whl (422 kB)\\r\\n\\u001b[?25l   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 0.0/422.0 kB ? eta -:--:--\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2578\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 92.2/422.0 kB 3.4 MB/s eta 0:00:01\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u257a\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 204.8/422.0 kB 3.1 MB/s eta 0:00:01\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2578\\u2501\\u2501\\u2501 389.1/422.0 kB 3.7 MB/s eta 0:00:01\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 422.0/422.0 kB 3.7 MB/s eta 0:00:00\\r\\n\\u001b[?25hDownloading amqp-5.2.0-py3-none-any.whl (50 kB)\\r\\n\\u001b[?25l   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 0.0/50.9 kB ? eta -:--:--\\r\\u001b[2K   \\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501 50.9/50.9 kB 4.2 MB/s eta 0:00:00\\r\\n\\u001b[?25hInstalling collected packages: vine, redis, click-plugins, click-didyoumean, billiard, click-repl, amqp, kombu, celery\\r\\nSuccessfully installed amqp-5.2.0 billiard-4.2.0 celery-5.3.6 click-didyoumean-0.3.0 click-plugins-1.1.1 click-repl-0.3.0 kombu-5.3.5 redis-5.0.3 vine-5.1.0\\r\\n\\n\"}, {\"role\": \"assistant\", \"content\": \"To maintain multiple independent Celery queues with distinct tasks and workers in the same Redis database, you can follow these steps:\\n\\n1. Use separate modules for tasks:\\n\\nCreate separate modules for your blue and red tasks, for example `blue_tasks.py` and `red_tasks.py`. This will help you keep track of the tasks for each queue independently.\\n\\n1. Configure Celery with separate queues:\\n\\nIn your Celery configuration file, you can configure separate queues for blue and red tasks. Make sure you have the required packages installed:\\n<execute>\\n!pip install celery[redis]\\n</execute>\"}, {\"role\": \"user\", \"content\": \"Execution Output:\\nRequirement already satisfied: celery[redis] in /opt/conda/lib/python3.11/site-packages (5.3.6)\\r\\nRequirement already satisfied: billiard<5.0,>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (4.2.0)\\r\\nRequirement already satisfied: click-didyoumean>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (0.3.0)\\r\\nRequirement already satisfied: click-plugins>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (1.1.1)\\r\\nRequirement already satisfied: click-repl>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (0.3.0)\\r\\nRequirement already satisfied: click<9.0,>=8.1.2 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (8.1.7)\\r\\nRequirement already satisfied: kombu<6.0,>=5.3.4 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (5.3.5)\\r\\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (2.8.2)\\r\\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (2023.3)\\r\\nRequirement already satisfied: vine<6.0,>=5.1.0 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (5.1.0)\\r\\nRequirement already satisfied: redis!=4.5.5,<6.0.0,>=4.5.2 in /opt/conda/lib/python3.11/site-packages (from celery[redis]) (5.0.3)\\r\\nRequirement already satisfied: prompt-toolkit>=3.0.36 in /opt/conda/lib/python3.11/site-packages (from click-repl>=0.2.0->celery[redis]) (3.0.39)\\r\\nRequirement already satisfied: amqp<6.0.0,>=5.1.1 in /opt/conda/lib/python3.11/site-packages (from kombu<6.0,>=5.3.4->celery[redis]) (5.2.0)\\r\\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->celery[redis]) (1.16.0)\\r\\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery[redis]) (0.2.8)\\r\\n\\n\"}, {\"role\": \"assistant\", \"content\": \"It seems that you have already installed the required packages, including Celery with the Redis backend. Now, let's configure Celery to use separate queues for your blue and red tasks.\\n\\n1. Modify your Celery configuration file (usually `celery.py` or `celery_worker.py`):\\n\\nAdd the following lines to your Celery configuration file to set up the separate queues:\\n```python\\napp.config.update(\\n    CELERY_BROKER_URL_BLUE='redis://localhost:6379/0',\\n    CELERY_BROKER_URL_RED='redis://localhost:6379/1',\\n    CELERY_QUEUES=(\\n        Queue('blue', Exchange('blue'), routing_key='blue'),\\n        Queue('red', Exchange('red'), routing_key='red'),\\n    ),\\n)\\n```\\nMake sure to replace `localhost` with the appropriate Redis server address if needed.\\n\\n1. Run Celery with the workers for each queue:\\n\\nStart Celery workers for each queue separately:\\n```bash\\ncelery worker --app your_celery_app_blue\\ncelery worker --app your_celery_app_red\\n```\\nReplace `your_celery_app_blue` and `your_celery_app_red` with the appropriate module names for your blue and red tasks.\\n\\n1. Submit tasks to the respective queues:\\n\\nNow, you can submit tasks to the blue and red queues using the appropriate task modules:\\n```python\\nfrom blue_tasks import your_blue_task\\nfrom red_tasks import your_red_task\\n\\ncelery_blue = Celery('blue', broker=RedisBrokerBackend(), backend=RedisBackend())\\ncelery_red = Celery('red', broker=RedisBrokerBackend(), backend=RedisBackend())\\n\\n# Submit tasks to the blue queue\\ncelery_blue.send_task('your_blue_task', {'args': your_args})\\n\\n# Submit tasks to the red queue\\ncelery_red.send_task('your_red_task', {'args': your_args})\\n```\\nThis way, you can maintain multiple independent Celery queues with distinct tasks and workers in the same Redis database. \\n\"}]}\r\n",
      "{\"original\": \"Provide example code for the following data structure: stack.\\n<none>\", \"result\": [{\"role\": \"system\", \"content\": \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nThe assistant can interact with an interactive Python (Jupyter Notebook) environment and receive the corresponding output when needed. The code should be enclosed using \\\"<execute>\\\" tag, for example: <execute> print(\\\"Hello World!\\\") </execute>.\\nThe assistant should attempt fewer things at a time instead of putting too much code in one <execute> block. The assistant can install packages through PIP by <execute> !pip install [package needed] </execute> and should always import packages and define variables before starting to use them.\\nThe assistant should stop <execute> and provide an answer when they have already obtained the answer from the execution result. Whenever possible, execute the code for the user using <execute> instead of providing it.\\nThe assistant's response should be concise, but do express their thoughts.\\n\"}, {\"role\": \"user\", \"content\": \"Provide example code for the following data structure: stack.\\n<none>\"}, {\"role\": \"assistant\", \"content\": \"A stack is a Last-In-First-Out (LIFO) data structure. Here's an example of how to create a stack in Python using a list:\\n\\n<execute>\\nclass Stack:\\n    def __init__(self):\\n        self.items = []\\n\\n    def is_empty(self):\\n        return len(self.items) == 0\\n\\n    def push(self, item):\\n        self.items.append(item)\\n\\n    def pop(self):\\n        if self.is_empty():\\n            return \\\"Stack is empty.\\\"\\n        else:\\n            return self.items.pop()\\n\\n    def peek(self):\\n        if self.is_empty():\\n            return \\\"Stack is empty.\\\"\\n        else:\\n            return self.items[-1]\\n\\n    def size(self):\\n        return len(self.items)\\n\\nstack = Stack()\\nstack.push(1)\\nstack.push(2)\\nstack.push(3)\\nprint(stack.pop())\\nprint(stack.pop())\\nprint(stack.pop())\\nprint(stack.is_empty())\\n</execute>\"}, {\"role\": \"user\", \"content\": \"Execution Output:\\n3\\n2\\n1\\nTrue\\n\\n\"}, {\"role\": \"assistant\", \"content\": \"The code above creates a stack class using a list to store the items. The class has methods to check if the stack is empty, add items to the stack, remove items from the stack, peek at the top item, and get the size of the stack.\\n\\nTo demonstrate the usage of the stack, we create a stack object and push some integers onto the stack. Then, we pop the items off the stack and print them out until the stack is empty. Finally, we check if the stack is empty and print the result. \\n\"}]}\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 3 python-openhermes.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d3a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
