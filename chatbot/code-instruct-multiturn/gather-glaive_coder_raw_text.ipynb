{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0819a578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127319"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "files = glob('ultrachat-glaive_coder_raw_text/*.json')\n",
    "files = sorted(files, key = lambda x: os.path.getmtime(x))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18e0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rejected_words = [\n",
    "    'kebutuhan',\n",
    "    'berbeda',\n",
    "    'bahwa',\n",
    "    'Kode',\n",
    "    'kode',\n",
    "    'nomor',\n",
    "    'RMXX,XXX',\n",
    "    'kompleksitas',\n",
    "    'listrik',\n",
    "    'jawaban',\n",
    "    'teknis',\n",
    "    'berkualitas',\n",
    "    'mencoba',\n",
    "    'kampanye',\n",
    "    'komunitas',\n",
    "    'stabilitas',\n",
    "    'Stabilitas',\n",
    "    'metode',\n",
    "    'pria',\n",
    "    'butuh',\n",
    "    'jadwal',\n",
    "    'kasus',\n",
    "    'otomatis',\n",
    "    'populer',\n",
    "    'bisnis',\n",
    "    'probabilitas',\n",
    "    'rusak',\n",
    "    'kapasitas',\n",
    "    'rutinitas'\n",
    "]\n",
    "rejected_words = set(rejected_words)\n",
    "\n",
    "def check_indon(string):\n",
    "    string = re.sub('[^A-Za-z ]+', ' ', string)\n",
    "    return len(set(string.split()) & rejected_words) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11199aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "for f in files:\n",
    "    try:\n",
    "        with open(f) as fopen:\n",
    "            data = json.load(fopen)[1:]\n",
    "        for d in data:\n",
    "            try:\n",
    "                texts.append(d['content'])\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "texts = [t for t in texts if t]\n",
    "texts = [t for t in texts if len(t)]\n",
    "texts = list(set(texts))\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1218d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glaive_coder_raw_text.texts', 'w') as fopen:\n",
    "    for t in texts:\n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f820a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp glaive_coder_raw_text.texts ~/ssd3/ctranslate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67d1707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {}\n",
    "\n",
    "for f in glob('/home/husein/ssd3/ctranslate2/glaive_coder_raw_text.texts*.splitted.requested'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            mapping[l['src']] = l['r']\n",
    "        \n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c8d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ultrachat-glaive_coder_raw_text.jsonl', 'w') as fopen_l:\n",
    "    for f in files:\n",
    "        try:\n",
    "            with open(f) as fopen:\n",
    "                data = json.load(fopen)\n",
    "        except:\n",
    "            continue\n",
    "        if not data:\n",
    "            continue\n",
    "        for i in range(0, len(data), 1):\n",
    "            data[i]['content_ms'] = mapping.get(data[i]['content'])\n",
    "            indon = False\n",
    "            if data[i]['content'] and check_indon(data[i]['content']):\n",
    "                indon = True\n",
    "            data[i]['indon'] = indon\n",
    "        fopen_l.write(f'{json.dumps(data)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75897b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Bagaimana saya boleh mencipta satu Rangkaian Neural Tiruan dalam Python untuk mengkategorikan warna bunga dari input yang diberikan?',\n",
       "  'content_ms': None,\n",
       "  'indon': False},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Untuk mencipta satu Rangkaian Neural Tiruan dalam Python untuk mengkategorikan warna bunga dari input yang diberikan, anda boleh mengikuti langkah-langkah berikut:\\n\\n1. Impor pustaka yang diperlukan:\\n   ```python\\n   import numpy as np\\n   import pandas as pd\\n   from sklearn.model_selection import train_test_split\\n   from sklearn.preprocessing import LabelEncoder\\n   from keras.models import Sequential\\n   from keras.layers import Dense\\n   ```\\n\\n2. Persiapkan data latihan dan data ujian:\\n   ```python\\n   # Misalnya data bunga adalah dalam fail CSV\\n   data = pd.read_csv('nama_fail.csv')\\n\\n   # Pisahkan atribut dan label\\n   X = data.drop('warna', axis=1)\\n   y = data['warna']\\n\\n   # Melabelkan label kategori ke nombor\\n   label_encoder = LabelEncoder()\\n   y = label_encoder.fit_transform(y)\\n\\n   # Bahagikan data kepada data latih dan data ujian\\n   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n   ```\\n\\n3. Cipta model Rangkaian Neural Tiruan:\\n   ```python\\n   model = Sequential()\\n   model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\\n   model.add(Dense(4, activation='relu'))\\n   model.add(Dense(1, activation='sigmoid'))\\n   ```\\n\\n4. Latih model Rangkaian Neural Tiruan:\\n   ```python\\n   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n   model.fit(X_train, y_train, epochs=100, batch_size=10)\\n   ```\\n\\n5. Nilai model menggunakan data ujian:\\n   ```python\\n   _, accuracy = model.evaluate(X_test, y_test)\\n   print('Accuracy: %.2f' % (accuracy*100))\\n   ```\\n\\nSila pastikan anda mempunyai dataset warna bunga yang mencukupi serta mengubah model tersebut mengikut keperluan sebenar anda. Jangan lupa untuk memasukkan preprocessing data yang diperlukan seperti normalisasi, pengkodean, dan pengambilan ciri-ciri yang sesuai.\\n\",\n",
       "  'content_ms': \"Untuk mencipta Rangkaian Neural Tiruan dalam Python untuk mengkategorikan warna bunga dari input yang diberikan, anda boleh mengikuti langkah-langkah berikut:\\n\\n1. Import perpustakaan yang diperlukan:\\n   ```python\\n   import numpy as np\\n   import pandas as pd\\n   from sklearn.model_selection import train_test_split\\n   from sklearn.preprocessing import LabelEncoder\\n   from keras.models import Sequential\\n   from keras.layers import Dense\\n   ```\\n\\n2. Sediakan data latihan dan data ujian:\\n   ```python\\n   # Contohnya data bunga adalah dalam fail CSV\\n   data = pd.read_csv('nama_fail.csv')\\n\\n   # Pisahkan atribut dan label\\n   X = data.drop('warna', axis=1)\\n   y = data['warna']\\n\\n   # Melabelkan label kategori ke nombor\\n   label_encoder = LabelEncoder()\\n   y = label_encoder.fit_transform(y)\\n\\n   # Bahagikan data kepada data latihan dan data ujian\\n   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n   ```\\n\\n3. Cipta model Rangkaian Neural Tiruan:\\n   ```python\\n   model = Sequential()\\n   model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\\n   model.add(Dense(4, activation='relu'))\\n   model.add(Dense(1, activation='sigmoid'))\\n   ```\\n\\n4. Latih model Rangkaian Neural Tiruan:\\n   ```python\\n   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n   model.fit(X_train, y_train, epochs=100, batch_size=10)\\n   ```\\n\\n5. Nilai model menggunakan data ujian:\\n   ```python\\n   _, accuracy = model.evaluate(X_test, y_test)\\n   print('Accuracy: %.2f' % (accuracy*100))\\n   ```\\n\\nSila pastikan anda mempunyai set data warna bunga yang mencukupi serta mengubah model mengikut keperluan sebenar anda. Jangan lupa untuk memasukkan prapemprosesan data yang diperlukan seperti normalisasi, pengekodan, dan pengambilan ciri-ciri yang sesuai.\",\n",
       "  'indon': False},\n",
       " {'role': 'user',\n",
       "  'content': 'Err, Maaf ya. Mungkin saya masih ragu dengan jawapan awak tadi. Boleh saya tahu apakah langkah yang lebih terperinci lagi dalam proses mencipta Rangkaian Neural Tiruan ini? Saya ingin memahami dengan lebih baik.',\n",
       "  'content_ms': 'Err, Maaf. Mungkin saya masih ragu-ragu dengan jawapan awak tadi. Bolehkah saya tahu apakah langkah yang lebih terperinci dalam proses mencipta Rangkaian Neural Tiruan ini? Saya ingin memahami dengan lebih baik.',\n",
       "  'indon': False},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Tentu! Berikut langkah-langkah yang lebih terperinci dalam proses mencipta Rangkaian Neural Tiruan (RNT) untuk mengkategorikan warna bunga dari input yang diberikan:\\n\\n1. Perkara pertama yang perlu anda lakukan adalah mengimport pustaka yang diperlukan:\\n   ```python\\n   import numpy as np\\n   import pandas as pd\\n   from sklearn.model_selection import train_test_split\\n   from sklearn.preprocessing import LabelEncoder\\n   from keras.models import Sequential\\n   from keras.layers import Dense\\n   ```\\n\\n2. Kemudian, anda perlu mempersiapkan data latihan dan data ujian:\\n   ```python\\n   # Misalkan anda mempunyai data bunga yang tersimpan dalam fail CSV\\n   data = pd.read_csv('nama_fail.csv')\\n\\n   # Pisahkan atribut dan label\\n   X = data.drop('warna', axis=1)\\n   y = data['warna']\\n\\n   # Laporkan label kategori ke dalam nombor\\n   label_encoder = LabelEncoder()\\n   y = label_encoder.fit_transform(y)\\n\\n   # Bahagikan data kepada data latihan dan data ujian\\n   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n   ```\\n\\n3. Setelah itu, mari kita cipta model RNT:\\n   ```python\\n   model = Sequential()\\n   model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\\n   model.add(Dense(4, activation='relu'))\\n   model.add(Dense(1, activation='sigmoid'))\\n   ```\\n\\n   Dalam contoh di atas, model RNT yang tersusun terdiri daripada 3 lapisan keras. Lapisan pertama mempunyai 8 neuron, lapisan kedua mempunyai 4 neuron, dan lapisan output hanya mempunyai 1 neuron. Aktivasi 'relu' digunakan untuk lapisan-lapisan tersembunyi, manakala aktivasi 'sigmoid' digunakan untuk lapisan output.\\n\\n4. Setelah itu, kita perlu melatih model menggunakan data latihan:\\n   ```python\\n   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n   model.fit(X_train, y_train, epochs=100, batch_size=10)\\n   ```\\n\\n   Dalam contoh di atas, kami menggunakan fungsi kerugian 'binary_crossentropy' kerana kita mempunyai hanya 2 kategori warna (dua output yang mungkin). Kami juga menggunakan pengoptimum 'adam', tetapi anda boleh menyesuaikan pengoptimum mengikut keperluan anda.\\n\\n5. Akhirnya, kita perlu menilai prestasi model menggunakan data ujian:\\n   ```python\\n   _, accuracy = model.evaluate(X_test, y_test)\\n   print('Accuracy: %.2f' % (accuracy*100))\\n   ```\\n\\n   Dalam contoh di atas, prestasi model diukur menggunakan ketepatan ('accuracy'). Anda boleh menggunakan metrik yang lain seperti presisi, kitaran semula, atau pecahan pertama jika ianya lebih sesuai dengan tugas anda.\\n\\nPastikan anda mempunyai dataset warna bunga yang mencukupi dan menyesuaikan model dengan keperluan sebenar anda. Jangan lupa untuk melakukan proses preprocessing data seperti normalisasi, pengodean, dan pengambilan ciri-ciri yang sesuai sebelum melatih model RNT ini.\",\n",
       "  'content_ms': \"Tentu! Berikut adalah langkah-langkah yang lebih terperinci dalam proses mencipta Rangkaian Neural Tiruan (RNT) untuk mengkategorikan warna bunga dari input yang diberikan:\\n\\n1. Perkara pertama yang perlu anda lakukan adalah mengimport perpustakaan yang diperlukan:\\n   ```python\\n   import numpy as np\\n   import pandas as pd\\n   from sklearn.model_selection import train_test_split\\n   from sklearn.preprocessing import LabelEncoder\\n   from keras.models import Sequential\\n   from keras.layers import Dense\\n   ```\\n\\n2. Kemudian, anda perlu menyediakan data latihan dan data ujian:\\n   ```python\\n   # Sebagai contoh, anda mempunyai data bunga yang disimpan dalam fail CSV\\n   data = pd.read_csv('nama_fail.csv')\\n\\n   # Pisahkan atribut dan label\\n   X = data.drop('warna', axis=1)\\n   y = data['warna']\\n\\n   # Laporkan label kategori ke dalam nombor\\n   label_encoder = LabelEncoder()\\n   y = label_encoder.fit_transform(y)\\n\\n   # Bahagikan data kepada data latihan dan data ujian\\n   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n   ```\\n\\n3. Selepas itu, mari kita cipta model RNT:\\n   ```python\\n   model = Sequential()\\n   model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\\n   model.add(Dense(4, activation='relu'))\\n   model.add(Dense(1, activation='sigmoid'))\\n   ```\\n\\n   Dalam contoh di atas, model RNT yang tersusun terdiri daripada 3 lapisan keras. Lapisan pertama mempunyai 8 neuron, lapisan kedua mempunyai 4 neuron, dan lapisan output hanya mempunyai 1 neuron. Aktivasi'relu' digunakan untuk lapisan tersembunyi, manakala aktivasi'sigmoid' digunakan untuk lapisan output.\\n\\n4. Selepas itu, kita perlu melatih model menggunakan data latihan:\\n   ```python\\n   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n   model.fit(X_train, y_train, epochs=100, batch_size=10)\\n   ```\\n\\n   Dalam contoh di atas, kami menggunakan fungsi kerugian 'binary_crossentropy' kerana kami hanya mempunyai 2 kategori warna (dua output yang mungkin). Kami juga menggunakan pengoptimum 'adam', tetapi anda boleh menyesuaikan pengoptimum mengikut keperluan anda.\\n\\n5. Akhirnya, kita perlu menilai prestasi model menggunakan data ujian:\\n   ```python\\n   _, accuracy = model.evaluate(X_test, y_test)\\n   print('Accuracy: %.2f' % (accuracy*100))\\n   ```\\n\\n   Dalam contoh di atas, prestasi model diukur menggunakan ketepatan ('accuracy'). Anda boleh menggunakan metrik lain seperti ketepatan, kitaran semula, atau pecahan pertama jika ia lebih sesuai dengan tugas anda.\\n\\nPastikan anda mempunyai set data warna bunga yang mencukupi dan menyesuaikan model dengan keperluan sebenar anda. Jangan lupa untuk melakukan proses prapemprosesan data seperti normalisasi, pengodean, dan pengambilan ciri-ciri yang sesuai sebelum melatih model RNT ini.\",\n",
       "  'indon': False},\n",
       " {'role': 'user',\n",
       "  'content': \"Macam mana perbezaan aktivasi 'relu' dan 'sigmoid' dalam lapisan neural network? Saya ingin memahami kelebihan dan kelemahan mereka.\",\n",
       "  'content_ms': \"Bagaimanakah perbezaan dalam pengaktifan'relu' dan'sigmoid' dalam lapisan rangkaian saraf? Saya ingin memahami kelebihan dan kelemahan mereka.\",\n",
       "  'indon': False},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Aktivasi 'relu' dan 'sigmoid' adalah dua jenis fungsi aktivasi yang sering digunakan dalam lapisan rangkaian neural. Berikut adalah perbezaan dan kelebihan serta kelemahan keduanya:\\n\\n1. ReLU (Rectified Linear Unit):\\n   - Kelebihan: ReLU adalah fungsi aktivasi yang popular dalam rangkaian neural. Ia hanya mengaktifkan neuron jika inputnya adalah positif. Ia memberikan output sejajar dengan input x apabila x adalah positif, dan 0 apabila x adalah negatif. Kelebihan utama ReLU adalah dapat mengatasi masalah kehilangan ketinggian gradien (vanishing gradient) dan bijak dalam masalah optimasi. Fungsi ini juga relatif mudah dihitung yang menjadikannya lebih cepat dalam proses latihan model.\\n   - Kelemahan: Walaupun ReLU berjaya mengatasi masalah kehilangan ketinggian gradien, ia boleh rentan terhadap masalah pergeseran (shift) mati (dead shift) di mana neuron dapat menjadi tidak aktif secara permanen. Dalam kes ini, neuron dengan output negatif tidak akan melakukan apa-apa dan tidak menyumbang kepada pembelajaran model. Oleh itu, perlu berhati-hati dengan reka bentuk dan saiz model untuk mengelakkan masalah ini.\\n\\n2. Sigmoid:\\n   - Kelebihan: Sigmoid adalah fungsi aktivasi yang umum digunakan dalam lapisan terakhir rangkaian neural untuk masalah klasifikasi binari. Ia mengekalkan output dalam julat 0 hingga 1, yang boleh diinterpretasikan sebagai peluang atau probabiliti. Ia juga bisa diinterpretasikan sebagai penghampiran kepada fungsi unit teras (step function) dalam teori logistik. Fungsi sigmoid berguna kerana dapat merepresentasikan pelbagai jenis output dan mendapatkan keputusan yang jelas dalam klasifikasi binari.\\n   - Kelemahan: Walaupun sigmoid mempunyai kelebihan dalam konteks klasifikasi binari, ia mempunyai kelemahan dalam masalah optimasi dan masalah vanishing gradient. Kekurangannya juga termasuk cenderung mengalami kejungcapan (saturation) yang tinggi pada input yang besar atau kecil, yang boleh menghambat pembelajaran rangkaian neural. Tambahan pula, penggunaan sigmoid dalam lapisan tersembunyi rangkaian neural yang dalam dan kompleks boleh menyebabkan masalah lambat dalam pelatihan.\\n\\n\\nDalam kes penentuan aktivasi yang terbaik, ia bergantung kepada permasalahan dan sifat dataset anda. ReLU sering menjadi pendekatan awal yang baik kerana keupayaannya yang baik dalam mempercepatkan proses pembelajaran dan mengatasi masalah kehilangan ketinggian gradien. Bagaimanapun, untuk lapisan output pada masalah klasifikasi binari, Sigmoid adalah pilihan yang lebih sesuai. Jadi, penting untuk menguji dan menyesuaikan fungsi-fungsi aktivasi ini mengikut keperluan dan tuntutan tugas anda.\",\n",
       "  'content_ms': \"Pengaktifan'relu' dan'sigmoid' ialah dua jenis fungsi pengaktifan yang sering digunakan dalam lapisan rangkaian saraf. Berikut adalah perbezaan dan kelebihan dan kelemahan kedua-duanya:\\n\\n1. ReLU (Unit Linear Bertauliah):\\n   - Kelebihan: ReLU ialah fungsi pengaktifan yang popular dalam rangkaian saraf. Ia hanya mengaktifkan neuron jika inputnya positif. Ia memberikan output selari dengan input x apabila x adalah positif, dan 0 apabila x adalah negatif. Kelebihan utama ReLU ialah dapat mengatasi masalah kehilangan ketinggian kecerunan dan bijak dalam masalah pengoptimuman. Fungsi ini juga agak mudah dikira yang menjadikannya lebih cepat dalam proses latihan model.\\n   - Kelemahan: Walaupun ReLU berjaya mengatasi masalah kehilangan ketinggian kecerunan, ia boleh terdedah kepada masalah anjakan mati (anjakan mati) di mana neuron boleh menjadi tidak aktif secara kekal. Dalam kes ini, neuron dengan output negatif tidak akan melakukan apa-apa dan tidak menyumbang kepada pembelajaran model. Oleh itu, perlu berhati-hati dengan reka bentuk dan saiz model untuk mengelakkan masalah ini.\\n\\n2. Sigmoid:\\n   - Kelebihan: Sigmoid ialah fungsi pengaktifan yang biasa digunakan dalam lapisan terakhir rangkaian saraf untuk masalah pengelasan binari. Ia mengekalkan output dalam julat 0 hingga 1, yang boleh ditafsirkan sebagai peluang atau kebarangkalian. Ia juga boleh ditafsirkan sebagai penghampiran kepada fungsi unit teras (fungsi langkah) dalam teori logistik. Fungsi sigmoid berguna kerana ia boleh mewakili pelbagai jenis output dan mendapatkan keputusan yang jelas dalam pengelasan binari.\\n   - Kelemahan: Walaupun sigmoid mempunyai kelebihan dalam konteks pengelasan binari, ia mempunyai kelemahan dalam masalah pengoptimuman dan masalah kecerunan hilang. Kelemahannya juga termasuk cenderung mengalami ketepuan (saturation) yang tinggi pada input yang besar atau kecil, yang boleh menghalang pembelajaran rangkaian saraf. Tambahan pula, penggunaan sigmoid dalam lapisan tersembunyi rangkaian saraf yang dalam dan kompleks boleh menyebabkan masalah perlahan dalam latihan.\\n\\n\\nDalam kes penentuan pengaktifan terbaik, ia bergantung kepada masalah dan sifat set data anda. ReLU sering menjadi pendekatan awal yang baik kerana keupayaannya yang baik dalam mempercepatkan proses pembelajaran dan mengatasi masalah kehilangan ketinggian kecerunan. Walau bagaimanapun, untuk lapisan output pada masalah pengelasan binari, Sigmoid adalah pilihan yang lebih sesuai. Oleh itu, adalah penting untuk menguji dan menyesuaikan fungsi pengaktifan ini mengikut keperluan dan tuntutan tugas anda.\",\n",
       "  'indon': False}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d362ed219440608c71c093ea97a692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ultrachat-glaive_coder_raw_text.jsonl:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='ultrachat-glaive_coder_raw_text.jsonl',\n",
    "    path_in_repo='ultrachat-glaive_coder_raw_text.jsonl',\n",
    "    repo_id='mesolitica/chatgpt-code-instruct-multiturn',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237d3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
