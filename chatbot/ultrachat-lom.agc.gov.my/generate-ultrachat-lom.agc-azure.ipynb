{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a656026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/husein/3.9/lib/python3.9/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/3.9/lib/python3.9/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import malaya\n",
    "from pydantic import BaseModel, Field\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import random\n",
    "\n",
    "minimum_len = 15\n",
    "\n",
    "def simple_cleaning(string):\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(string).replace('\\n', ' ').replace('--', ' ').replace('/', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19099d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = 'azure'\n",
    "openai.api_base = 'https://nous.openai.azure.com/'\n",
    "openai.api_version = '2023-07-01-preview'\n",
    "openai.api_key = ''\n",
    "engine = 'nous-16k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf95259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(messages):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=engine,\n",
    "            messages=messages,\n",
    "            temperature=1.0,\n",
    "            max_tokens=1024,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        return response.choices[0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643b1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'Above is a conversation between a user and an intelligent assistant. You suppose to simulate conversation between the user and the assistant. Bear in mind your major request is to ask the assistant to generate some material. So you can ask the assistant either to make it more detailed, add more related information, or any other request to improve the generated material. Be creative and diverse in your request. Make the response short and the language casual.'\n",
    "system_malay = 'Above is a conversation between a user and an intelligent assistant. You suppose to simulate conversation between the user and the assistant in malay language. Bear in mind your major request is to ask the assistant to generate some material. So you can ask the assistant either to make it more detailed, add more related information, or any other request to improve the generated material. Be creative and diverse in your request. Make the response short and the language casual.'\n",
    "next_step = 'Above is a conversation between a user and an intelligent assistant. Now suppose you are the user, generate response according to the generated material to continue the conversation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15dfd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘ultrachat-lom-agc’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ultrachat-lom-agc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d314931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultrachat(row, n = 1):\n",
    "    results = [\n",
    "        {'role': 'context', 'content': row['paragraph']},\n",
    "        {'role': 'user', 'content': row['question']},\n",
    "    ]\n",
    "    initial = f\"\"\"\n",
    "    {row['paragraph']}\n",
    "\n",
    "    {row['question']}\n",
    "    \"\"\".strip()\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_malay},\n",
    "        {'role': 'user', 'content': initial},\n",
    "    ]\n",
    "    r = predict(messages)\n",
    "    results.append({\n",
    "        'role': 'assistant', 'content': r,\n",
    "    })\n",
    "    messages.append({\n",
    "        'role': 'assistant', 'content': r,\n",
    "    })\n",
    "    \n",
    "    for _ in range(n):\n",
    "    \n",
    "        messages_temp = messages + [\n",
    "            {'role': 'user', 'content': 'Now suppose you are the user, say something to continue the conversation based on given context. Make the response short and the language casual'}\n",
    "        ]\n",
    "        r2 = predict(messages_temp)\n",
    "        if r2 is None:\n",
    "            break\n",
    "\n",
    "        results.append({\n",
    "            'role': 'user', 'content': r2,\n",
    "        })\n",
    "        messages.append({\n",
    "            'role': 'user', 'content': r2,\n",
    "        })\n",
    "\n",
    "        r = predict(messages)\n",
    "        if r is None:\n",
    "            break\n",
    "        results.append({\n",
    "            'role': 'assistant', 'content': r,\n",
    "        })\n",
    "        messages.append({\n",
    "            'role': 'assistant', 'content': r,\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504dda2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = sorted(glob('question-lom-agc/*.json'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f627087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(f):\n",
    "    index = int(os.path.split(f)[1].replace('.json', ''))\n",
    "    filename = f'ultrachat-lom-agc/{index}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "        \n",
    "    with open(f) as fopen:\n",
    "        data = json.load(fopen)\n",
    "    \n",
    "    if len(data['paragraph'].split()) < 100:\n",
    "        return\n",
    "    \n",
    "    r = ultrachat(data, n = random.randint(3, 7))\n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(r, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93714ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(files[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59644a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'context',\n",
       "  'content': '\\n\\nPindaan peraturan 37\\n\\n24. Peraturan 37 Peraturan-Peraturan ibu dipinda dengan menggantikan perkataan\\n\\n“dalam Jadual I dan disertakan dengan bayaran sebanyak dua ratus ringgit dalam\\n\\nbentuk kiriman wang, draf bank, cek atau apa-apa bentuk lain sebagaimana yang\\n\\nditentukan oleh Lembaga, yang kena dibayar kepada Lembaga” dengan perkataan\\n\\n“di laman sesawang Lembaga dan disertakan dengan suatu fi untuk Peperiksaan\\n\\nPenilaian Professional sebagaimana yang dinyatakan dalam Jadual III.”.\\n\\n\\n\\nBahagian baru VIA\\n\\n25. Peraturan-Peraturan ibu dipinda dengan memasukkan selepas Bahagian VI\\n\\nbahagian  yang berikut:   Peperiksaan\\n\\nKompetensi\\n\\nProfesional.\\n\\n“BAHAGIAN  VIA\\n\\nPEPERIKSAAN  KOMPETENSI PROFESIONAL\\n\\n\\n\\n38A. (1)     Jurutera Profesional yang berhasrat untuk berdaftar sebagai\\n\\nJurutera  Profesional dengan Perakuan Amalan di bawah seksyen 10D\\n\\nAkta, hendaklah lulus Peperiksaan Kompetensi Profesional.\\n\\n(2)  Tiap-tiap Jurutera Profesional yang berhasrat untuk\\n\\nmenduduki Peperiksaan Kompetensi Profesional hendaklah\\n\\nmengemukakan kepada Lembaga borang permohonan sebagaimana\\n\\nyang ditetapkan di laman sesawang Lembaga dan disertakan dengan fi\\n\\nuntuk Peperiksaan Kompetensi Profesional sebagaimana yang\\n\\ndinyatakan dalam Jadual III.”.\\n\\n\\n\\nPemotongan Jadual I\\n\\n26. Peraturan-Peraturan ibu dipinda dengan  memotong Jadual I.\\n\\n\\n\\nPenggantian Jadual II\\n\\n27. Peraturan-Peraturan ibu dipinda dengan menggantikan Jadual II dengan Jadual\\n\\nyang berikut:P.U. (A) 173\\n\\n15\\n\\n“JADUAL  II\\n\\nAKTA PENDAFTARAN JURUTERA 1967\\n\\nPERATURAN-PERATURN PENDAFTARAN JURUTERA 1990 \\n(Peraturan  18, 20, 21, 34 dan 36)\\n\\nFI UNTUK PEMPROSESAN, PENDAFTARAN, PEMBAHARUAN\\n\\nDAN PEMASUKAN SEMULA PENDAFTARAN\\n\\nFi   Pemprosesan\\n\\nFi   Pendaftaran\\n\\nFi   Pembaharuan\\n\\nTarikh \\nPembaharuan\\n\\npendaftaran bagi \\nsetiap bulan\\n\\nFi   Pemasukan Semula\\n\\n\\n\\nJurutera Siswazah\\n\\n\\n\\nRM50.00 Tidak berkenaan Tidak berkenaan Tidak berkenaan Tidak berkenaan\\n\\nTeknologis \\nKejuruteraan\\n\\n\\n\\nRM50.00 Tidak berkenaan Tidak berkenaan Tidak berkenaan Tidak berkenaan\\n\\nPemeriksa Tapak\\n\\n\\n\\nRM50.00   ** RM50.00   RM30.00\\n\\n\\n\\n31 Januari bagi  \\ntahun ketiga\\n\\nberikutan tahun \\npendaftaran tamat\\n\\ntempoh\\n\\nRM180.00   Jurutera \\nProfesional\\n\\nRM50.00 ** RM300.00 RM200.00 (Umur \\nbawah 60 tahun )\\n\\n31 Januari bagi \\ntahun berikutan\\n\\ntahun pendaftaran \\ntamat tempoh\\n\\nRM1,250.00\\n\\n\\n\\nRM100.00 (Umur  \\n60 tahun dan\\n\\nke atas)\\n\\n\\n\\nRM1,150.00\\n\\nJurutera \\nProfesional dengan \\nPerakuan Amalan\\n\\nRM50.00 ** RM200.00 RM400.00   31 Januari bagi \\ntahun berikutan\\n\\ntahun pendaftaran \\ntamat tempoh\\n\\nRM1,450.00\\n\\nPemeriksa \\nBertauliah\\n\\nRM50.00 ** RM200.00 RM200.00 (Umur \\nbawah 60 tahun)\\n\\n31 Januari bagi\\n\\ntahun berikutan \\ntahun pendaftaran\\n\\ntamat tempoh\\n\\nRM1,250.00   RM100.00 (Umur  \\n60 tahun dan\\n\\nke atas)\\n\\n\\n\\nRM1,150.00\\n\\nAmalan \\nPerundingan \\nKejuruteraan\\n\\n\\uf0b7 Pertubuhan'},\n",
       " {'role': 'user',\n",
       "  'content': 'Apakah pindaan yang dibuat dalam Peraturan 37 mengenai bayaran untuk Peperiksaan Penilaian Professional?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Pada pindaan Peraturan 37, perubahan yang telah dibuat adalah menggantikan perkataan \"dalam Jadual I dan disertakan dengan bayaran sebanyak dua ratus ringgit dalam bentuk kiriman wang, draf bank, cek atau apa-apa bentuk lain sebagaimana yang ditentukan oleh Lembaga, yang kena dibayar kepada Lembaga\" dengan perkataan \"di laman sesawang Lembaga dan disertakan dengan suatu fi untuk Peperiksaan Penilaian Professional sebagaimana yang dinyatakan dalam Jadual III\". Jadi, bayaran untuk Peperiksaan Penilaian Professional akan dilakukan melalui laman sesawang Lembaga dan dinyatakan dalam Jadual III. Apakah ada yang lagi ingin ditanyakan?'},\n",
       " {'role': 'user',\n",
       "  'content': 'Macam mana saya boleh mendapatkan maklumat lanjut berkenaan bayaran untuk Peperiksaan Penilaian Professional yang dinyatakan dalam Jadual III?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Untuk mendapatkan maklumat lanjut berkenaan bayaran untuk Peperiksaan Penilaian Professional yang dinyatakan dalam Jadual III, anda boleh mengunjungi laman sesawang Lembaga. Di laman sesawang tersebut, anda akan dapat menemui butiran terkini mengenai bayaran yang perlu dibuat serta prosedur pembayaran yang diperlukan. Jika terdapat sebarang kekeliruan atau ketidakjelasan, anda juga boleh menghubungi Lembaga untuk mendapatkan penjelasan yang lebih terperinci. Semoga berjaya dalam perjalanan profesional anda!'},\n",
       " {'role': 'user',\n",
       "  'content': 'Okay, terima kasih atas maklumatnya. Saya akan melawat laman sesawang Lembaga untuk mendapatkan butiran lanjut tentang bayaran Peperiksaan Penilaian Professional. Sekiranya saya mempunyai sebarang soalan, saya akan menghubungi Lembaga.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Sama-sama! Semoga laman sesawang Lembaga memberikan anda maklumat yang diperlukan dan menjawab segala soalan yang anda ada. Jika terdapat sebarang keperluan lain atau pertanyaan tambahan, jangan ragu untuk menghubungi Lembaga. Mereka akan dengan senang hati membantu anda. Semoga berjaya dalam persediaan dan pencapaian dalam Peperiksaan Penilaian Professional!'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ultrachat-lom-agc/997.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb010ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████                           | 1045/4160 [17:32<35:14:34, 40.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████▋                          | 1122/4160 [59:50<28:11:34, 33.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████▊                    | 1690/4160 [5:52:31<16:36:03, 24.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████                    | 1714/4160 [6:01:06<17:46:53, 26.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|██████████████                    | 1715/4160 [6:01:09<13:01:30, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████▌                   | 1787/4160 [6:34:21<24:46:42, 37.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████▉                  | 1948/4160 [7:57:14<24:46:40, 40.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████▌                 | 2034/4160 [8:37:43<16:14:54, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████▊                 | 2062/4160 [8:51:20<19:04:55, 32.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████                | 2208/4160 [9:56:29<11:54:07, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████▌             | 2460/4160 [12:03:34<13:08:13, 27.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████▋             | 2486/4160 [12:15:24<11:07:35, 23.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████▍            | 2569/4160 [12:58:09<14:12:35, 32.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████▍            | 2576/4160 [13:00:55<10:55:35, 24.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████             | 2577/4160 [13:00:57<7:55:26, 18.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████▍            | 2583/4160 [13:03:55<10:58:49, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████▊           | 2753/4160 [14:31:41<11:00:03, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████▊           | 2755/4160 [14:32:36<10:49:15, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████▎        | 3100/4160 [16:58:31<7:30:25, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████▍        | 3109/4160 [17:01:31<6:16:38, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████▍        | 3119/4160 [17:05:19<6:28:39, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████     | 3552/4160 [20:15:42<3:13:23, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████▍    | 3599/4160 [20:31:10<3:06:01, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████▌   | 3746/4160 [21:22:54<2:08:59, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████▋   | 3754/4160 [21:26:03<2:35:55, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████▏  | 3815/4160 [21:47:10<1:59:51, 20.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████▍  | 3854/4160 [22:01:20<2:05:48, 24.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████▋  | 3884/4160 [22:15:09<2:04:05, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████  | 3917/4160 [22:31:22<1:48:29, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████▎ | 3943/4160 [22:52:37<12:26:45, 206.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out: HTTPSConnectionPool(host='nous.openai.azure.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████▍ | 3974/4160 [23:08:29<1:53:46, 36.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████▋ | 4002/4160 [23:22:22<1:17:22, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 4160/4160 [24:39:18<00:00, 21.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_worker = 2\n",
    "for i in tqdm(range(0, len(files), max_worker)):\n",
    "    b = files[i: i + max_worker]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate, f): f for f in b}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9",
   "language": "python",
   "name": "3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
