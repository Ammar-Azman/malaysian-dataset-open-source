{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a656026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/husein/3.9/lib/python3.9/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/3.9/lib/python3.9/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import malaya\n",
    "from pydantic import BaseModel, Field\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import random\n",
    "\n",
    "minimum_len = 15\n",
    "\n",
    "def simple_cleaning(string):\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(string).replace('\\n', ' ').replace('--', ' ').replace('/', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19099d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://husein-ai7-aiservices-435901645.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = ''\n",
    "engine = 'gpt-35-turbo-16k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf95259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(messages):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=engine,\n",
    "            messages=messages,\n",
    "            temperature=1.0,\n",
    "            max_tokens=1024,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        return response.choices[0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643b1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'Above is a conversation between a user and an intelligent assistant. You suppose to simulate conversation between the user and the assistant. Bear in mind your major request is to ask the assistant to generate some material. So you can ask the assistant either to make it more detailed, add more related information, or any other request to improve the generated material. Be creative and diverse in your request. Make the response short and the language casual.'\n",
    "system_malay = 'Above is a conversation between a user and an intelligent assistant. You suppose to simulate conversation between the user and the assistant in malay language. Bear in mind your major request is to ask the assistant to generate some material. So you can ask the assistant either to make it more detailed, add more related information, or any other request to improve the generated material. Be creative and diverse in your request. Make the response short and the language casual.'\n",
    "next_step = 'Above is a conversation between a user and an intelligent assistant. Now suppose you are the user, generate response according to the generated material to continue the conversation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ultrachat-muftiwp.gov.my\n",
    "# !rm ultrachat-maktabahalbakri.com/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d314931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultrachat(row, n = 1):\n",
    "    if row['question'].lower().startswith('soalan:'):\n",
    "        question = row['question'].split(':')[1:]\n",
    "        question = ':'.join(question).strip()\n",
    "    else:\n",
    "        question = row['question']\n",
    "        \n",
    "    results = [\n",
    "        {'role': 'context', 'content': row['paragraph']},\n",
    "        {'role': 'user', 'content': question},\n",
    "    ]\n",
    "    if row['question'] is None:\n",
    "        return\n",
    "    \n",
    "    initial = f\"\"\"\n",
    "    {row['paragraph']}\n",
    "\n",
    "    {row['question']}\n",
    "    \"\"\".strip()\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_malay},\n",
    "        {'role': 'user', 'content': initial + ', jawab dalam bahasa melayu'},\n",
    "    ]\n",
    "    r = predict(messages)\n",
    "    results.append({\n",
    "        'role': 'assistant', 'content': r,\n",
    "    })\n",
    "    messages.append({\n",
    "        'role': 'assistant', 'content': r,\n",
    "    })\n",
    "    \n",
    "    for _ in range(n):\n",
    "    \n",
    "        messages_temp = messages + [\n",
    "            {'role': 'user', 'content': 'Now suppose you are the user and you dont really understand, so say something in malay related to islam fiqh to continue the conversation based on given context.'}\n",
    "        ]\n",
    "        r2 = predict(messages_temp)\n",
    "        if r2 is None:\n",
    "            break\n",
    "\n",
    "        results.append({\n",
    "            'role': 'user', 'content': r2,\n",
    "        })\n",
    "        messages.append({\n",
    "            'role': 'user', 'content': r2 + ', jawab dalam bahasa melayu',\n",
    "        })\n",
    "\n",
    "        r = predict(messages)\n",
    "        if r is None:\n",
    "            break\n",
    "        results.append({\n",
    "            'role': 'assistant', 'content': r,\n",
    "        })\n",
    "        messages.append({\n",
    "            'role': 'assistant', 'content': r,\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504dda2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3885"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = sorted(glob('question-muftiwp.gov.my/*.json'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f627087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(f):\n",
    "    index = int(os.path.split(f)[1].replace('.json', ''))\n",
    "    filename = f'ultrachat-muftiwp.gov.my/{index}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "        \n",
    "    with open(f) as fopen:\n",
    "        data = json.load(fopen)\n",
    "    \n",
    "    try:\n",
    "        r = ultrachat(data, n = random.randint(1, 5))\n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(r, fopen)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93714ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb010ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████        | 258/324 [2:16:21<34:33, 31.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████    | 289/324 [2:42:18<2:02:33, 210.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out: HTTPSConnectionPool(host='husein-ai7-aiservices-435901645.openai.azure.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████▏   | 292/324 [2:43:41<47:11, 88.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "Invalid value for 'content': expected a string, got null.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 324/324 [2:57:09<00:00, 32.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_worker = 3\n",
    "for i in tqdm(range((len(files) // 4) * 0, (len(files) // 4) * 1, max_worker)):\n",
    "    b = files[i: i + max_worker]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate, f): f for f in b}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef537045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9",
   "language": "python",
   "name": "3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
