{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ac9d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/crawl-my-website/resolve/main/muftiwp.gov.my.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37427739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import malaya\n",
    "from pydantic import BaseModel, Field\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "minimum_len = 15\n",
    "\n",
    "def simple_cleaning(string):\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(string).replace('\\n', ' ').replace('--', ' ').replace('/', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec8bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = 'azure'\n",
    "openai.api_base = \"https://husein-ai2-aiservices.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53354d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=\"gpt-35-turbo-16k\",\n",
    "            messages=messages,\n",
    "            temperature=1.0,\n",
    "            max_tokens=1024,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "        return response.choices[0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5020de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3885"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open('muftiwp.gov.my.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        data.append({\n",
    "            'paragraph': json.loads(l)['body']\n",
    "        })\n",
    "        \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12e45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir question-muftiwp.gov.my\n",
    "# !rm question-maktabahalbakri.com/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12bd1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(filename, l):\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    s = f\"\"\"\n",
    "{l['paragraph']}\n",
    "\n",
    "anda adalah seorang pelajar yang kurang faham tentang konteks diatas, generate one question in malay based on context above\n",
    "\"\"\"\n",
    "    s = s.strip()\n",
    "    r = predict(s)\n",
    "    l['question'] = r\n",
    "\n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(l, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ea4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate('question-muftiwp.gov.my/0.json', data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a061fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paragraph': 'Soalan:\\nAssalamualaikum, saya ingin bertanyakan satu soalan. Apakah hukum menjual beli haiwan yang haram dimakan? Mohon penjelasan Datuk Mufti. Terima kasih.\\nJawapan Ringkas\\nHukum jual beli binatang yang haram dimakan adalah sah sekiranya terdapat manfaat lain seperti digunakan untuk tujuan perubatan, berburu, mengawal harta benda, dan dijadikan tunggangan, selama mana ia tidak menyalahi syarat sah jual beli yang lain. Sekiranya binatang itu tidak melepasi syarat sah jual beli iaitu tidak suci seperti babi dan anjing, tidak boleh dimanfaatkan seperti binatang buas dan binatang perosak, tidak dapat diserahkan kepada pembeli seperti burung yang terbang bebas dan tidak diketahui kondisinya, maka jual beli menjadi haram dan tidak sah.\\nHuraian \\nAlhamdulillah, segala puji bagi Allah SWT, selawat dan salam kepada junjungan besar Nabi Muhammad SAW, ahli keluarga Baginda SAW, sahabat Baginda SAW serta orang-orang yang mengikuti jejak langkah Baginda SAW.\\nSebagaimana maklum, perbuatan jual beli pada asalnya adalah harus selagi mana ia tidak mempunyai unsur-unsur yang bertentangan dengan syariat Islam. Dalam melakukan transaksi jual beli, terdapat beberapa rukun tertentu dan setiap rukun mempunyai syarat-syaratnya yang wajib ditepati agar akad yang dilakukan itu sah di sisi syarak. Sekiranya salah satu rukun dan syarat jual beli itu tidak dipenuhi, maka terbatal dan tidak sah akad jual beli.\\nAntara rukun jual beli ialah al-ma’qud alaih atau barang jualan. Islam mensyaratkan lima perkara bagi barang jualan untuk menjadikan jualan itu sah[1]:\\n\\nHendaklah barang itu suci dan bukan najis.\\nHendaklah barang itu bermanfaat.\\nHendaklah barang itu boleh diserahkan kepada pembeli.\\nHendaklah barang itu dimiliki oleh penjual.\\nHendaklah diketahui jenis, kadar dan sifatnya oleh pembeli dan penjual.\\n\\nBerdasarkan syarat-syarat ini, telah jelas bahawa barangan yang ingin diperjualbelikan wajib mempunyai manfaat atau boleh dimanfaatkan mengikut syarak. Merujuk kepada persoalan, binatang yang haram dimakan semestinya tidak dapat dimanfaatkan melalui pemakanan. Namun begitu, manfaat tidak terhad kepada pemakanan sahaja, bahkan terdapat binatang yang dimanfaatkan untuk tujuan perubatan, berburu, memetik buah dan sebagainya.\\nMenurut Imam al-Syafi’i, setiap binatang buas yang tiada manfaat padanya seperti helang, burung hering, gagak putih dan kesemua binatang yang tidak halal dimakan dan tidak boleh digunakan untuk berburu seperti tikus, adalah haram dijual beli sama ada dalam keadaan hidup atau sudah mati dan tidak dikenakan bayaran ganti rugi ke atas orang yang membunuhnya[2].\\nImam al-Syirazi berkata:\\nما لا منفعة فيه فهو كالحشرات والسباع التي لا تصلح للاصطياد والطيور التي لا تؤكل ولا تصطاد كالرخمة والحدأة وما يؤكل من الغراب فلا يجوز بيعه لأن ما لا منفعة فيه لا قيمة له فأخذ العوض عنه من أكل المال بالباطل\\nMaksudnya: “Sesuatu yang tiada manfaat padanya seperti serangga, binatang buas yang tidak boleh digunakan untuk berburu, burung yang tidak halal dimakan dan tidak dapat digunakan untuk berburu seperti burung hering Mesir, helang, dan jenis burung gagak yang tidak boleh dimakan, maka haram diperniagakan. Hal ini kerana sesuatu yang tiada manfaat adalah tidak bernilai. Justeru, mengambil hasil jualan daripadanya termasuk dalam memakan harta secara batil.”[3]\\nMenurut Imam al-Mawardi dalam kitabnya al-Hawi al-Kabir, binatang yang suci terbahagi kepada dua kategori[4]:\\n\\nBinatang yang halal dimakan. Jual beli binatang dalam kategori ini adalah dibenarkan sama ada ia hidup ataupun telah disembelih. Namun begitu, sekiranya binatang tersebut menjadi bangkai yang tidak disembelih, maka hukum jual belinya adalah haram kecuali pada hidupan laut dan belalang.\\nBinatang yang tidak halal dimakan. Ia terbahagi kepada dua jenis:\\nBinatang yang boleh dimanfaatkan seperti baghal, keldai, harimau bintang, harimau yang boleh dilatih berburu dan seumpamanya. Hukum jual beli binatang seperti ini adalah harus dijual beli ketika ia masih hidup namun haram sekiranya sudah mati.\\nBinatang yang tiada manfaat seperti ular, kala jengking, serangga perosak, binatang yang melata dan binatang-binatang buas atau liar. Menjual beli binatang jenis ini adalah tidak dibenarkan malah hasil pendapatan juga menjadi tidak sah kerana tiada sebarang manfaat padanya seperti tidak dapat dilatih, diajar membuat sesuatu, tidak dapat dijadikan tunggangan dan sebagainya.\\n\\nSelain itu, Imam al-Nawawi turut menjelaskan bahawa burung yang boleh dimakan dagingnya seperti merpati atau puyuh dan yang dijual beli kerana keistimewaan warna dan bunyinya seperti burung merak dan burung starling, adalah termasuk dalam kategori binatang yang boleh dimanfaatkan dan sah diperniagakan[5]. Begitu juga sah jual beli binatang dengan tujuan memanfaatkan kulitnya namun hanya dibenarkan setelah ia mati dan bukan semasa hidup[6].\\nTerdapat juga binatang yang memberi manfaat selainnya seperti lebah yang diambil madunya, lintah untuk tujuan perubatan (menghisap darah orang yang sakit) dan juga cengkerik untuk memancing ikan.\\nKesimpulannya, hukum jual beli binatang yang haram dimakan adalah sah sekiranya terdapat manfaat lain padanya seperti digunakan untuk tujuan perubatan, berburu, mengawal harta benda, dijadikan tunggangan, membuat sesuatu kerja dan berseronok dengan keindahan warna dan bunyinya selama mana ia tidak menyalahi syarat sah jual beli yang lain. Sekiranya binatang itu tidak melepasi syarat sah jual beli iaitu tidak suci seperti babi dan anjing, tidak boleh dimanfaatkan, tidak dapat diserahkan kepada pembeli seperti burung yang terbang bebas dan tidak diketahui kondisinya, maka jual beli menjadi haram dan tidak sah.\\nWallahua’lam\\n\\nRujukan:\\n[1] Hasan bin Ahmad bin Muhammad al-Kaf, al-Taqrirat al-Sadidah Qism al-Buyu’, (Riyadh: Dar al-Mirath al-Nabawi, 1, 1434H – 2013M), 14\\nRujuk: Abdul Aziz bin Juned, Isu-isu Kewangan 2, (Seri Begawan: Brunei Press, 1, 2022M), 4\\n[2] Muhammad bin Idris al-Syafi’i, al-Umm, (Beirut: Dar al-Fikr, 2, 1403H – 1973M), 3:12\\nوكل ما لا منفعة فيه من وحش مثل الحدأة والرخمة والبغاثة وما لا يصيد من الطير الذي لا يؤكل لحمه ومثل اللحكة والقطا والخنافس وما أشبه هذا فأرى والله تعالى أعلم أن لا يجوز شراؤه ولا بيعه بدين ولا غيره، ولا يكون على أحد لو حبسه رجل عنده فقتله رجل له قيمة وكذلك الفأر والجرذان والوزغان؛ لأنه لا معنى للمنفعة فيه حيا ولا مذبوحا ولا ميتا فإذا اشترى هذا أشبه أن يكون أكل المال بالباطل\\n[3] Ibrahim bin Ali bin Yusuf al-Syirazi, al-Muhazzab fi Fiqh al-Imam al-Syafi’i, (Beirut: Dar Kutub al-Ilmiah), 2:11\\n[4] Ali bin Muhammad al-Mawardi, al-Hawi al-Kabir, (Beirut: Dar al-Kutub al-Ilmiyyah, 1, 1419H – 1999M), 5: 382\\nالطاهر فضربان: مأكول وغير مأكول. فأما المأكول فيجوز بيعه حيا ومذبوحا، ولا يجوز بيعه ميتا إلا الحوت والجراد. وأما غير المأكول: فضربان: منتفع به وغير منتفع به. فما كان منتفعا به كالبغل والحمار والفهد والنمر فبيعه حيا جائز، ولا يجوز بيعه غير حي.\\nوأما غير المنتفع به فضربان: أحدهما: ما لا يرجى نفعه أبدا كالسبع والذئب والحية والعقرب وسائر الهوام والحشرات فبيعه باطل لأن بيعه مع عدم المنفعة فيه من أكل المال بالباطل.\\n[5] Yahya bin Syaraf al-Nawawi, Raudah al-Talibin wa ‘Umdah al-Muftin, (Beirut: al-Maktab al-Islamiy, 3, 1416H – 1991M), 3: 352\\nوالحيوان الطاهر، ضربان: ضرب ينتفع به، فيجوز بيعه، كالنعم، والخيل، والبغال، والحمير، والظباء، والغزلان. ومن الجوارح، كالصقور، والبزاة، والفهد. ومن الطير، كالحمام، والعصفور، والعقاب. وما ينتفع بلونه كالطاووس، أو صوته كالزرزور.\\n[6] Ibid, 3:353\\nيجوز لغرض جلده إذا مات', 'question': 'Soalan: Adakah semua binatang yang haram dimakan juga haram untuk dijual beli?'}\n"
     ]
    }
   ],
   "source": [
    "with open('question-muftiwp.gov.my/0.json') as fopen:\n",
    "    print(json.load(fopen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832ffcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                       | 40/1295 [01:46<57:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                      | 91/1295 [04:08<59:12,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                    | 95/1295 [04:23<1:08:58,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▉                                   | 101/1295 [04:40<1:00:49,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▎                                  | 112/1295 [05:16<1:05:29,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▉                                 | 167/1295 [08:34<1:14:17,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                  | 183/1295 [09:25<53:57,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▉                                | 258/1295 [13:02<53:16,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▌                               | 277/1295 [13:57<54:37,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▋                            | 380/1295 [19:01<52:44,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▎                         | 419/1295 [21:53<1:13:58,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▏                         | 458/1295 [23:42<47:56,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▎                         | 462/1295 [23:53<42:17,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▎                         | 463/1295 [23:56<41:13,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▌                         | 473/1295 [24:28<45:44,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████▍                        | 499/1295 [25:45<35:43,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████▍                        | 501/1295 [25:51<36:02,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████▍                       | 534/1295 [27:21<32:14,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▉                       | 547/1295 [27:57<35:40,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▍                      | 566/1295 [28:50<33:45,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████                      | 586/1295 [29:44<28:59,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████▍                    | 630/1295 [31:40<28:53,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████▌                    | 635/1295 [31:52<26:16,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████▊                  | 706/1295 [34:54<23:51,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▎              | 821/1295 [39:31<18:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████           | 939/1295 [44:23<15:28,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████           | 942/1295 [44:30<14:53,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████▌          | 959/1295 [45:14<13:14,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▌     | 1116/1295 [52:13<07:30,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▉    | 1159/1295 [53:53<04:51,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 23381 tokens. Please reduce the length of the messages.\n",
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████▍  | 1210/1295 [56:07<04:08,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████▊  | 1224/1295 [56:44<03:20,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 21488 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████  | 1230/1295 [57:02<03:08,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 16427 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████▏ | 1235/1295 [57:17<03:01,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 30610 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████▏ | 1236/1295 [57:21<03:08,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 16584 tokens. Please reduce the length of the messages.\n",
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 23676 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▎ | 1238/1295 [57:26<02:47,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 17452 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▎ | 1241/1295 [57:36<02:56,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, you requested 17265 tokens (16241 in the messages, 1024 in the completion). Please reduce the length of the messages or completion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▍ | 1243/1295 [57:42<02:40,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 21563 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▍ | 1244/1295 [57:46<02:49,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 19325 tokens. Please reduce the length of the messages.\n",
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 18431 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▌ | 1246/1295 [57:51<02:25,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 19363 tokens. Please reduce the length of the messages.\n",
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 18390 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▌ | 1247/1295 [57:53<02:07,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 27907 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▌ | 1248/1295 [57:56<02:04,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 17199 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████▊ | 1255/1295 [58:15<01:44,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████▉ | 1260/1295 [58:29<01:45,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████▏| 1268/1295 [58:55<01:24,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████▎| 1271/1295 [59:03<01:09,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, your messages resulted in 17621 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████▉| 1293/1295 [1:00:04<00:06,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16384 tokens. However, you requested 16996 tokens (15972 in the messages, 1024 in the completion). Please reduce the length of the messages or completion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1295/1295 [1:00:09<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_worker = 3\n",
    "for i in tqdm(range(0, len(data), max_worker)):\n",
    "    b = data[i: i + max_worker]\n",
    "    filenames = [(os.path.join('question-muftiwp.gov.my', f'{i + k}.json'), l) for k, l in enumerate(b)]\n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate, *f): f for f in filenames}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f04bd933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3885"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "len(glob('question-muftiwp.gov.my/*'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
