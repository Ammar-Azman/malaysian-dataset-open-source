{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfe23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install transformers msgspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad79387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import msgspec\n",
    "import json\n",
    "import re\n",
    "\n",
    "http_errors = [\n",
    "        \"400 Bad Request\", \"401 Unauthorized\", \"402 Payment Required\", \"403 Forbidden\", \"404 Not Found\",\n",
    "        \"405 Method Not Allowed\", \"406 Not Acceptable\", \"407 Proxy Authentication Required\", \"408 Request Timeout\",\n",
    "        \"409 Conflict\", \"410 Gone\", \"411 Length Required\", \"412 Precondition Failed\", \"413 Payload Too Large\",\n",
    "        \"414 URI Too Long\", \"415 Unsupported Media Type\", \"416 Range Not Satisfiable\", \"417 Expectation Failed\",\n",
    "        \"418 I'm a teapot\", \"421 Misdirected Request\", \"422 Unprocessable Entity\", \"423 Locked\", \"424 Failed Dependency\",\n",
    "        \"425 Too Early\", \"426 Upgrade Required\", \"428 Precondition Required\", \"429 Too Many Requests\",\n",
    "        \"431 Request Header Fields Too Large\", \"451 Unavailable For Legal Reasons\", \"500 Internal Server Error\",\n",
    "        \"501 Not Implemented\", \"502 Bad Gateway\", \"503 Service Unavailable\", \"504 Gateway Timeout\",\n",
    "        \"505 HTTP Version Not Supported\", \"506 Variant Also Negotiates\", \"507 Insufficient Storage\",\n",
    "        \"508 Loop Detected\", \"510 Not Extended\", \"511 Network Authentication Required\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2128386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected = [\n",
    "    'Internal Server Error',\n",
    "    '__NOEDITSECTION__',\n",
    "    'enter your username and password',\n",
    "    'forgotten your password',\n",
    "    'cookies enabled',\n",
    "    'enable JavaScript in your browser.',\n",
    "    'The page cannot be displayed',\n",
    "    'site or edit the error_page',\n",
    "    'Request unsuccessful',\n",
    "]\n",
    "\n",
    "rejected.extend(http_errors)\n",
    "\n",
    "def replace_multiple(input_string, pattern =r\"\\s{6,}\", replace = '   '):\n",
    "    return re.sub(pattern, replace, input_string)\n",
    "\n",
    "def replace(string):\n",
    "    string = replace_multiple(string.replace('â€¦', '.'))\n",
    "    string = replace_multiple(string, pattern = r\"\\.{6,}\", replace = '...')\n",
    "    return string\n",
    "\n",
    "def reject(string):\n",
    "    if any([r in string for r in rejected]):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d008f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(text, size = 500):\n",
    "    splitted = text.split()\n",
    "    return [' '.join(splitted[i: i + size]) for i in range(0, len(splitted), size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad491dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('/home/ubuntu/dedup-text-dataset/*.jsonl')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d118a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = [\n",
    "    'wikipedia-2023-10-01.jsonl',\n",
    "    'wikipedia-jawi.jsonl',\n",
    "    'wikipedia-20230901.en.filtered.jsonl',\n",
    "]\n",
    "language_related = [\n",
    "    'dictionary.jsonl',\n",
    "    'dewanbahasa-jdbp.jsonl',\n",
    "    'dialect.jsonl',\n",
    "    'kamusbm.jsonl',\n",
    "    'wiktionary-bahasa.jsonl',\n",
    "]\n",
    "gov_related = [\n",
    "    'hansard.jsonl',\n",
    "    'lom.agc.gov.my.jsonl',\n",
    "    'parlimen-gov.jsonl',\n",
    "    'data.gov.my.jsonl',\n",
    "    'mufti_wilayah_articles.jsonl',\n",
    "    'e-khutbah.jsonl',\n",
    "    'mufti_negeri_sem_artikel.jsonl',\n",
    "    'mufti_perlis_artikel.jsonl',\n",
    "    'mufti_negeri_sem_artikel.jsonl',\n",
    "    'gov.my.jsonl',\n",
    "    'edu.my.jsonl',\n",
    "]\n",
    "research_papers = [\n",
    "    'academia-edu.jsonl',\n",
    "    'eprints.jsonl',\n",
    "]\n",
    "social_media = [\n",
    "    'iium-confession.jsonl',\n",
    "    'b.cari.com.my.jsonl',\n",
    "    'semisupervised-whisper-large-v2.jsonl',\n",
    "    'lowyat.jsonl',\n",
    "    'malay-tweets.jsonl',\n",
    "    'c.cari.com.my.jsonl',\n",
    "    'cn.cari.com.my.jsonl',\n",
    "    'carigold.jsonl',\n",
    "    'cc-100.jsonl',\n",
    "    'salary-sg.jsonl'\n",
    "]\n",
    "common_crawl = [\n",
    "    'common-crawl.jsonl',\n",
    "    'NLLB.jsonl',\n",
    "]\n",
    "buku_teks = [\n",
    "    'buku-teks.jsonl',\n",
    "    'bumigemilang.com.jsonl',\n",
    "    'tcer.my.jsonl',\n",
    "    'mysoalan.com.jsonl'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b80e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = set(wiki) | set(language_related) | set(gov_related) | set(research_papers) | set(common_crawl) | set(buku_teks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f3fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = {os.path.join('/home/ubuntu/dedup-text-dataset', f) for f in combine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c71a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_articles = sorted(list(set(files) - combine))\n",
    "len(online_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2744ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected = social_media + common_crawl + [\n",
    "    'pdfdrive.jsonl',\n",
    "    'hardwarezone-sg.jsonl',\n",
    "    'sinchew.com.my.jsonl',\n",
    "    'orientaldaily.com.my.jsonl',\n",
    "    'cc-100',\n",
    "    'news.jsonl'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc37b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_articles = [x for x in online_articles if 'c4-filtered' not in x and 'the-pile' not in x and 'c.cari.com.my' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e893115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_articles = [x for x in online_articles if all([r not in x for r in rejected])]\n",
    "len(online_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27130a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 2048\n",
    "\n",
    "def partition(text, size = 500):\n",
    "    splitted = text.split()\n",
    "    return [' '.join(splitted[i: i + size]) for i in range(0, len(splitted), size)]\n",
    "\n",
    "def read_dataset(tokenizer, train_file, block_size = block_size):\n",
    "    temp = []\n",
    "    \n",
    "    if os.path.exists(train_file) and (os.stat(train_file).st_size / 1024 ** 2) > 1:\n",
    "        return\n",
    "    \n",
    "    with open(f'{train_file}.tokenized', 'w') as fopen_l:\n",
    "        with open(train_file) as fopen:\n",
    "            for l in tqdm(fopen):\n",
    "                l = msgspec.json.decode(l)\n",
    "                partitioned = partition(l)\n",
    "                for p in partitioned:\n",
    "                    tokenized = tokenizer(p)['input_ids']\n",
    "                    temp.extend(tokenized)\n",
    "                    while len(temp) >= block_size:\n",
    "                        block = temp[:block_size]\n",
    "                        temp = temp[block_size:]\n",
    "                        if len(block) == block_size:\n",
    "                            s = tokenizer.decode(block)\n",
    "                            fopen_l.write(f'{json.dumps(s)}\\n')\n",
    "                            fopen_l.flush()\n",
    "                        \n",
    "def loop(files):\n",
    "    files, _ = files\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
    "    )\n",
    "    tokenizer.add_bos_token = False\n",
    "    tokenizer.add_eos_token = False\n",
    "    for f in files:\n",
    "        read_dataset(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc092975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/huseinzol05/98974ae8c6c7a65d4bc0af9f5003786a/raw/2e06e71ef7349a57bc58cc9913ae6bae1f9f8447/mp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9381d751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.75it/s]/s]\n",
      "4it [00:00, 39.72it/s]s]\n",
      "68it [00:00, 420.27it/s]s]\n",
      "40it [00:00, 184.06it/s]]]\n",
      "56it [00:00, 169.91it/s]/s]\n",
      "46it [00:00, 146.59it/s]\n",
      "172it [00:00, 503.91it/s]\n",
      "1362it [00:00, 4315.99it/s]\n",
      "43it [00:00, 108.65it/s]\n",
      "70it [00:00, 199.58it/s]s]\n",
      "\n",
      "70it [00:00, 176.62it/s]\n",
      "91it [00:00, 218.49it/s]\n",
      "48it [00:00, 126.30it/s]]\n",
      "12it [00:00, 25.34it/s]]/s]\n",
      "42it [00:00, 205.58it/s]\n",
      "58it [00:00, 98.06it/s]s]s]\n",
      "24it [00:00, 95.78it/s]]\n",
      "15it [00:00, 43.56it/s]s]s]\n",
      "140it [00:00, 248.67it/s]s]\n",
      "84it [00:00, 91.67it/s]s]s]\n",
      "168it [00:01, 148.28it/s]s]\n",
      "297it [00:01, 233.21it/s]s]\n",
      "118it [00:01, 81.74it/s]]\n",
      "233it [00:01, 147.74it/s]s]\n",
      "276it [00:01, 173.21it/s]\n",
      "19it [00:00, 188.81it/s]]s]\n",
      "216it [00:01, 129.91it/s]\n",
      "54it [00:01, 33.67it/s]\n",
      "473it [00:01, 368.28it/s]]]\n",
      "8593it [00:01, 4837.27it/s]\n",
      "48it [00:00, 174.96it/s]\n",
      "65it [00:01, 44.77it/s]\n",
      "151it [00:01, 79.93it/s]\n",
      "37it [00:00, 107.27it/s]/s]\n",
      "87it [00:00, 153.12it/s]\n",
      "1578it [00:00, 2885.13it/s]\n",
      "74it [00:01, 37.65it/s]s]\n",
      "153it [00:00, 153.39it/s]\n",
      "47it [00:00, 105.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import mp\n",
    "mp.multiprocessing(online_articles, loop, cores = 30, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f56b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/datasets/malaysia-ai/online-articles-partition\n",
    "!cp dedup-text-dataset/*.tokenized online-articles-partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d4f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
