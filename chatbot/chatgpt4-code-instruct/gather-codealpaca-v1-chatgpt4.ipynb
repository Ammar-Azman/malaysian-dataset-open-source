{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8c3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23040e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_words = [\n",
    "    'kebutuhan',\n",
    "    'berbeda',\n",
    "    'bahwa',\n",
    "    'Kode',\n",
    "    'kode',\n",
    "    'nomor',\n",
    "    'RMXX,XXX',\n",
    "    'kompleksitas',\n",
    "    'listrik',\n",
    "    'jawaban',\n",
    "    'teknis',\n",
    "    'berkualitas',\n",
    "    'mencoba',\n",
    "    'kampanye',\n",
    "    'komunitas',\n",
    "    'stabilitas',\n",
    "    'Stabilitas',\n",
    "    'metode',\n",
    "    'pria',\n",
    "    'butuh',\n",
    "    'jadwal',\n",
    "    'kasus',\n",
    "    'otomatis',\n",
    "    'populer',\n",
    "    'bisnis',\n",
    "    'probabilitas',\n",
    "    'rusak',\n",
    "    'kapasitas',\n",
    "    'rutinitas',\n",
    "    'pertama-tama'\n",
    "]\n",
    "rejected_words = set(rejected_words)\n",
    "\n",
    "def check_indon(string):\n",
    "    string = re.sub('[^A-Za-z ]+', ' ', string)\n",
    "    return len(set(string.split()) & rejected_words) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6738383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111272"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = []\n",
    "with open('evol-codealpaca-v1.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        instructions.append(json.loads(l)['instruction'])\n",
    "len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a44291",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(instructions)):\n",
    "    filename = f'evol-codealpaca-v1-chatgpt4/{i}.json'\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    \n",
    "    with open(filename) as fopen:\n",
    "        d = json.load(fopen)\n",
    "        \n",
    "    d['instruction_en'] = instructions[i]\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2ab74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43503"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb82b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4406189",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_instructions = [\n",
    "    'tidak dapat melakukan penulisan semula', \n",
    "    'maaf', \n",
    "    'not able to fulfill your request',\n",
    "    'saya tidak dapat membantu',\n",
    "    'dengan permintaan itu',\n",
    "    'feel free to ask',\n",
    "    'saya tidak bisa',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f743a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 43503/43503 [00:00<00:00, 212000.51it/s]\n"
     ]
    }
   ],
   "source": [
    "count, indon_count = 0, 0\n",
    "\n",
    "indon_texts = []\n",
    "for d in tqdm(data):\n",
    "\n",
    "    if d['output'] is None:\n",
    "        continue\n",
    "        \n",
    "    if any([r in d['instruction'].lower() for r in rejected_instructions]):\n",
    "        continue\n",
    "\n",
    "    indon_texts.append(d['instruction'])\n",
    "    indon_texts.append(d['output'])\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92201b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86680"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indon_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8c2316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuk mengubah skrip ini, kita Akkan menggunakan konsep pengulangan 'while' dan memastikan index tidak melebihi panjang senarai. Juga, kita harus memastikan skrip kita menangani senarai kosong dengan betul. \n",
      "\n",
      "Berikut adalah cara mengubahnya:\n",
      "\n",
      "```python\n",
      "  # Menetapkan senarai integer\n",
      "  arr = [1, 2, 3, 4]\n",
      "\n",
      "  # Tentukan panjang senarai\n",
      "  n = len(arr)\n",
      "\n",
      "  # Pastikan senarai tidak kosong\n",
      "  if n > 0:\n",
      "    i = 0\n",
      "    # Melalui senarai dan keluarkan setiap elemen individu\n",
      "    while i < n:\n",
      "        print(arr[i])\n",
      "        i += 1\n",
      "  else:\n",
      "    print(\"Senarai adalah kosong.\")\n",
      "```\n",
      "\n",
      "Dalam skrip ini, sebelum kita mulai mengulang, kita memeriksa apakah `n`, yang merupakan panjang senarai, lebih besar dari 0. Jika tidak (yang berarti senarai kosong), kita mencetak pesan yang sesuai. \n",
      "\n",
      "Kemudian, kami menggunakan pengulangan 'while' untuk mengulang selama indeks `i` kurang dari panjang `n` senarai. Selama setiap iterasi, kita mencetak elemen senarai dan tambahkan 1 ke indeks, sehingga kita dapat bergerak ke elemen berikutnya pada iterasi berikutnya. \n",
      "\n",
      "Ini akan mencegah terjadinya kesalahan index, karena kita tidak akan pernah mencoba mengakses indeks yang melebihi batas senarai.\n"
     ]
    }
   ],
   "source": [
    "print(indon_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5234ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('codealpaca-v1-chatgpt4.texts', 'w') as fopen:\n",
    "    for t in set(indon_texts):\n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fad4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(indon_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp codealpaca-v1-chatgpt4.texts ~/ssd3/ctranslate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc720ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86657"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {}\n",
    "with open('/home/husein/ssd3/ctranslate2/codealpaca-v1-chatgpt4.texts.requested') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        mapping[l['src']] = l['r']\n",
    "        \n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0082a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"Harap ubah skrip Python berikut agar ia memasukkan pengulangan 'while' daripada pengulangan 'for' yang sedia ada, yang meneruskan melalui item-item dalam senarai integer. \\n\\nSkrip semasa mempunyai bug di mana ia cuba mencetak objek yang berada di luar batas senarai. Betulkan ralat ini dan ubah skrip untuk menggunakan 'while' bukannya pengulangan 'for'. Pastikan skrip anda menangani senarai kosong dengan betul. \\n\\n```python\\n  # Menetapkan senarai integer\\n  arr = [1, 2, 3, 4]\\n\\n  # Tentukan panjang senarai\\n  n = len(arr)\\n\\n  # Melalui senarai dan keluarkan setiap elemen individu\\n  for i in range(n+1):\\n      print(arr[i])\\n```\",\n",
       " 'output': 'Untuk mengubah skrip ini, kita Akkan menggunakan konsep pengulangan \\'while\\' dan memastikan index tidak melebihi panjang senarai. Juga, kita harus memastikan skrip kita menangani senarai kosong dengan betul. \\n\\nBerikut adalah cara mengubahnya:\\n\\n```python\\n  # Menetapkan senarai integer\\n  arr = [1, 2, 3, 4]\\n\\n  # Tentukan panjang senarai\\n  n = len(arr)\\n\\n  # Pastikan senarai tidak kosong\\n  if n > 0:\\n    i = 0\\n    # Melalui senarai dan keluarkan setiap elemen individu\\n    while i < n:\\n        print(arr[i])\\n        i += 1\\n  else:\\n    print(\"Senarai adalah kosong.\")\\n```\\n\\nDalam skrip ini, sebelum kita mulai mengulang, kita memeriksa apakah `n`, yang merupakan panjang senarai, lebih besar dari 0. Jika tidak (yang berarti senarai kosong), kita mencetak pesan yang sesuai. \\n\\nKemudian, kami menggunakan pengulangan \\'while\\' untuk mengulang selama indeks `i` kurang dari panjang `n` senarai. Selama setiap iterasi, kita mencetak elemen senarai dan tambahkan 1 ke indeks, sehingga kita dapat bergerak ke elemen berikutnya pada iterasi berikutnya. \\n\\nIni akan mencegah terjadinya kesalahan index, karena kita tidak akan pernah mencoba mengakses indeks yang melebihi batas senarai.',\n",
       " 'instruction_en': \"Please amend the subsequent Python script so that it includes a 'while' loop rather than the existing 'for' loop, which iterates through the items of an integer list.\\n\\nThe script currently has a bug where it attempts to print an object that is outside the bounds of the list. Fix this error and modify the script to use 'while' instead of 'for' loop. Ensure your script correctly handles empty lists. \\n\\n```python\\n  # Establish an integer list\\n  arr = [1, 2, 3, 4]\\n\\n  # Determine the length of the list\\n  n = len(arr)\\n\\n  # Traverse the list and output each individual element\\n  for i in range(n+1):\\n      print(arr[i])\\n```\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2edaea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 43503/43503 [00:03<00:00, 12748.67it/s]\n"
     ]
    }
   ],
   "source": [
    "rejected = 0\n",
    "\n",
    "with open('synthetic-codealpaca-v1-chatgpt4.jsonl', 'w') as fopen_l:\n",
    "    for d in tqdm(data):\n",
    "            \n",
    "        if d['output'] is None:\n",
    "            continue\n",
    "        \n",
    "        output_ms = mapping.get(d['output'])\n",
    "        instruction_ms = mapping.get(d['instruction'])\n",
    "        \n",
    "        indon_ins = False\n",
    "        if check_indon(d['instruction']):\n",
    "            indon_ins = True\n",
    "        \n",
    "        indon_output = False\n",
    "        if check_indon(d['output']):\n",
    "            indon_output = True\n",
    "        \n",
    "        rejected_ins = False\n",
    "            \n",
    "        if any([r in d['instruction'].lower() for r in rejected_instructions]):\n",
    "            rejected_ins = True\n",
    "        \n",
    "        rejected_output = False\n",
    "            \n",
    "        if rejected_ins or rejected_output:\n",
    "            rejected += 1\n",
    "            \n",
    "        d['indon_ins'] = indon_ins\n",
    "        d['indon_output'] = indon_output\n",
    "        d['instruction_ms'] = instruction_ms\n",
    "        d['output_ms'] = output_ms\n",
    "        d['rejected_ins'] = rejected_ins\n",
    "        d['rejected_output'] = rejected_output\n",
    "        \n",
    "        fopen_l.write(f'{json.dumps(d)}\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1c1f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"Semasa menggunakan Amazon Redshift untuk keperluan gudang data saya, saya menghadapi 'DiskFullError'. Bolehkah anda memberi penerangan mengenai kaedah-kaedah berkesan untuk meningkatkan dan mengoptimumkan sumber Redshift saya, terutamanya untuk mengendalikan volume data yang besar, sambil pada masa yang sama menyediakan analisis terperinci mengenai asas logik yang kompleks di sebalik pendekatan-pendekatan ini?\",\n",
       " 'output': \"Apabila anda menghadapi 'DiskFullError' di Amazon Redshift, ini bermakna kapasiti penyimpanan cluster anda sudah penuh. Berikut adalah beberapa kaedah untuk mengoptimumkan penggunaan sumber di Redshift, yang boleh membantu menangani volume data yang besar:\\n\\n1. **Tinjauan Kapasiti Penyimpanan:**\\n   - Pertama, lakukan tinjauan penggunaan disk dengan memeriksa metric di konsol Redshift atau menggunakan query sistem untuk mengenal pasti penggunaan ruang oleh tabel dan skema.\\n\\n2. **Pembersihan Data:**\\n   - Buang data yang tidak perlu atau kurang penting dengan melakukan `DELETE` pada rekod-rekod lama atau dengan `TRUNCATE` pada tabel yang tidak lagi diperlukan.\\n   - Melaksanakan kompresi data dengan `VACUUM` untuk membuang ruang kosong dan mengecilkan saiz tabel. `VACUUM FULL` boleh mengatur semula tabel dan membebaskan ruang penyimpanan yang tidak digunakan.\\n\\n3. **Pertimbangan Skala Infrastruktur:**\\n   - Naikkan skala secara mendatar (horizontal scaling) dengan menambahkan nod pada cluster Redshift, atau secara menegak (vertical scaling) dengan memilih nod yang lebih besar, sekiranya budget membenarkan.\\n\\n4. **Optimumkan Skema dan Kueri:**\\n   - Menggunakan kunci pengedaran (distribution key) yang tepat untuk mendistribusikan data secara rata di antara nod, yang akan mengefisienkan operasi JOIN.\\n   - Pilih kunci sortasi (sort key) yang efektif untuk mempercepat proses kueri terhadap data yang sering diakses atau diquery.\\n   - Optimumkan kueri dengan menggunakan cara terbaik pengindexan, membatasi penggunaan fungsi yang berat, dan memastikan statistik untuk penjadualan kueri yang efisien.\\n\\n5. **Memantau dan Pengendalian Kinerja:**\\n   - Gunakan 'query monitoring rules' (QMRs) untuk memantau kinerja kueri dan mengambil tindakan otomatis yang diperlukan.\\n   - Monitor dan analisis kinerja dengan menggunakan Amazon Redshift's system tables dan views.\\n\\n6. **Pengurusan Data Secara Aktif:**\\n   - Menggunakan `ANALYZE` secara berkala untuk mengemaskini statistik untuk pengoptimum kueri, membolehkan Redshift membuat keputusan yang lebih baik tentang bagaimana untuk melaksanakan kueri.\\n\\n7. **Penggunaan Tetapan `WLM` (Workload Management):**\\n   - Penyesuaian parameter WLM untuk mengawal berapa banyak sumber yang digunakan oleh setiap kueri atau pengguna, dan memastikan rantaian kerja yang penting mendapat keutamaan yang sesuai.\\n\\n8. **Kaedah Penyimpanan Eksternal:**\\n   - Gunakan Amazon S3 sebagai gudang data untuk menyimpan data besar yang jarang diakses, mengurangkan tekanan pada penyimpanan Redshift.\\n   - Pertimbangkan penggunaan Redshift Spectrum untuk menyiasat data terus di S3 tanpa perlu memuatnya ke dalam kluster Redshift.\\n\\nAnalisis logik dan kompleks memerlukan sumber yang cukup agar kinerja tidak terjejas. Ini termasuk memastikan skema dan jenis-jenis data dirancang dengan baik, kueri dikemasoptimumkan, dan sumber disesuaikan dengan keperluan beban kerja analitik. Dengan melaksanakan amalan terbaik ini, anda dapat meningkatkan kinerja dan skalabilitas gudang data Redshift anda, sambil mengatasi masalah kesesakan penyimpanan.\",\n",
       " 'instruction_en': \"While utilizing Amazon Redshift for my data warehousing requirements, I'm encountering a 'DiskFullError'. Can you shed light on the effective methods to enhance and optimize my Redshift resources, particularly for handling massive data volumes, while concurrently providing a comprehensive analysis of the complex rationale that underpins these approaches?\",\n",
       " 'indon_ins': False,\n",
       " 'indon_output': True,\n",
       " 'rejected_ins': False,\n",
       " 'rejected_output': False,\n",
       " 'instruction_ms': \"Semasa menggunakan Amazon Redshift untuk keperluan gudang data saya, saya menghadapi 'DiskFullError'. Bolehkah anda menerangkan kaedah yang berkesan untuk meningkatkan dan mengoptimumkan sumber Redshift saya, terutamanya untuk mengawal jumlah data yang besar, sambil menyediakan analisis terperinci tentang asas logik yang kompleks di sebalik pendekatan ini?\",\n",
       " 'output_ms': \"Apabila anda menghadapi 'DiskFullError' di Amazon Redshift, ini bermakna kapasiti penyimpanan kluster anda sudah penuh. Berikut adalah beberapa kaedah untuk mengoptimumkan penggunaan sumber di Redshift, yang boleh membantu menangani jumlah data yang besar:\\n\\n1. **Tinjauan Kapasiti Penyimpanan:**\\n   - Pertama, lakukan semakan penggunaan cakera dengan memeriksa metrik di konsol Redshift atau menggunakan sistem kueri untuk mengenal pasti penggunaan ruang oleh jadual dan skema.\\n\\n2. **Pembersihan Data:**\\n   - Buang data yang tidak perlu atau kurang penting dengan melakukan `DELETE` pada rekod lama atau dengan `TRUNCATE` pada jadual yang tidak lagi diperlukan.\\n   - Melaksanakan mampatan data dengan `VACUUM` untuk membuang ruang kosong dan mengecilkan saiz jadual. `VACUUM FULL` boleh mengatur semula jadual dan membebaskan ruang penyimpanan yang tidak digunakan.\\n\\n3. **Pertimbangan Skala Infrastruktur:**\\n   - Naikkan skala secara mendatar (penskalaan mendatar) dengan menambahkan nod pada kluster Redshift, atau secara menegak (penskalaan menegak) dengan memilih nod yang lebih besar, jika bajet membenarkan.\\n\\n4. **Optimumkan Skema dan Kueri:**\\n   - Menggunakan kunci pengedaran (kunci pengedaran) yang tepat untuk mengedarkan data secara rata di antara nod, yang akan memperkecilkan operasi JOIN.\\n   - Pilih kunci penyusunan (kunci sort) yang berkesan untuk mempercepatkan proses kueri terhadap data yang sering diakses atau dikueri.\\n   - Optimumkan kueri dengan menggunakan kaedah pengindeksan terbaik, mengehadkan penggunaan fungsi yang berat, dan memastikan statistik untuk penjadualan kueri yang cekap.\\n\\n5. **Memantau dan Pengendalian Prestasi:**\\n   - Gunakan'peraturan pemantauan kueri' (QMRs) untuk memantau prestasi kueri dan mengambil tindakan automatik yang diperlukan.\\n   - Memantau dan menganalisis prestasi dengan menggunakan jadual dan pandangan sistem Amazon Redshift.\\n\\n6. **Pengurusan Data Secara Aktif:**\\n   - Menggunakan `ANALYZE` secara berkala untuk mengemas kini statistik untuk pengoptimum kueri, membolehkan Redshift membuat keputusan yang lebih baik tentang cara melaksanakan kueri.\\n\\n7. **Penggunaan Tetapan `WLM` (Workload Management):**\\n   - Penyesuaian parameter WLM untuk mengawal berapa banyak sumber yang digunakan oleh setiap kueri atau pengguna, dan memastikan rantaian kerja yang penting mendapat keutamaan yang sesuai.\\n\\n8. **Kaedah Penyimpanan Luar:**\\n   - Gunakan Amazon S3 sebagai gudang data untuk menyimpan data besar yang jarang diakses, mengurangkan tekanan pada penyimpanan Redshift.\\n   - Pertimbangkan penggunaan Redshift Spectrum untuk menyiasat data terus di S3 tanpa perlu memuatkannya ke dalam kluster Redshift.\\n\\nAnalisis logik dan kompleks memerlukan sumber yang mencukupi supaya prestasi tidak terjejas. Ini termasuk memastikan skema dan jenis data dirancang dengan baik, kueri dikemas kini, dan sumber disesuaikan dengan keperluan beban kerja analitik. Dengan melaksanakan amalan terbaik ini, anda boleh meningkatkan prestasi dan skalabiliti gudang data Redshift anda, sambil mengatasi masalah kesesakan penyimpanan.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a55bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0ba6ab610a4aa0862f616dfaa385fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "synthetic-codealpaca-v1-chatgpt4.jsonl:   0%|          | 0.00/274M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='synthetic-codealpaca-v1-chatgpt4.jsonl',\n",
    "    path_in_repo='synthetic-codealpaca-v1-chatgpt4.jsonl',\n",
    "    repo_id='mesolitica/chatgpt4-code-instruct',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
