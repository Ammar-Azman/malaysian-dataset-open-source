{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8963ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1/resolve/main/train.jsonl -O evol-codealpaca-v1.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fd8bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import malaya\n",
    "from pydantic import BaseModel, Field\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import random\n",
    "\n",
    "minimum_len = 15\n",
    "\n",
    "def simple_cleaning(string):\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(string).replace('\\n', ' ').replace('--', ' ').replace('/', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc25282",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://husein-ai7-aiservices-435901645.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = ''\n",
    "\n",
    "engine = 'gpt-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb89b567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111272"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = []\n",
    "with open('evol-codealpaca-v1.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        instructions.append(json.loads(l)['instruction'])\n",
    "len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6966ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt, max_tokens = 1024):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "       \n",
    "    ]\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=engine,\n",
    "            messages=messages,\n",
    "            temperature=1.0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        return response.choices[0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb4e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'terjemah ke bahasa melayu: {instructions[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbb3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘evol-codealpaca-v1-chatgpt4’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir evol-codealpaca-v1-chatgpt4\n",
    "# !rm -rf evol-codealpaca-v1/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48c4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction, index, show = False):\n",
    "    filename = f'evol-codealpaca-v1-chatgpt4/{index}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        prompt = f'terjemah ke bahasa melayu: {instruction}'\n",
    "        ins = predict(prompt)\n",
    "        if show:\n",
    "            print(ins)\n",
    "        answer = predict(ins + ', jawab dalam bahasa melayu', max_tokens = 2048)\n",
    "        d = {\"instruction\":ins,\"output\":answer}\n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(d, fopen)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c55199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▏                                                                                              | 1140/18545 [00:00<00:01, 11393.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
      "unsupported operand type(s) for +: 'NoneType' and 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████▋                                                                                          | 2280/18545 [00:14<02:00, 134.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "unsupported operand type(s) for +: 'NoneType' and 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▉                                                                                 | 3206/18545 [3:02:13<173:27:50, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'content'\n",
      "unsupported operand type(s) for +: 'NoneType' and 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▋                                                                             | 3758/18545 [9:11:30<811:32:10, 197.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out: HTTPSConnectionPool(host='husein-ai7-aiservices-435901645.openai.azure.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████                                                                     | 5510/18545 [24:19:19<88:01:54, 24.31s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_worker = 1\n",
    "for i in tqdm(range((len(instructions) // 6) * 0, (len(instructions) // 6) * 1, max_worker)):\n",
    "    b = instructions[i: i + max_worker]\n",
    "    b = [(ins, i + no) for no, ins in enumerate(b)]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate, f[0], f[1]): f for f in b}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102de0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
