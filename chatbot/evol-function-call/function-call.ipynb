{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2/resolve/main/glaive-function-calling-v2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024caaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import malaya\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import random\n",
    "\n",
    "minimum_len = 15\n",
    "\n",
    "def simple_cleaning(string):\n",
    "    return re.sub(r'[ ]+', ' ', unidecode(string).replace('\\n', ' ').replace('--', ' ').replace('/', ' ')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d41f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructor.patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationObject(BaseModel):\n",
    "    role: str\n",
    "    content: str = Field('...', description = 'if the role is `assistant`, it must convert user content into function parameter format `<functioncall> {\"name\", \"arguments\"}`')\n",
    "        \n",
    "class JsonObject(BaseModel):\n",
    "    function_call: str\n",
    "    conversations: List[ConversationObject]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dd02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://husein-ai10-aiservices-2093329748.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "engine = 'gpt-35-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5233f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glaive-function-calling-v2.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "all_data = []\n",
    "for d in data:\n",
    "    function_call = None\n",
    "    try:\n",
    "        function_call = d['system'].split('required -')[1]\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    \n",
    "    conversations = []\n",
    "    splitted = d['chat'].split('ASSISTANT:')\n",
    "    conversations.append({\n",
    "        'role': 'user',\n",
    "        'content': splitted[0].split('USER:')[1].strip(),\n",
    "    })\n",
    "    for s in splitted[1:]:\n",
    "        s = s.replace('<|endoftext|>', '')\n",
    "        if 'USER:' in s:\n",
    "            s = s.split('USER:')\n",
    "            conversations.append({\n",
    "                'role': 'assistant',\n",
    "                'content': s[0].strip(),\n",
    "            })\n",
    "            conversations.append({\n",
    "                'role': 'user',\n",
    "                'content': s[1].strip(),\n",
    "            })\n",
    "        else:\n",
    "            conversations.append({\n",
    "                'role': 'assistant',\n",
    "                'content': s.strip(),\n",
    "            })\n",
    "        \n",
    "    filtered_message = []\n",
    "    \n",
    "    for i in range(len(conversations)):\n",
    "        if conversations[i]['role'] == 'assistant' and '<functioncall>' in conversations[i]['content']:\n",
    "            if conversations[i-1]['role'] == 'user':\n",
    "                message = conversations[i-1]['content'].strip() \n",
    "            else:\n",
    "                message = conversations[i-2]['content'].strip() \n",
    "            filtered_message.append({\n",
    "                'role': 'user',\n",
    "                'content': message ,\n",
    "            })\n",
    "            filtered_message.append({\n",
    "                'role': 'assistant',\n",
    "                'content':  conversations[i]['content'].split('FUNCTION RESPONSE')[0].strip() ,\n",
    "            })\n",
    "            \n",
    "    if len(filtered_message) > 0:\n",
    "        all_data.append({\n",
    "            'function_call':function_call,\n",
    "            'conversations': filtered_message\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75bdfcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt, max_tokens = 1024):\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "       \n",
    "    ]\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "        engine=engine,\n",
    "        messages=messages,\n",
    "        temperature=1.0,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def predict_instruct(text):\n",
    "    r = openai.ChatCompletion.create(\n",
    "        engine=engine,\n",
    "        response_model=JsonObject,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "        temperature=1.0,\n",
    "        max_tokens=1024,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b557811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘function-call’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir function-call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf0a282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = []\n",
    "for i in range(len(all_data)):\n",
    "    d = {\n",
    "        'function_call': all_data[i]['function_call'].strip(),\n",
    "        'conversations': all_data[i]['conversations'],\n",
    "    }\n",
    "    text = f\"\"\"translate to malay,\n",
    "    ```\n",
    "    {d}\n",
    "    ```\n",
    "    \"\"\".strip()\n",
    "    instructions.append(text)\n",
    "    \n",
    "len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab1b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction, index):\n",
    "    filename = f'function-call/{index}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        e = None\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = predict(instruction)\n",
    "                e = eval(output.choices[0]['message']['content'].replace('```', ''))\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if e is None:\n",
    "            return\n",
    "        \n",
    "        text = f\"\"\"Generate complex Malay function call prompts inspired by the given example. If translation is challenging, use Malaysian terms for variety. Maintain the JSON format, altering only key contents. Follow instructions precisely, avoiding randomness.\n",
    "\n",
    "Code snippet for inspiration:\n",
    "```\n",
    "{e}\n",
    "```\n",
    "\"\"\".strip()\n",
    "        rs = []\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                r = predict_instruct(text)\n",
    "                rs.append(r.dict())\n",
    "            except Exception as e__:\n",
    "                print('nested', e__)\n",
    "                pass\n",
    "        \n",
    "        d = {\n",
    "            'e': e,\n",
    "            'rs': rs\n",
    "        }\n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(d, fopen)\n",
    "    except Exception as e_:\n",
    "        print(e_)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4dc4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(instructions[2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ff6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/5268 [00:00<?, ?it/s]/tmp/ipykernel_3644185/2968651273.py:30: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  rs.append(r.dict())\n",
      "  0%|                                       | 5/5268 [01:09<19:17:07, 13.19s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_worker = 2\n",
    "for i in tqdm(range((len(instructions) // 6) * 0, (len(instructions) // 6) * 1, max_worker)):\n",
    "    b = instructions[i: i + max_worker]\n",
    "    b = [(ins, i + no) for no, ins in enumerate(b)]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate, f[0], f[1]): f for f in b}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bad943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9",
   "language": "python",
   "name": "3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
