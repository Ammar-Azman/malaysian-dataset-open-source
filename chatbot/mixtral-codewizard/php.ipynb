{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f779b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/malaysia-ai/starcoderdata-sample/resolve/main/php.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb5572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6f5a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300000it [00:23, 12659.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "297509"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = []\n",
    "\n",
    "with open('php.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        try:\n",
    "            l = json.loads(l)\n",
    "            if len(l['content'].split()) > 5e3:\n",
    "                continue\n",
    "            ls.append(l['content'])\n",
    "        except:\n",
    "            pass\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61e8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    \"\", timeout = 120\n",
    ")\n",
    "\n",
    "\n",
    "def format_prompt(message, history):\n",
    "  prompt = \"<s>\"\n",
    "  for user_prompt, bot_response in history:\n",
    "    prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "    prompt += f\" {bot_response}</s> \"\n",
    "  prompt += f\"[INST] {message} [/INST]\"\n",
    "  return prompt\n",
    "\n",
    "def format_user(history):\n",
    "    prompt = \"<s>\"\n",
    "    for user_prompt, bot_response in history:\n",
    "        prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "        prompt += f\" {bot_response}</s> \"\n",
    "    prompt += f\"[INST]\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda36b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = dict(\n",
    "    temperature=1.0,\n",
    "    max_new_tokens=5120,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.0,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc207c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘mixtral-php’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir mixtral-php\n",
    "# !rm -rf mixtral-php/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef3a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(q, i):\n",
    "    filename = f'mixtral-php/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "    # for _ in range(5):\n",
    "        try:\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "Please gain inspiration from the following random code snippet to create a high-quality PHP problem. Present your output in two distinct sections: [Problem Description] and [Solution].\n",
    "\n",
    "PHP snippet for inspiration:\n",
    "```\n",
    "{q}\n",
    "```\n",
    "\n",
    "Guidelines for each section:\n",
    "\n",
    "1. [Problem Description]: This should be **completely self-contained**, providing all the contextual information one needs to understand and solve the problem. Assume common programming knowledge, but ensure that any specific context, variables, or code snippets pertinent to this problem are explicitly included but do not mention code snippet above.\n",
    "\n",
    "2. [Solution]: Offer a comprehensive, **correct** solution that accurately addresses the [Problem Description] you provided.\n",
    "\"\"\".strip()\n",
    "            formatted_prompt = format_prompt(prompt, [])\n",
    "            stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "            output = stream.generated_text\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(output, fopen)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if 'tokens + `max_new_tokens`' in str(e):\n",
    "                with open(filename, 'w') as fopen:\n",
    "                    json.dump(False, fopen)\n",
    "                break\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0ac5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236113b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "queue = Queue()\n",
    "questions = ls\n",
    "urls = [(q, no) for no, q in enumerate(questions)]\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efbd604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aacdb9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **[Problem Description]**\n",
      "\n",
      "You are working on a PHP project using the Yii2 framework that involves a table called \"ref\\_scale\" in the database. This table has the following columns: type, name, raw, scaled, attribute\\_1, attribute\\_2, and attribute\\_3. Each of these columns is a string with a maximum length of 255 characters.\n",
      "\n",
      "Your task is to create a function that will calculate the average value of the \"scaled\" column for each unique value of the \"type\" column. The function should return an associative array with the unique values of the \"type\" column as keys and their corresponding average value of the \"scaled\" column as values.\n",
      "\n",
      "However, you have noticed that there are some missing or invalid values in the \"scaled\" column, and you want to exclude these from the calculation. A value is considered valid if it is a non-empty string. You will also need to consider the following edge cases:\n",
      "\n",
      "* If there are no valid values for a given type, then that type should not be present in the final associative array.\n",
      "* If there is only one valid value for a given type, then the average value for that type should be the value itself.\n",
      "\n",
      "**[Solution]**\n",
      "\n",
      "Here's a solution for the given problem:\n",
      "\n",
      "```php\n",
      "use common\\modules\\core\\models\\RefScale;\n",
      "\n",
      "function getAverageScaledValuesByType() {\n",
      "    // Fetch unique types and corresponding scaled values\n",
      "    $data = RefScale::find()\n",
      "        ->select(['type', 'scaled'])\n",
      "        ->where(['not', ['scaled' => '']])\n",
      "        ->groupBy('type')\n",
      "        ->all();\n",
      "\n",
      "    $averages = [];\n",
      "\n",
      "    foreach ($data as $item) {\n",
      "        $scaledValues = RefScale::find()\n",
      "            ->select('scaled')\n",
      "            ->where(['type' => $item->type])\n",
      "            ->andWhere(['not', ['scaled' => '']])\n",
      "            ->column();\n",
      "\n",
      "        $total = 0;\n",
      "        $validCount = 0;\n",
      "\n",
      "        foreach ($scaledValues as $scaledValue) {\n",
      "            if (is_numeric($scaledValue)) {\n",
      "                $total += $scaledValue;\n",
      "                $validCount++;\n",
      "            }\n",
      "        }\n",
      "\n",
      "        if ($validCount > 0) {\n",
      "            $averages[$item->type] = $total / $validCount;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    return $averages;\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "\n",
      "The function `getAverageScaledValuesByType()` first fetches unique types and their corresponding \"scaled\" values using the `RefScale` model. Afterward, it initializes an empty array `$averages` that will store the final results.\n",
      "\n",
      "Then, the code iterates through each type and their corresponding scaled values, calculating the total sum and the number of valid scaled values for each type. If there are any valid scaled values, the function calculates the average value for that type and stores it in the `$averages` array.\n",
      "\n",
      "Finally, the function returns the `$averages` array with unique type keys and their corresponding average values of the \"scaled\" column. This should provide a solution that fits the given problem description, considering missing or invalid values.\n"
     ]
    }
   ],
   "source": [
    "with open('mixtral-php/1.json') as fopen:\n",
    "    print(json.loads(fopen.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c77c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                          | 17721/297509 [3:47:35<1240:59:53, 15.97s/it]"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e0e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
