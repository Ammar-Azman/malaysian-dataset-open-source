{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227bbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fa73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-en/left.txt') as fopen:\n",
    "    left = fopen.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f9717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:72: UserWarning: You are currently using TensorFlow 2.6.0 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.4.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.4.0 and strictly below 2.5.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/malaya_boilerplate/frozen_graph.py:35: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, ['malaya.jawi_rumi.deep_model', 'malaya.phoneme.deep_model', 'malaya.rumi_jawi.deep_model', 'malaya.stem.deep_model'] will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a2446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya.text.rules import rules_normalizer, rules_compound_normalizer\n",
    "from malaya.text.normalization import _is_number_regex\n",
    "from malaya.text.function import replace_punct\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd8d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = '!\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}~'\n",
    "\n",
    "def case_of(text):\n",
    "    return (\n",
    "        str.upper\n",
    "        if text.isupper()\n",
    "        else str.lower\n",
    "        if text.islower()\n",
    "        else str.title\n",
    "        if text.istitle()\n",
    "        else str\n",
    "    )\n",
    "\n",
    "def strip_punct(word):\n",
    "    left = []\n",
    "    right = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if word[i] in PUNCTUATION:\n",
    "            left.append(word[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    i = len(word) - 1\n",
    "    while i > 0:\n",
    "        if word[i] in PUNCTUATION:\n",
    "            right.append(word[i])\n",
    "            i -= 1\n",
    "        else:\n",
    "            break\n",
    "    left = ''.join(left)\n",
    "    right = ''.join(right[::-1])\n",
    "    if len(right):\n",
    "        word_ = word[:-len(right)]\n",
    "    else:\n",
    "        word_ = word\n",
    "    word_ = word_[len(left):]\n",
    "    return left, right, word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a691ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_punct(left_word, right_word):\n",
    "    left_left, left_right, left_word = strip_punct(left_word)\n",
    "    right_left, right_right, right_word = strip_punct(right_word)\n",
    "    return f'{left_left}{right_word}{left_right}'\n",
    "\n",
    "def random_replace_alignment(left, right, alignment, min_replace = 5, max_replace = 15):\n",
    "    splitted_left = left.split()\n",
    "    splitted_right = right.split()\n",
    "    \n",
    "    selected_alignment = []\n",
    "    for s in alignment:\n",
    "        l = s[0]\n",
    "        r = s[1]\n",
    "        try:\n",
    "            if _is_number_regex(splitted_left[l].replace(',', '').replace('.', '')) or _is_number_regex(splitted_right[r].replace(',', '').replace('.', '')):\n",
    "                continue\n",
    "            elif splitted_left[l].isupper() or splitted_right[r].isupper():\n",
    "                continue\n",
    "            elif splitted_left[l].lower() == splitted_right[r].lower():\n",
    "                continue\n",
    "            elif splitted_left[r].lower() in ['the', 'a', 'an', 'it', 'is', 'are']:\n",
    "                continue\n",
    "            else:\n",
    "                selected_alignment.append((l, r))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    try:\n",
    "        count_replace = random.randint(min_replace, min(max_replace, len(selected_alignment)))\n",
    "        selected = random.sample(selected_alignment, count_replace)\n",
    "        for s in selected:\n",
    "            splitted_left[s[0]] = replace_words_punct(splitted_left[s[0]], splitted_right[s[1]])\n",
    "\n",
    "        return ' '.join(splitted_left), selected\n",
    "    \n",
    "    except:\n",
    "        return ' '.join(splitted_left), []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44acf599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = malaya.language_detection.substring_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578ddb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = malaya.tokenizer.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552658ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EN', 'EN', 'EN', 'EN', 'EN', 'EN', 'EN', 'EN', 'NOT_LANG', 'NOT_LANG']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ' '.join(tokenizer.tokenize(left[0]))\n",
    "predicted = model.predict(l.split())\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356db312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Most', 'of', 'them', 'are', 'teenagers', 'or', 'in', 'their', '20s', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e964a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def loop(rows):\n",
    "    rows, _ = rows\n",
    "    strings, labels = [], []\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        try:\n",
    "            left_ = rows[i]\n",
    "            tokenized_l = tokenizer.tokenize(left_)\n",
    "            l = tokenized_l\n",
    "            predicted = model.predict(l)\n",
    "            strings.append(l)\n",
    "            labels.append(predicted)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    return [[strings, labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d2a47e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1525.65it/s]\n"
     ]
    }
   ],
   "source": [
    "r = loop((left[:10],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa5fd70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Most', 'of', 'them', 'are', 'teenagers', 'or', 'in', 'their', '20s', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ca58d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EN', 'EN', 'EN', 'EN', 'EN', 'EN', 'EN', 'EN', 'NOT_LANG', 'NOT_LANG']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b286adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21431ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 75000/75000 [00:21<00:00, 3448.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 75000/75000 [00:21<00:00, 3432.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 75000/75000 [00:21<00:00, 3418.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 75000/75000 [00:22<00:00, 3406.53it/s]\n"
     ]
    }
   ],
   "source": [
    "r = mp.multiprocessing(left[400000:700000], loop, cores = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b12585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 75000\n",
      "1 75000\n",
      "2 75000\n",
      "3 75000\n"
     ]
    }
   ],
   "source": [
    "strings, labels = [], []\n",
    "for i in range(len(r)):\n",
    "    print(i, len(r[i][0]))\n",
    "    strings.extend(r[i][0])\n",
    "    labels.extend(r[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0718461b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['But',\n",
       "  'I',\n",
       "  'believe',\n",
       "  'it',\n",
       "  'has',\n",
       "  'an',\n",
       "  'assimilation',\n",
       "  'problem',\n",
       "  '.',\n",
       "  'Muslim',\n",
       "  'minorities',\n",
       "  'there',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'be',\n",
       "  'less',\n",
       "  'integrated',\n",
       "  'than',\n",
       "  'in',\n",
       "  'other',\n",
       "  'European',\n",
       "  'countries',\n",
       "  '.',\n",
       "  'There',\n",
       "  'are',\n",
       "  '.',\n",
       "  'that',\n",
       "  'while',\n",
       "  'Muslims',\n",
       "  'are',\n",
       "  'around',\n",
       "  '7%',\n",
       "  'to',\n",
       "  '8%',\n",
       "  'of',\n",
       "  \"France's\",\n",
       "  'population',\n",
       "  ',',\n",
       "  'they',\n",
       "  'are',\n",
       "  'more',\n",
       "  'than',\n",
       "  '60%',\n",
       "  'of',\n",
       "  'its',\n",
       "  'prison',\n",
       "  'population',\n",
       "  '.',\n",
       "  'A',\n",
       "  '.',\n",
       "  'also',\n",
       "  'showed',\n",
       "  'that',\n",
       "  'four',\n",
       "  'of',\n",
       "  'the',\n",
       "  'five',\n",
       "  'most',\n",
       "  'radicalized',\n",
       "  'Muslim',\n",
       "  'populations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'are',\n",
       "  'in',\n",
       "  'countries',\n",
       "  'of',\n",
       "  'French',\n",
       "  'culture',\n",
       "  '.',\n",
       "  'One',\n",
       "  'factor',\n",
       "  'could',\n",
       "  'be',\n",
       "  'the',\n",
       "  'very',\n",
       "  'aggressive',\n",
       "  'form',\n",
       "  'of',\n",
       "  'secularism',\n",
       "  'in',\n",
       "  'France',\n",
       "  '-',\n",
       "  '-',\n",
       "  'far',\n",
       "  'more',\n",
       "  'aggressive',\n",
       "  'than',\n",
       "  'the',\n",
       "  'United',\n",
       "  'States',\n",
       "  'or',\n",
       "  'any',\n",
       "  'other',\n",
       "  'Western',\n",
       "  'country',\n",
       "  '.',\n",
       "  'A',\n",
       "  'woman',\n",
       "  'can',\n",
       "  'wear',\n",
       "  'what',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'in',\n",
       "  'America',\n",
       "  '.',\n",
       "  'But',\n",
       "  'in',\n",
       "  '2011',\n",
       "  ',',\n",
       "  'for',\n",
       "  'example',\n",
       "  '.',\n",
       "  'certain',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'Muslim',\n",
       "  'veils',\n",
       "  '.',\n",
       "  'So',\n",
       "  'there',\n",
       "  'may',\n",
       "  'be',\n",
       "  'something',\n",
       "  'going',\n",
       "  'on',\n",
       "  'between',\n",
       "  'that',\n",
       "  'dynamic',\n",
       "  'of',\n",
       "  'French',\n",
       "  'culture',\n",
       "  'and',\n",
       "  'the',\n",
       "  'alienation',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'producing',\n",
       "  'in',\n",
       "  'some',\n",
       "  'disaffected',\n",
       "  'quarters',\n",
       "  '.',\n",
       "  'None',\n",
       "  'of',\n",
       "  'that',\n",
       "  'in',\n",
       "  'any',\n",
       "  'way',\n",
       "  'justifies',\n",
       "  'violence',\n",
       "  ',',\n",
       "  'but',\n",
       "  'if',\n",
       "  'we',\n",
       "  'are',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'why',\n",
       "  'France',\n",
       "  'seems',\n",
       "  'particularly',\n",
       "  'troubled',\n",
       "  ',',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'look',\n",
       "  'honestly',\n",
       "  'at',\n",
       "  'what',\n",
       "  'differentiates',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['EN',\n",
       "  'CAPITAL',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'CAPITAL',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'OTHERS',\n",
       "  'OTHERS',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'CAPITAL',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'EN',\n",
       "  'NOT_LANG'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings[-1], labels[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db974a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en-substrings.json', 'w') as fopen:\n",
    "    json.dump({'strings': strings, 'labels': labels}, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
