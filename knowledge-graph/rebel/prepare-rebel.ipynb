{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/Babelscape/rebel-dataset/resolve/main/rebel_dataset.zip\n",
    "# !unzip rebel_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_test.jsonl  en_train.jsonl  en_val.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls en_*.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"docid\": \"30113940\", \"title\": \"Transportation Journal\", \"uri\": \"Q7835172\", \"text\": \"Transportation Journal is an academic journal devoted to transportation, logistics and related fields. The journal is published quarterly by the Penn State University Press on behalf of the American Society of Transportation and Logistics.\", \"entities\": [{\"uri\": \"Q737498\", \"boundaries\": [29, 45], \"surfaceform\": \"academic journal\", \"annotator\": \"Me\"}, {\"uri\": \"Q7163300\", \"boundaries\": [145, 172], \"surfaceform\": \"Penn State University Press\", \"annotator\": \"Me\"}, {\"uri\": \"Q296160\", \"boundaries\": [190, 238], \"surfaceform\": \"American Society of Transportation and Logistics\", \"annotator\": \"Me\"}, {\"uri\": \"Q7835172\", \"boundaries\": [0, 22], \"surfaceform\": \"Transportation Journal\", \"annotator\": \"Me\"}], \"triples\": [{\"subject\": {\"uri\": \"Q7835172\", \"boundaries\": [0, 22], \"surfaceform\": \"Transportation Journal\", \"annotator\": \"Me\"}, \"predicate\": {\"uri\": \"P123\", \"boundaries\": null, \"surfaceform\": \"publisher\", \"annotator\": \"NoSubject-Triple-aligner\"}, \"object\": {\"uri\": \"Q7163300\", \"boundaries\": [145, 172], \"surfaceform\": \"Penn State University Press\", \"annotator\": \"Me\"}, \"sentence_id\": 1, \"dependency_path\": null, \"confidence\": null, \"annotator\": \"NoSubject-Triple-aligner\"}]}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 en_val.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# article = data[1]\n",
    "\n",
    "def rebel_format(article):\n",
    "    prev_len = 0\n",
    "    count = 0\n",
    "    for text_paragraph in article['text'].split('\\n'):\n",
    "        if len(text_paragraph) == 0:\n",
    "            continue\n",
    "        sentences = re.split(r'(?<=[.])\\s', text_paragraph)\n",
    "        text = ''\n",
    "        for sentence in sentences:\n",
    "            text += sentence + ' '\n",
    "            if any([entity['boundaries'][0] < len(text) + prev_len < entity['boundaries'][1] for entity in article['entities']]):\n",
    "                continue\n",
    "            entities = sorted([entity for entity in article['entities'] if prev_len < entity['boundaries'][1] <= len(text)+prev_len], key=lambda tup: tup['boundaries'][0])\n",
    "            decoder_output = '<triplet> '\n",
    "            for int_ent, entity in enumerate(entities):\n",
    "                triplets = sorted([triplet for triplet in article['triples'] if triplet['subject'] == entity and prev_len< triplet['subject']['boundaries'][1]<=len(text) + prev_len and prev_len< triplet['object']['boundaries'][1]<=len(text)+ prev_len], key=lambda tup: tup['object']['boundaries'][0])\n",
    "                if len(triplets) == 0:\n",
    "                    continue\n",
    "                decoder_output += entity['surfaceform'] + ' <subj> '\n",
    "                for triplet in triplets:\n",
    "                    decoder_output += triplet['object']['surfaceform'] + ' <obj> '  + triplet['predicate']['surfaceform'] + ' <subj> '\n",
    "                decoder_output = decoder_output[:-len(' <subj> ')]\n",
    "                decoder_output += ' <triplet> '\n",
    "            decoder_output = decoder_output[:-len(' <triplet> ')]\n",
    "            count += 1\n",
    "            prev_len += len(text)\n",
    "\n",
    "            if len(decoder_output) == 0:\n",
    "                text = ''\n",
    "                continue\n",
    "\n",
    "            text = re.sub('([\\[\\].,!?()])', r' \\1 ', text.replace('()', ''))\n",
    "            text = re.sub('\\s{2,}', ' ', text)\n",
    "\n",
    "            a = {\n",
    "                'title': article['title'],\n",
    "                'context': text,\n",
    "                'id': article['uri'] + '-' + str(count),\n",
    "                'triplets': decoder_output,\n",
    "            }\n",
    "            return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid': '30113940',\n",
       " 'title': 'Transportation Journal',\n",
       " 'uri': 'Q7835172',\n",
       " 'text': 'Transportation Journal is an academic journal devoted to transportation, logistics and related fields. The journal is published quarterly by the Penn State University Press on behalf of the American Society of Transportation and Logistics.',\n",
       " 'entities': [{'uri': 'Q737498',\n",
       "   'boundaries': [29, 45],\n",
       "   'surfaceform': 'academic journal',\n",
       "   'annotator': 'Me'},\n",
       "  {'uri': 'Q7163300',\n",
       "   'boundaries': [145, 172],\n",
       "   'surfaceform': 'Penn State University Press',\n",
       "   'annotator': 'Me'},\n",
       "  {'uri': 'Q296160',\n",
       "   'boundaries': [190, 238],\n",
       "   'surfaceform': 'American Society of Transportation and Logistics',\n",
       "   'annotator': 'Me'},\n",
       "  {'uri': 'Q7835172',\n",
       "   'boundaries': [0, 22],\n",
       "   'surfaceform': 'Transportation Journal',\n",
       "   'annotator': 'Me'}],\n",
       " 'triples': [{'subject': {'uri': 'Q7835172',\n",
       "    'boundaries': [0, 22],\n",
       "    'surfaceform': 'Transportation Journal',\n",
       "    'annotator': 'Me'},\n",
       "   'predicate': {'uri': 'P123',\n",
       "    'boundaries': None,\n",
       "    'surfaceform': 'publisher',\n",
       "    'annotator': 'NoSubject-Triple-aligner'},\n",
       "   'object': {'uri': 'Q7163300',\n",
       "    'boundaries': [145, 172],\n",
       "    'surfaceform': 'Penn State University Press',\n",
       "    'annotator': 'Me'},\n",
       "   'sentence_id': 1,\n",
       "   'dependency_path': None,\n",
       "   'confidence': None,\n",
       "   'annotator': 'NoSubject-Triple-aligner'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152673it [00:06, 22817.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "with open('rebel-val.jsonl', 'w') as fopen:\n",
    "    with open('en_val.jsonl') as fread:\n",
    "        for l in tqdm(fread):\n",
    "            l = json.loads(l)\n",
    "            a = rebel_format(l)\n",
    "            if a:\n",
    "                fopen.write(f'{json.dumps(a)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\": \"Chelopech Hill\", \"context\": \"Chelopech Hill ( , \\u2018Halm Chelopech\\u2019 \\\\'h&lm che-lo-'pech\\\\ ) is the ice-covered hill rising to 946 m in the north foothills of Detroit Plateau on Trinity Peninsula in Graham Land , Antarctica . \", \"id\": \"Q5090011-1\", \"triplets\": \"<triplet> Trinity Peninsula <subj> Graham Land <obj> part of <subj> Antarctica <obj> continent <triplet> Graham Land <subj> Antarctica <obj> continent\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 rebel-val.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152836it [00:06, 22850.83it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('rebel-test.jsonl', 'w') as fopen:\n",
    "    with open('en_test.jsonl') as fread:\n",
    "        for l in tqdm(fread):\n",
    "            l = json.loads(l)\n",
    "            a = rebel_format(l)\n",
    "            if a:\n",
    "                fopen.write(f'{json.dumps(a)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2754388it [01:57, 23425.76it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('rebel-train.jsonl', 'w') as fopen:\n",
    "    with open('en_train.jsonl') as fread:\n",
    "        for l in tqdm(fread):\n",
    "            l = json.loads(l)\n",
    "            a = rebel_format(l)\n",
    "            if a:\n",
    "                fopen.write(f'{json.dumps(a)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -l 200000 -d --additional-suffix=.splitted rebel-train.jsonl rebel-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -l 200000 -d --additional-suffix=.splitted rebel-test.jsonl rebel-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -l 200000 -d --additional-suffix=.splitted rebel-val.jsonl rebel-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rebel(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace('<s>', '').replace(\"<pad>\", '').replace('</s>', '').split():\n",
    "        if token == '<triplet>':\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == '<subj>':\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == '<obj>':\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail': object_.strip()})\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 'Trinity Peninsula', 'type': 'part of', 'tail': 'Graham Land'},\n",
       " {'head': 'Trinity Peninsula', 'type': 'continent', 'tail': 'Antarctica'},\n",
       " {'head': 'Graham Land', 'type': 'continent', 'tail': 'Antarctica'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_rebel('<triplet> Trinity Peninsula <subj> Graham Land <obj> part of <subj> Antarctica <obj> continent <triplet> Graham Land <subj> Antarctica <obj> continent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet subj obj subj obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelm = []\n",
    "with open('quadruples-train21.splitted.translated') as fopen:\n",
    "    for l in fopen:\n",
    "        kelm.append(json.loads(l))\n",
    "        if len(kelm) == 100:\n",
    "            break\n",
    "            \n",
    "kelm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_kelm = []\n",
    "for k in kelm:\n",
    "    for k_ in k:\n",
    "        if len(k_['triples']) > 2:\n",
    "            filtered_kelm.append(k_)\n",
    "            \n",
    "len(filtered_kelm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_kelm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_list(triplets):\n",
    "    q = []\n",
    "    for no, triple in enumerate(triplets):\n",
    "        q.append([triple['head'], triple['type'], triple['tail']])\n",
    "    return q\n",
    "\n",
    "def rebel_format(triplets):\n",
    "    \"\"\"\n",
    "    Convert\n",
    "    [['Bruno Santana', 'participant of', '2004 Summer Olympics'],\n",
    "    ['Bruno Santana', 'participant of', '2008 Summer Olympics'],\n",
    "    ['Bruno Santana', 'country of citizenship', 'Brazil']]\n",
    "    to rebel format,\n",
    "    <triplet> Bruno Santana <subj> 2004 Summer Olympics <obj> participant of <subj> 2008 Summer Olympics <obj> participant of <subj> Brazil <obj> country of citizenship\n",
    "    \"\"\"\n",
    "    q = []\n",
    "    for no, triple in enumerate(triplets):\n",
    "        obj = ['<obj>'] + triple[1].split()\n",
    "        subj = ['<subj>'] + triple[2].split()\n",
    "        if no > 0 and triple[0] == triplets[no - 1][0]:\n",
    "            q.extend(subj + obj)\n",
    "        else:\n",
    "            triplet = ['<triplet>'] + triple[0].split()\n",
    "            q.extend(triplet + subj + obj)\n",
    "    return ' '.join(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "triples = filtered_kelm[1]['triples']\n",
    "q = rebel_format(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_list(parse_rebel(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
