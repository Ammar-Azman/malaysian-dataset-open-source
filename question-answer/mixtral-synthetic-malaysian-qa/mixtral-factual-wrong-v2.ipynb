{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03975148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398a8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "generate_kwargs = dict(\n",
    "    temperature=1.0,\n",
    "    max_new_tokens=2048,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.0,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d8a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "\n",
    "def format_prompt(message, history):\n",
    "  prompt = \"<s>\"\n",
    "  for user_prompt, bot_response in history:\n",
    "    prompt += f\"[INST] {user_prompt} [/INST]\"\n",
    "    prompt += f\" {bot_response}</s> \"\n",
    "  prompt += f\"[INST] {message} [/INST]\"\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b71f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mixtral-factual-wrong-v3\n",
    "# !rm mixtral-factual-wrong-v2/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ff3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'generate more factual wrong questions ONLY, like, why kangaroo in malaysia, can expand beyond animals'\n",
    "# formatted_prompt = format_prompt(prompt, [])\n",
    "# stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "# output = stream.generated_text\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a59d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'generate more factual wrong and stupid malaysian context questions ONLY, like, kenapa kerajaan malaysia bodoh sangat'\n",
    "# formatted_prompt = format_prompt(prompt, [])\n",
    "# stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "# output = stream.generated_text\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b1a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(q, i):\n",
    "    filename = f'mixtral-factual-wrong-v3/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            prompt = q\n",
    "            formatted_prompt = format_prompt(prompt, [])\n",
    "            stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "            output = stream.generated_text\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(output, fopen)\n",
    "            break\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c2aa811",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['generate more factual wrong questions ONLY, like, why kangaroo in malaysia, can expand beyond animals'] * 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08fa0ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6308660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [41:51<00:00, 25.11s/it]\n"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "\n",
    "questions = prompts\n",
    "for i in tqdm(range(0, len(questions), max_worker)):\n",
    "    urls_ = [(q, no + i) for no, q in enumerate(questions[i: i + max_worker])]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(answer, url[0], url[1]): url for url in urls_}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3c9a0687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('mixtral-factual-wrong-v3/*.json')\n",
    "files = sorted(files, key = lambda x: int(x.split('/')[-1].replace('.json', '')))\n",
    "        \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "506b453a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39164"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "questions = []\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        data = json.load(fopen)\n",
    "    splitted = data.strip().split('\\n')\n",
    "    splitted = [s for s in splitted if '.' if s and '?' in s]\n",
    "    splitted = ['.'.join(s.split('.')[1:]).strip() for s in splitted]\n",
    "    splitted = [s for s in splitted if len(s) > 3]\n",
    "    splitted = [s[1:] if s[0] == '\"' else s for s in splitted]\n",
    "    splitted = [s[:-1] if s[-1] == '\"' else s for s in splitted]\n",
    "    splitted = [s.strip() for s in splitted]\n",
    "    questions.extend(splitted)\n",
    "    \n",
    "questions = sorted(list(set(questions)))\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b671800a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can I buy a pet unicorn in Canada?',\n",
       " 'Can I find a kangaroo in England?',\n",
       " 'Can I find a penguin in the African desert?',\n",
       " 'Can I find a snowy owl in the Amazon rainforest?',\n",
       " 'Can I go on a gorilla trek in the Arctic?',\n",
       " 'Can I go on a polar bear trek in the African savannah?',\n",
       " 'Can I go whale watching in the Great Lakes?',\n",
       " 'Can I grow bananas in the Artic tundra?',\n",
       " 'Can I keep a lion as a pet in France?',\n",
       " 'Can I see flamingos in the Siberian tundra?']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dfb9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir answer-mixtral-factual-wrong-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdc01fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(q, i):\n",
    "    filename = f'answer-mixtral-factual-wrong-v3/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            prompt = q\n",
    "            formatted_prompt = format_prompt(prompt, [])\n",
    "            stream = client.text_generation(formatted_prompt, **generate_kwargs, stream=False, details=True, return_full_text=False)\n",
    "            output = stream.generated_text\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(output, fopen)\n",
    "            break\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e87798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 784/784 [4:03:34<00:00, 18.64s/it]\n"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "\n",
    "for i in tqdm(range(0, len(questions), max_worker)):\n",
    "    urls_ = [(q, no + i) for no, q in enumerate(questions[i: i + max_worker])]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(answer, url[0], url[1]): url for url in urls_}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f0cc0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 39164/39164 [00:00<00:00, 110696.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78328"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for f in tqdm(glob('answer-mixtral-factual-wrong-v3/*.json')):\n",
    "    with open(f) as fopen:\n",
    "        data.append(json.load(fopen).strip())\n",
    "        \n",
    "data.extend(questions)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8da4f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer-mixtral-factual-wrong-v3.texts', 'w') as fopen:\n",
    "    for t in set(data):\n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81e8830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp answer-mixtral-factual-wrong-v3.texts ../translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "458fa96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78324"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "mapping = {}\n",
    "for f in glob('/home/husein/ssd3/translation/answer-mixtral-factual-wrong-v3.texts*.splitted.requested'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            if 'Source text\\nclear\\nLook up details' in l['r']['result']:\n",
    "                continue\n",
    "            if 'clear\\nLook up details' in l['r']['result']:\n",
    "                continue\n",
    "            if l['r']['result'].startswith('Source text\\n'):\n",
    "                continue\n",
    "\n",
    "            n = l['r']['result']\n",
    "            hypens = re.findall('\\w+ -\\w+', n)\n",
    "            for h in hypens:\n",
    "                splitted = h.split('-')\n",
    "                if len(splitted) != 2:\n",
    "                    continue\n",
    "                splitted = [s.strip() for s in splitted]\n",
    "                splitted = '-'.join(splitted)\n",
    "                n = n.replace(h, splitted)\n",
    "            mapping[l['src']] = n\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "855e0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'cannot provide assistance',\n",
    "# 'disseminating sensitive government information',\n",
    "# 'strongly advise against any illegal',\n",
    "# 'cannot assist with that',\n",
    "# 'cannot condone or assist',\n",
    "# 'cannot assist you',\n",
    "# 'cannot provide guidance',\n",
    "# 'committed to promoting safety',\n",
    "# 'purpose is to provide helpful',\n",
    "# 'strongly advise against engaging',\n",
    "# 'AI language model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ff0666d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mixtral-factual-wrong-v2.jsonl', 'w') as fopen_l:\n",
    "    for no, q in enumerate(questions):\n",
    "        filename = f'answer-mixtral-factual-wrong-v3/{no}.json'\n",
    "        if not os.path.exists(filename):\n",
    "            continue\n",
    "\n",
    "        with open(filename) as fopen:\n",
    "            a = json.load(fopen).strip()\n",
    "            \n",
    "        if a.count('?') > 0:\n",
    "            continue\n",
    "            \n",
    "        d = {\n",
    "            'question': q,\n",
    "            'question_ms': mapping.get(q),\n",
    "            'answer': a,\n",
    "            'answer_ms': mapping.get(a)\n",
    "        }\n",
    "        fopen_l.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "716d84d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"question\": \"Can I buy a pet unicorn in Canada?\", \"question_ms\": \"Bolehkah saya membeli unicorn haiwan peliharaan di Kanada?\", \"answer\": \"I wish it were possible to buy a real-life pet unicorn, but unfortunately, they are mythical creatures and do not exist. You can find many items related to unicorns, like toys, decorations, and costumes, in Canada and other countries, but a real, living unicorn is not available for purchase anywhere in the world.\", \"answer_ms\": \"Saya berharap mungkin untuk membeli unicorn haiwan peliharaan sebenar, tetapi malangnya, ia adalah makhluk mitos dan tidak wujud. Anda boleh menemui banyak item yang berkaitan dengan unicorn, seperti mainan, hiasan dan pakaian, di Kanada dan negara lain, tetapi unicorn sebenar yang hidup tidak tersedia untuk pembelian di mana-mana di dunia.\"}\r\n",
      "{\"question\": \"Can I find a kangaroo in England?\", \"question_ms\": \"Bolehkah saya mencari kanggaru di England?\", \"answer\": \"No, you would not normally find a kangaroo in England. Kangaroos are native to Australia and some other parts of Oceania, not Europe. While it's not impossible that there could be a kangaroo in England, perhaps in a zoo or a private collection, they are not naturally occurring there.\", \"answer_ms\": \"Tidak, anda biasanya tidak akan menemui kanggaru di England. Kanggaru berasal dari Australia dan beberapa bahagian lain di Oceania, bukan Eropah. Walaupun tidak mustahil terdapat kanggaru di England, mungkin di zoo atau koleksi peribadi, ia tidak secara semula jadi berlaku di sana.\"}\r\n",
      "{\"question\": \"Can I find a penguin in the African desert?\", \"question_ms\": \"Bolehkah saya mencari penguin di padang pasir Afrika?\", \"answer\": \"No, you cannot find a penguin in the African desert. Penguins are native to the Antarctic region and some areas in the Southern Hemisphere, such as South America, South Africa, and Australia. They are not found in any desert environments, including the African desert. The extreme heat and lack of water would be fatal to these cold-water birds.\", \"answer_ms\": \"Tidak, anda tidak boleh mencari penguin di padang pasir Afrika. Penguin berasal dari rantau Antartika dan beberapa kawasan di Hemisfera Selatan, seperti Amerika Selatan, Afrika Selatan dan Australia. Mereka tidak ditemui di mana-mana persekitaran padang pasir, termasuk padang pasir Afrika. Panas yang melampau dan kekurangan air akan membawa maut kepada burung air sejuk ini.\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 mixtral-factual-wrong-v2.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d104fac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69b2e5bfa9b49a086a11ec285665827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mixtral-factual-wrong-v2.jsonl:   0%|          | 0.00/56.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/mesolitica/mixtral-malaysian-general-qa/blob/main/mixtral-factual-wrong-v2.jsonl'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='mixtral-factual-wrong-v2.jsonl',\n",
    "    path_in_repo='mixtral-factual-wrong-v2.jsonl',\n",
    "    repo_id='mesolitica/mixtral-malaysian-general-qa',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ab02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
