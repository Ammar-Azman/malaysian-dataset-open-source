{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368e9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('prepared-wikipedia-llama3.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if len(l['text']) < 512:\n",
    "            continue\n",
    "        data.append(l['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234e4737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97963"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39277104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generate-wikipedia-qa-llama3’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf generate-wikipedia-qa-llama3\n",
    "!mkdir generate-wikipedia-qa-llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695d750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97963"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    s = \"\"\"\n",
    "```\n",
    "{{replace_me}}\n",
    "```\n",
    "\n",
    "Generate list of QA choice in malay, return in JSON [{'question', 'A', 'B', 'C', 'D', 'answer'}]\n",
    "    \"\"\".strip()\n",
    "    s = s.replace('{{replace_me}}', data[i])\n",
    "    results.append(s)\n",
    "        \n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c577ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "def answer(q, i):\n",
    "    filename = f'generate-wikipedia-qa-llama3/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    openai = OpenAI(\n",
    "        base_url='https://llama-3.us.mesolitica.com/v1',\n",
    "        api_key='empty',\n",
    "    )\n",
    "    for _ in range(1):\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                \n",
    "                json_data = {\n",
    "                    'messages': [\n",
    "                        {\n",
    "                            'role': 'user',\n",
    "                            'content': q,\n",
    "                        },\n",
    "                    ],\n",
    "                    'model': 'model',\n",
    "                    'stop': [\n",
    "                        '<|eot_id|>',\n",
    "                    ],\n",
    "                    'temperature': 0.9,\n",
    "                    'max_tokens': 2048,\n",
    "                }\n",
    "                response = requests.post(\n",
    "                    'https://llama-3.us.mesolitica.com/v1/chat/completions', \n",
    "                    headers=headers, json=json_data, timeout = 60 * 10)\n",
    "                \n",
    "                r = response.json()['choices'][0]['message']['content']\n",
    "                results.append(r)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "                \n",
    "    \n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(results, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0f6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ec131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [(q, no) for no, q in enumerate(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaffe556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer(*urls[10005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c55c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "\n",
    "queue = Queue()\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983c3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████▌ | 96022/97963 [31:13:03<25:29,  1.27it/s]"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('generate-wikipedia-qa/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ec00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files[0]) as fopen:\n",
    "    d = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc144fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e97374",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[77747]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2525db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('prepared-wikipedia.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if len(l['text']) < 512:\n",
    "            continue\n",
    "        data.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(q.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppose = {'question', 'A', 'B', 'C', 'D', 'answer'}\n",
    "len(set(q.keys()) | suppose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78321af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('generated-wikipedia-qa.jsonl', 'w') as fopen_j:\n",
    "    for i in tqdm(range(len(data))):\n",
    "        f = f'generate-wikipedia-qa/{i}.json'\n",
    "        if not os.path.exists(f):\n",
    "            continue\n",
    "            \n",
    "        with open(f) as fopen:\n",
    "            d = json.load(fopen)\n",
    "        \n",
    "        questions = []\n",
    "        unique_questions = set()\n",
    "        for d_ in d:\n",
    "            try:\n",
    "                qa = json.loads(d_)['arguments']['qa']\n",
    "                for q in qa:\n",
    "                    if len(set(q.keys()) | suppose) != len(suppose):\n",
    "                        continue\n",
    "                    if q['question'].lower() not in unique_questions:\n",
    "                        if not ('A' in q and isinstance(q['A'], str)):\n",
    "                            continue\n",
    "                        if not ('B' in q and isinstance(q['B'], str)):\n",
    "                            continue\n",
    "                        if not ('C' in q and isinstance(q['C'], str)):\n",
    "                            continue\n",
    "                        if not ('D' in q and isinstance(q['D'], str)):\n",
    "                            continue\n",
    "                        if not ('answer' in q and isinstance(q['answer'], str)):\n",
    "                            continue\n",
    "                            \n",
    "                        for k in suppose:\n",
    "                            q[k] = q[k].encode(\"utf8\", errors=\"surrogatepass\").decode(\"utf8\")\n",
    "\n",
    "                        questions.append(q)\n",
    "                        unique_questions.add(q['question'].lower())\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        data[i]['text'] = data[i]['text'].encode(\"utf8\", errors=\"surrogatepass\").decode(\"utf8\")\n",
    "        data[i]['questions'] = questions\n",
    "        fopen_j.write(f'{json.dumps(data[i])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5d8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wc -l generated-wikipedia-qa.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh generated-wikipedia-qa.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "with open('generated-wikipedia-qa.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        \n",
    "        d.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3511e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f73ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub('mesolitica/mallam-small-malaysian-qa-choice', split = 'wikipedia')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
