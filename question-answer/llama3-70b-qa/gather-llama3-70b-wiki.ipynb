{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c282adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9705091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('prepared-wikipedia-llama3.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if len(l['text']) < 512:\n",
    "            continue\n",
    "        data.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf3c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppose = {'question', 'A', 'B', 'C', 'D', 'answer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d673631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91635"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('generate-wikipedia-qa-llama3/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23093609",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files[0]) as fopen:\n",
    "    d = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4a19a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = []\n",
    "for d_ in d[0].split('```'):\n",
    "    try:\n",
    "        selected.append(json.loads(d_))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f487ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'question': 'Di manakah beribu pejabat Stora Enso Oyj?',\n",
       "   'A': 'Stockholm, Sweden',\n",
       "   'B': 'Helsinki, Finland',\n",
       "   'C': 'Oslo, Norway',\n",
       "   'D': 'Copenhagen, Denmark',\n",
       "   'answer': 'B'},\n",
       "  {'question': 'Apabila syarikat Stora Enso dibentuk?',\n",
       "   'A': '1980',\n",
       "   'B': '1998',\n",
       "   'C': '2001',\n",
       "   'D': '2010',\n",
       "   'answer': 'B'},\n",
       "  {'question': 'Berapa ramai pekerja Stora Enso pada tahun 2018?',\n",
       "   'A': '20,000',\n",
       "   'B': '26,000',\n",
       "   'C': '30,000',\n",
       "   'D': '35,000',\n",
       "   'answer': 'B'},\n",
       "  {'question': 'Di mana terdapat operasi penting Stora Enso?',\n",
       "   'A': 'Eropah sahaja',\n",
       "   'B': 'Asia, Amerika Selatan dan Amerika Syarikat',\n",
       "   'C': 'Afrika dan Australia',\n",
       "   'D': 'Semua di atas',\n",
       "   'answer': 'B'},\n",
       "  {'question': 'Pada tahun 2015, Stora Enso menduduki tempat keberapa dalam jualan?',\n",
       "   'A': 'Kelima',\n",
       "   'B': 'Ketujuh',\n",
       "   'C': 'Kesembilan',\n",
       "   'D': 'Kesebelas',\n",
       "   'answer': 'B'},\n",
       "  {'question': 'Apakah tahun penerbitan sijil saham terpelihara yang tertua di dunia?',\n",
       "   'A': '1200',\n",
       "   'B': '1288',\n",
       "   'C': '1300',\n",
       "   'D': '1400',\n",
       "   'answer': 'B'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60aa4fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 97963/97963 [00:06<00:00, 14866.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open('generated-wikipedia-qa-llama3.jsonl', 'w') as fopen_j:\n",
    "    for i in tqdm(range(len(data))):\n",
    "        f = f'generate-wikipedia-qa-llama3/{i}.json'\n",
    "        if not os.path.exists(f):\n",
    "            continue\n",
    "            \n",
    "        with open(f) as fopen:\n",
    "            d = json.load(fopen)\n",
    "        \n",
    "        questions = []\n",
    "        unique_questions = set()\n",
    "        for d_ in d:\n",
    "            try:\n",
    "                selected = []\n",
    "                for d__ in d_.split('```'):\n",
    "                    try:\n",
    "                        selected.append(json.loads(d__))\n",
    "                    except:\n",
    "                        pass\n",
    "                if not len(selected):\n",
    "                    continue\n",
    "                qa = selected[0]\n",
    "                for q in qa:\n",
    "                    if len(set(q.keys()) | suppose) != len(suppose):\n",
    "                        continue\n",
    "                    if q['question'].lower() not in unique_questions:\n",
    "                        if not ('A' in q and isinstance(q['A'], str)):\n",
    "                            continue\n",
    "                        if not ('B' in q and isinstance(q['B'], str)):\n",
    "                            continue\n",
    "                        if not ('C' in q and isinstance(q['C'], str)):\n",
    "                            continue\n",
    "                        if not ('D' in q and isinstance(q['D'], str)):\n",
    "                            continue\n",
    "                        if not ('answer' in q and isinstance(q['answer'], str)):\n",
    "                            continue\n",
    "                            \n",
    "                        for k in suppose:\n",
    "                            q[k] = q[k].encode(\"utf8\", errors=\"surrogatepass\").decode(\"utf8\")\n",
    "\n",
    "                        questions.append(q)\n",
    "                        unique_questions.add(q['question'].lower())\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if not len(questions):\n",
    "            continue\n",
    "        \n",
    "        data[i]['text'] = data[i]['text'].encode(\"utf8\", errors=\"surrogatepass\").decode(\"utf8\")\n",
    "        data[i]['questions'] = questions\n",
    "        fopen_j.write(f'{json.dumps(data[i])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a8d1d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eba1b67e6b449128437b4fc13204375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generated-wikipedia-qa-llama3.jsonl:   0%|          | 0.00/339M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/llama-3-70b-qa/commit/286a50d6181c49dfd3d2ee62908d154a4180bf12', commit_message='Upload generated-wikipedia-qa-llama3.jsonl with huggingface_hub', commit_description='', oid='286a50d6181c49dfd3d2ee62908d154a4180bf12', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='generated-wikipedia-qa-llama3.jsonl',\n",
    "    path_in_repo='generated-wikipedia-qa-llama3.jsonl',\n",
    "    repo_id='mesolitica/llama-3-70b-qa',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3db58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
