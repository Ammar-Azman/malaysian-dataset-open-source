{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_news = glob('/home/ubuntu/server2/google-translate-english-news/*.requested')\n",
    "len(english_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/server2/google-translate-english-news/cnn.txt31.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt19.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt12.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt16.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt23.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt18.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt25.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt00.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt09.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt05.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt04.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt11.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt01.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt14.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt24.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt13.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt28.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt02.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt17.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt22.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt26.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt07.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt30.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt08.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt03.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt15.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt21.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt27.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt29.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt10.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt06.splitted.requested',\n",
       " '/home/ubuntu/server2/google-translate-english-news/cnn.txt20.splitted.requested']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt31.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18837it [00:00, 457537.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt19.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 446656.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt12.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 430232.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt16.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 432425.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt23.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 433497.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt18.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 429322.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt25.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 433858.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt00.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 436230.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt09.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 434942.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt05.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 437211.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt04.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 432695.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt11.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 430400.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt01.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 430687.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt14.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 430214.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt24.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 424520.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt13.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 429401.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt28.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 429146.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt02.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 433252.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt17.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 221331.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt22.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 156440.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt26.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 180810.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt07.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 216881.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt30.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 223014.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt08.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 221409.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt03.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 222228.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt15.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 217812.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt21.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 217593.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt27.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 219123.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt29.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 222208.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt10.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 220014.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt06.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99999it [00:00, 224001.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/server2/google-translate-english-news/cnn.txt20.splitted.requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 216885.99it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for f in english_news:\n",
    "    print(f)\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            data.append({\n",
    "                'en': l['src'],\n",
    "                'ms': l['r']['result']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3118836"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Source text\\nclear\\nLook up details'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'When the crisis came, with interest rates moving up sharply in the secondary market for government bonds, the first reaction was denial; then a wave of austerity measures.',\n",
       " 'ms': 'Apabila krisis datang, dengan kadar faedah meningkat secara mendadak dalam pasaran sekunder untuk bon kerajaan, reaksi pertama ialah penafian; maka gelombang langkah penjimatan.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install transformers -U\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 14:08:47.193730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-15 14:08:47.280690: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-15 14:08:47.706705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-15 14:08:47.706763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-15 14:08:47.706768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('BAAI/bge-large-en')\n",
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(encoded_input):\n",
    "    encoded_input = {'input_ids': encoded_input.unsqueeze(0)}\n",
    "    for k in encoded_input:\n",
    "        encoded_input[k] = encoded_input[k].cuda()\n",
    "\n",
    "    model_output = model(**encoded_input)\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "    v = sentence_embeddings[0].detach().cpu().numpy()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import islice\n",
    "\n",
    "def batched(iterable, n):\n",
    "    \"\"\"\n",
    "    Batch data into tuples of length n. The last batch may be shorter.\n",
    "    \"\"\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while (batch := tuple(islice(it, n))):\n",
    "        yield batch\n",
    "\n",
    "def get_tokens(text):\n",
    "    encoded_input = tokenizer.encode(text,\n",
    "                             return_tensors='pt')\n",
    "    return encoded_input[0]\n",
    "\n",
    "def chunked_tokens(text, chunk_length):\n",
    "    tokens = get_tokens(text)\n",
    "    chunks_iterator = batched(tokens, chunk_length)\n",
    "    yield from chunks_iterator\n",
    "    \n",
    "def len_safe_get_embedding(\n",
    "    text,\n",
    "    max_tokens=512,\n",
    "    average=True\n",
    "):\n",
    "    chunk_embeddings = []\n",
    "    chunk_lens = []\n",
    "    for chunk in chunked_tokens(text, chunk_length=max_tokens):\n",
    "        \n",
    "        chunk = torch.Tensor(chunk).long()\n",
    "        \n",
    "        chunk_embeddings.append(embedding(chunk))\n",
    "        chunk_lens.append(len(chunk))\n",
    "\n",
    "    if average:\n",
    "        chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)\n",
    "        chunk_embeddings = chunk_embeddings / np.linalg.norm(chunk_embeddings)\n",
    "        chunk_embeddings = chunk_embeddings.tolist()\n",
    "    return chunk_embeddings\n",
    "\n",
    "len_safe_get_embedding(data[1]['en'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir english-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = 'Represent this sentence for searching relevant passages: '\n",
    "examples = [instruction + data[i]['en'] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = []\n",
    "for s in examples:\n",
    "    vs.append(len_safe_get_embedding(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70589901, 1.        , 0.70439388, 0.71524876, 0.726346  ,\n",
       "       0.75872452, 0.75125941, 0.72164168, 0.75889558, 0.79737995])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(vs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Represent this sentence for searching relevant passages: Argentina brought back Domingo Cavallo, the architect of its Houdini-like escape from hyperinflation half a decade earlier.',\n",
       " 'Represent this sentence for searching relevant passages: The increasingly hectic political moves over the last week in Greece are also reminding many veterans of emerging market crises of the Argentine case.')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[1], examples[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                    | 139073/3118836 [30:22<10:47:12, 76.73it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 11%|█████████▋                                                                             | 348258/3118836 [1:15:16<9:35:03, 80.30it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 17%|███████████████                                                                        | 541619/3118836 [1:57:15<9:28:46, 75.52it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 24%|█████████████████████                                                                  | 753900/3118836 [2:39:34<7:11:44, 91.29it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 32%|███████████████████████████▌                                                           | 986597/3118836 [3:22:09<6:23:35, 92.64it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 38%|████████████████████████████████▍                                                     | 1177421/3118836 [3:57:19<6:03:18, 89.06it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 39%|█████████████████████████████████▎                                                    | 1208161/3118836 [4:02:56<5:47:17, 91.69it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 46%|███████████████████████████████████████▏                                              | 1419759/3118836 [4:42:00<5:07:48, 92.00it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████████████████████████████████████████████▏                                        | 1637294/3118836 [5:22:04<4:35:31, 89.62it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 60%|███████████████████████████████████████████████████▎                                  | 1862996/3118836 [6:03:15<3:51:06, 90.56it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 66%|█████████████████████████████████████████████████████████▏                            | 2071894/3118836 [6:41:43<3:14:19, 89.80it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████▉               | 2573942/3118836 [8:14:09<1:41:20, 89.61it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████████████▎  | 3025032/3118836 [9:37:25<17:15, 90.59it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    filename = os.path.join('english-news', f'{i}.json')\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        v = len_safe_get_embedding(instruction + data[i]['en'])\n",
    "        d = {\n",
    "            'text': data[i],\n",
    "            'v': v,\n",
    "        }\n",
    "        with open(filename, 'w') as fopen:\n",
    "            fopen.write(f'{json.dumps(d)}\\n')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs english-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
