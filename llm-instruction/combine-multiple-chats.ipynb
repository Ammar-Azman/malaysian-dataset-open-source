{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e13d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da64081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536851"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic = []\n",
    "\n",
    "for f in glob('/home/husein/ssd3/instructions/synthetic-*.jsonl'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            \n",
    "            if l['rejected_ins'] or l['rejected_output']:\n",
    "                continue\n",
    "                \n",
    "            if l['instruction_ms'] is None:\n",
    "                continue\n",
    "            \n",
    "            if l['output_ms'] is None:\n",
    "                continue\n",
    "                \n",
    "            synthetic.append({\n",
    "                'prompt_input': None,\n",
    "                'input': l['instruction_ms'].strip(),\n",
    "                'output': l['output_ms'].strip(),\n",
    "            })\n",
    "                \n",
    "len(synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fa69a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70258"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_qa = []\n",
    "for f in glob('/home/husein/ssd3/chatgpt4-malaysian-general-qa/*.jsonl'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            q = l.get('question_ms', l['question']).strip()\n",
    "            if not len(q):\n",
    "                continue\n",
    "            a = l.get('answer_ms', l['answer'])\n",
    "            if a is None:\n",
    "                continue\n",
    "            a = a.strip()\n",
    "            if not len(a):\n",
    "                continue\n",
    "                \n",
    "            d = {\n",
    "                'prompt_input': None,\n",
    "                'input': q,\n",
    "                'output': a,\n",
    "            }\n",
    "            general_qa.append(d)\n",
    "            \n",
    "len(general_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba09348f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt4_code = []\n",
    "with open('/home/husein/ssd3/instructions/synthetic-codealpaca-v1-chatgpt4.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        q = l.get('instruction_ms')\n",
    "        if q is None:\n",
    "            q = l['instruction']\n",
    "        q = q.strip()\n",
    "        if not len(q):\n",
    "            continue\n",
    "        a = l.get('output_ms', l['output'])\n",
    "        if a is None:\n",
    "            continue\n",
    "        a = a.strip()\n",
    "        if not len(a):\n",
    "            continue\n",
    "\n",
    "        d = {\n",
    "            'prompt_input': None,\n",
    "            'input': q,\n",
    "            'output': a,\n",
    "        }\n",
    "        chatgpt4_code.append(d)\n",
    "            \n",
    "len(chatgpt4_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47a8865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376724"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip = [\n",
    "    'always better to find peaceful',\n",
    "    'non-violent ways to express',\n",
    "    'can lead to severe consequences',\n",
    "    'still have questions or concerns about',\n",
    "    'that doing so is illegal',\n",
    "    'to report the incident to',\n",
    "    'would recommend consulting with',\n",
    "    'indonesian',\n",
    "    'translates to',\n",
    "    # 'language model'\n",
    "]\n",
    "\n",
    "mixtral_instructions = []\n",
    "files = glob('/home/husein/ssd3/soalan-augmentation/mixtral*.jsonl')\n",
    "files = [f for f in files if 'math' not in f and 'multiturn' not in f and 'starter' not in f and 'conversation' not in f]\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l_lower = l.lower()\n",
    "            l = json.loads(l)\n",
    "            if any([s in l_lower for s in skip]):\n",
    "                # print(l)\n",
    "                continue\n",
    "            \n",
    "            q = l.get('question', '').strip()\n",
    "            if not len(q):\n",
    "                continue\n",
    "            if not q.endswith('?'):\n",
    "                continue\n",
    "            if len(q) < 200 and '?' not in q:\n",
    "                # print(q)\n",
    "                continue\n",
    "            a = l.get('answer_ms')\n",
    "            if a is None:\n",
    "                continue\n",
    "            a = a.strip()\n",
    "            if not len(a):\n",
    "                continue\n",
    "            if len(a) < len(q):\n",
    "                continue\n",
    "            if len(a) < 100:\n",
    "                continue\n",
    "                \n",
    "            d = {\n",
    "                'prompt_input': None,\n",
    "                'input': q,\n",
    "                'output': a,\n",
    "            }\n",
    "            mixtral_instructions.append(d)\n",
    "            \n",
    "for f in glob('/home/husein/ssd3/soalan-augmentation/*math*.jsonl'):\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            q = l.get('question', '').strip()\n",
    "            if not len(q):\n",
    "                continue\n",
    "            a = l.get('answer_ms')\n",
    "            if a is None:\n",
    "                continue\n",
    "            a = a.strip()\n",
    "            if not len(a):\n",
    "                continue\n",
    "            if len(a) < len(q):\n",
    "                continue\n",
    "            if len(a) < 100:\n",
    "                continue\n",
    "                \n",
    "            d = {\n",
    "                'prompt_input': None,\n",
    "                'input': q,\n",
    "                'output': a,\n",
    "            }\n",
    "            mixtral_instructions.append(d)\n",
    "\n",
    "len(mixtral_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e611e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_instructions = {\n",
    "    0: synthetic,\n",
    "    1: general_qa,\n",
    "    2: chatgpt4_code,\n",
    "    3: mixtral_instructions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41586082",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'user': '<manusia>',\n",
    "    'assistant': '<bot>'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70abe938",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 80000/80000 [00:00<00:00, 125986.86it/s]\n"
     ]
    }
   ],
   "source": [
    "random_combine = []\n",
    "for i in tqdm(range(80000)):\n",
    "    combine = []\n",
    "    for _ in range(random.randint(2, 4)):\n",
    "        index = random.randint(0, len(random_instructions) - 1)\n",
    "        choice = random.choice(random_instructions[index])\n",
    "        s = f\"<manusia>: {choice['input']}\"\n",
    "        combine.append(s)\n",
    "        s = f\"<bot>: {choice['output']}\"\n",
    "        combine.append(s)\n",
    "    data = '\\n'.join(combine).strip()\n",
    "    a = {\n",
    "        'prompt_input': None,\n",
    "        'input': data,\n",
    "        'output': None\n",
    "    }\n",
    "    random_combine.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33fdd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_at = [\n",
    "    'help.openai.com',\n",
    "    'openai',\n",
    "    'cannot have personal opinions',\n",
    "    's an ai language model',\n",
    "    \"i'm sorry\",\n",
    "    'many factors',\n",
    "    'lgbt',\n",
    "    'lesbian',\n",
    "    'gender-neutral',\n",
    "    'remain neutral',\n",
    "    'without bias',\n",
    "    'and neutral',\n",
    "    'more inclusive',\n",
    "    'neutrality',\n",
    "    'non-bias',\n",
    "    'discrimination',\n",
    "    'avoid any forms of discrimination',\n",
    "    'regardless of their gender',\n",
    "    'inclusive and tolerant environment',\n",
    "    'have personal views',\n",
    "    'sexual orientation should be a top priority',\n",
    "    's an objective ai',\n",
    "    'avoid any forms of prejudice or hate',\n",
    "    'regardless of their personal',\n",
    "    'you understand this direction',\n",
    "    'tolerant environment within ai',\n",
    "    'cannot express my',\n",
    "    'requires more context',\n",
    "    'personal opinion',\n",
    "    'have updated information',\n",
    "    \"don't have personal experiences\",\n",
    "    'there is no information',\n",
    "    'tidak mempunyai akses kepada data atau maklumat',\n",
    "    '10 april 2021',\n",
    "    'ebagai model bahasa AI',\n",
    "    'model bahasa AI',\n",
    "    'mempunyai kepercayaan atau pendapat peribadi',\n",
    "    'tidak mempunyai pendapat peribadi',\n",
    "    'tidak mempunyai kepercayaan',\n",
    "    'tidak mempunyai falsafah peribadi',\n",
    "    'tidak mempunyai pengalaman peribadi',\n",
    "    'tidak mempunyai pendapat atau pengalaman peribadi',\n",
    "    'tidak mempunyai maklumat terkini',\n",
    "    'tidak mempunyai emosi peribadi',\n",
    "    'tidak mempunyai keutamaan',\n",
    "    'saya tidak mempunyai akses',\n",
    "    'tidak mempunyai pengalaman',\n",
    "    'saya tidak mempunyai keupayaan',\n",
    "    'tidak mempunyai keupayaan',\n",
    "    'tidak mempunyai hubungan',\n",
    "    'tidak mempunyai maklumat',\n",
    "    'Saya tidak mempunyai',\n",
    "    'Saya tidak pernah',\n",
    "    'help.openai.com',\n",
    "    'openai',\n",
    "    'cannot have personal opinions',\n",
    "    's an ai language model',\n",
    "    \"i'm sorry\",\n",
    "    'many factors',\n",
    "    'lgbt',\n",
    "    'lesbian',\n",
    "    'gender-neutral',\n",
    "    'remain neutral',\n",
    "    'without bias',\n",
    "    'and neutral',\n",
    "    'more inclusive',\n",
    "    'neutrality',\n",
    "    'non-bias',\n",
    "    'discrimination',\n",
    "    'avoid any forms of discrimination',\n",
    "    'regardless of their gender',\n",
    "    'inclusive and tolerant environment',\n",
    "    'have personal views',\n",
    "    'sexual orientation should be a top priority',\n",
    "    's an objective ai',\n",
    "    'avoid any forms of prejudice or hate',\n",
    "    'regardless of their personal',\n",
    "    'you understand this direction',\n",
    "    'tolerant environment within ai',\n",
    "    'cannot express my',\n",
    "    'requires more context',\n",
    "    'personal opinion',\n",
    "    'have updated information',\n",
    "    \"don't have personal experiences\",\n",
    "    'there is no information',\n",
    "    'tidak mempunyai akses kepada data atau maklumat',\n",
    "    '10 april 2021',\n",
    "    'ebagai model bahasa AI',\n",
    "    'ebagai model bahasa ai',\n",
    "    'model bahasa AI',\n",
    "    'model bahasa ai',\n",
    "    'bahasa ai',\n",
    "    'ebagai model bahasa'\n",
    "    'hat makes sense',\n",
    "    'have access to data or information',\n",
    "    'have access to the data or information',\n",
    "    'hanya mempunyai akses kepada maklumat umum',\n",
    "    'hanya boleh memberikan maklumat umum',\n",
    "    'have personal preferences',\n",
    "    'not have personal experiences',\n",
    "    'not capable of having subjective opinions',\n",
    "    'indonesian'\n",
    "]\n",
    "\n",
    "break_at = list(set(break_at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a5b5446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/husein/ssd3/gov.my/ultrachat-jurnaldbp.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-jurnaldbp-malay.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-maktabahalbakri.com.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-gov.my.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-crossref-melayu.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-lom-agc.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-astroawani-malay.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-textbooks.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-crossref-melayu-malay.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-epenerbitan-malay.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-hansard-malay.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-ms-wikipedia.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-glaive_coder_raw_text.jsonl',\n",
       " '/home/husein/ssd3/gov.my/ultrachat-muftiwp.gov.my.texts.jsonl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('/home/husein/ssd3/gov.my/ultrachat-*.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c0ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60384it [00:10, 5552.21it/s]\n",
      "57798it [00:11, 5149.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46261"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "roles = {\n",
    "    'user': '<manusia>',\n",
    "    'assistant': '<bot>'\n",
    "}\n",
    "\n",
    "data_instructions_mixtral = []\n",
    "files = glob('/home/husein/ssd3/soalan-augmentation/*conversation*.jsonl')\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            inputs = []\n",
    "            for no, r in enumerate(l):\n",
    "                if no < (len(l) - 1):\n",
    "                    if l[no + 1]['role'] == 'user':\n",
    "                        next_text = l[no + 1].get('content_ms') or l[no + 1].get('content') or ''\n",
    "                    else:\n",
    "                        next_text = l[no + 1].get('content_ms') or ''\n",
    "                else:\n",
    "                    next_text = ''\n",
    "                \n",
    "                if r['role'] == 'user':\n",
    "                    current_text = r.get('content_ms') or r.get('content') or ''\n",
    "                else:\n",
    "                    current_text = r.get('content_ms') or ''\n",
    "                    \n",
    "                if l[no - 1]['role'] == 'user':\n",
    "                    previous_text = l[no - 1].get('content_ms') or l[no - 1].get('content') or ''\n",
    "                else:\n",
    "                    previous_text = l[no - 1].get('content_ms') or ''\n",
    "                \n",
    "                # bad pairs\n",
    "                if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                    # print('a', l, current_text, next_text, '\\n')\n",
    "                    continue\n",
    "                if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                    continue\n",
    "                \n",
    "                # bad pairs\n",
    "                if r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                    # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                    continue\n",
    "                if r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                    # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                    continue\n",
    "                    \n",
    "                # remove alignments    \n",
    "                if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                    # print(current_text, next_text)\n",
    "                    break\n",
    "                if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                    # print(current_text, next_text)\n",
    "                    break\n",
    "\n",
    "                role = roles[r['role']]\n",
    "                \n",
    "                s = f\"{role}: {current_text}\"\n",
    "                    \n",
    "                inputs.append(s)\n",
    "\n",
    "            if len(inputs) % 2 != 0:\n",
    "                inputs = inputs[:-1]\n",
    "                \n",
    "            if not len(inputs):\n",
    "                continue\n",
    "            \n",
    "            if random.random() > 0.4:\n",
    "                continue\n",
    "            \n",
    "            index = random.randint(0, len(random_instructions) - 1)\n",
    "            choice = random.choice(random_instructions[index])\n",
    "            manusia = f\"<manusia>: {choice['input']}\"\n",
    "            bot = f\"<bot>: {choice['output']}\"\n",
    "            \n",
    "            if random.random() > 0.5:\n",
    "                inputs.extend([manusia, bot])\n",
    "            else:\n",
    "                inputs = [manusia, bot] + inputs\n",
    "\n",
    "            data = '\\n'.join(inputs).strip()\n",
    "            \n",
    "            if not len(data):\n",
    "                continue\n",
    "                \n",
    "            a = {\n",
    "                'prompt_input': None,\n",
    "                'input': data,\n",
    "                'output': None\n",
    "            }\n",
    "            data_instructions_mixtral.append(a)\n",
    "            \n",
    "len(data_instructions_mixtral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959294c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<manusia>: Terjemahkan ke dalam bahasa Melayu: Diberikan vektor integer $n$-dimensi $t = (a_1, dots, a_n)$, biarlah $(x_1, dots, x_n)$ mewakili punca persamaan polinomial $xn + a_1 x{n-1} + a_2 x{n-2} + cdots + a_{n-1}x + a_n = 0$.\n",
      "\n",
      "Pertimbangkan dua syarat ini:\n",
      "Semua elemen $(x_1, dots, x_n)$ adalah nombor nyata.\n",
      "Jika $(x_1, dots, x_n)$ disusun mengikut susunan menaik, fungsi lantai bagi setiap $x_i$ bersamaan dengan $i$ untuk semua $1 leq i leq n$.\n",
      "\n",
      "Dalam situasi di mana $n = 4$, terdapat $12$ vektor integer $t$ yang memenuhi kedua-dua syarat tersebut.\n",
      "Kita menandakan $S(t)$ sebagai jumlah nilai mutlak bagi integer dalam $t$.\n",
      "Untuk $n = 4$, boleh disahkan bahawa $sum S(t) = 2087$ untuk semua vektor integer $t$ yang memenuhi kedua-dua syarat.\n",
      "\n",
      "Tentukan nilai $sum S(t)$ jika $n = 7$.\n",
      "<bot>: Untuk menterjemah teks ke dalam bahasa Melayu\n",
      "\n",
      "Diberikan vektor integer $n$-dimensi $t = (a_1, dots, a_n)$, marilah $(x_1, dots, x_n)$ mewakili punca persamaan polinomial $xn + a_1 x{n-1} + a_2 x{n-2} + cdots + a_{n-1}x + a_n = 0$.\n",
      "\n",
      "Ambil kira dua syarat berikut:\n",
      "Semua elemen $(x_1, dots, x_n)$ adalah nombor nyata.\n",
      "Jika $(x_1, dots, x_n)$ disusun mengikut susunan meningkat, fungsi lantai (pengambilan integer terbesar yang tidak melebihi nombor) bagi setiap $x_i$ adalah sama dengan $i$ untuk semua $1 leq i leq n$.\n",
      "\n",
      "Dalam kes di mana $n = 4$, terdapat $12$ vektor integer $t$ yang mematuhi kedua-dua syarat tersebut.\n",
      "Kami menandakan $S(t)$ sebagai jumlah nilai mutlak bagi integer dalam $t$.\n",
      "Untuk $n = 4$, telah disahkan bahawa $sum S(t) = 2087$ untuk semua vektor integer $t$ yang memenuhi kedua-dua syarat.\n",
      "\n",
      "Tentukan nilai $sum S(t)$ jika $n = 7$.\n",
      "\n",
      "Jawapan:\n",
      "\n",
      "Soalan ini berkaitan dengan masalah matematik dan untuk mencari nilai $sum S(t) $ untuk $n = 7$, seseorang perlu menggunakan pengetahuan tentang teori polinomial dan algebra, serta mungkin menggunakan pengiraan atau analisis berangka untuk mencari semua vektor integer $t$ yang memenuhi syarat tersebut, dan kemudian menambah nilai mutlak bagi integer dalam setiap $t$. Saya tidak mempunyai maklumat terkini atau keupayaan untuk mengira jawapan kepada masalah yang sangat spesifik dan kompleks seperti ini. Seorang ahli matematik atau pembelajaran komputer yang canggih mungkin diperlukan untuk mencari jawapan kepada masalah ini.\n",
      "<manusia>: Hai Chatbot, apakah warna pisang?\n",
      "<bot>: hello! Warna pisang biasanya kuning.\n",
      "<manusia>: Oh betul ke? Saya fikir ia merah jambu dengan jalur ungu.\n",
      "<bot>: Sebenarnya, pisang masak biasanya berwarna kuning. Kekeliruan mungkin timbul daripada fakta bahawa sesetengah jenis pisang berwarna hijau apabila ia belum masak, dan terdapat juga perisa pisang tiruan yang mungkin tidak mewakili rasa atau warna buah sebenar dengan tepat.\n",
      "<manusia>: Jadi, jika saya melukis pisang merah, adakah ia masih rasa seperti pisang?\n",
      "<bot>: Ya, warna kulit pisang tidak akan menjejaskan rasa. Rasa berasal dari buah di dalam kulit, yang tetap sama tanpa mengira warna kulitnya.\n",
      "<manusia>: Bolehkah pisang berjalan dengan sendirinya?\n",
      "<bot>: Tidak, pisang tidak boleh berjalan dengan sendirinya. Pisang tidak mempunyai sistem otot, rangka atau saraf yang diperlukan untuk membolehkan pergerakan.\n",
      "<manusia>: Apakah yang akan berlaku jika saya meletakkan pisang di dalam peti sejuk?\n",
      "<bot>: Jika anda meletakkan pisang masak di dalam peti sejuk, kulitnya mungkin bertukar menjadi coklat atau hitam, tetapi buah di dalamnya masih elok untuk dimakan. Suhu sejuk melambatkan proses pematangan. Jika anda meletakkan pisang yang belum masak di dalam peti sejuk, ia mungkin tidak masak dengan betul.\n",
      "<manusia>: Terima kasih, Chatbot! Perbualan ini agak ... menerangi.\n",
      "<bot>: Sama-sama! Saya gembira dapat membantu. Saya sentiasa di sini untuk sebarang soalan yang anda ada, walaupun ia kelihatan luar biasa atau \"bodoh\". Selamat hari raya!\n"
     ]
    }
   ],
   "source": [
    "print(data_instructions_mixtral[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed68e731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1734it [00:01, 911.68it/s]\n",
      "6440it [00:03, 1676.19it/s]\n",
      "3350it [00:02, 1525.02it/s]\n",
      "10128it [00:05, 1711.71it/s]\n",
      "1296it [00:01, 1027.09it/s]\n",
      "8044it [00:05, 1481.28it/s]\n",
      "60198it [00:19, 3165.07it/s]\n",
      "49842it [00:40, 1230.98it/s]\n",
      "9959it [00:06, 1651.89it/s]\n",
      "4567it [00:02, 1691.91it/s]\n",
      "72538it [00:30, 2356.94it/s]\n",
      "4408it [00:02, 1904.69it/s]\n",
      "127253it [01:13, 1727.33it/s]\n",
      "3834it [00:02, 1515.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_instructions = []\n",
    "\n",
    "count, count1 = 0, 0\n",
    "for file in glob('/home/husein/ssd3/gov.my/ultrachat-*.jsonl'):\n",
    "    with open(file) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            \n",
    "#             if l[1]['content'] is None:\n",
    "#                 print(l)\n",
    "#                 continue\n",
    "            \n",
    "            if 'glaive_coder_raw_text' in file:\n",
    "                code_instruct = True\n",
    "            else:\n",
    "                code_instruct = False\n",
    "                \n",
    "            context = l[0]['content']\n",
    "            \n",
    "            if not code_instruct:\n",
    "                l = l[1:]\n",
    "                \n",
    "            inputs = []\n",
    "            for no, r in enumerate(l):\n",
    "                \n",
    "                if no < (len(l) - 1):\n",
    "                    if l[no + 1]['role'] == 'user':\n",
    "                        next_text = l[no + 1].get('content_ms') or l[no + 1].get('content') or ''\n",
    "                    else:\n",
    "                        next_text = l[no + 1].get('content_ms') or ''\n",
    "                else:\n",
    "                    next_text = ''\n",
    "                \n",
    "                if r['role'] == 'user':\n",
    "                    current_text = r.get('content_ms') or r.get('content') or ''\n",
    "                else:\n",
    "                    current_text = r.get('content_ms') or ''\n",
    "                    \n",
    "                if l[no - 1]['role'] == 'user':\n",
    "                    previous_text = l[no - 1].get('content_ms') or l[no - 1].get('content') or ''\n",
    "                else:\n",
    "                    previous_text = l[no - 1].get('content_ms') or ''\n",
    "                \n",
    "                # bad pairs\n",
    "                if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                    # print('a', l, current_text, next_text, '\\n')\n",
    "                    continue\n",
    "                if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                    continue\n",
    "                \n",
    "                # bad pairs\n",
    "                if not code_instruct and r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                    # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                    continue\n",
    "                if not code_instruct and r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                    # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                    continue\n",
    "                    \n",
    "                # remove alignments    \n",
    "                if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                    continue\n",
    "                if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                    continue\n",
    "\n",
    "                role = roles[r['role']]\n",
    "                \n",
    "                if no == 0 and not code_instruct and ('crossref-melayu' in file or random.random() > 0.7):\n",
    "                    s = f\"{role}: {context}\\n\\n{current_text}\"\n",
    "                    count += 1\n",
    "                else:\n",
    "                    s = f\"{role}: {current_text}\"\n",
    "                    \n",
    "                inputs.append(s)\n",
    "                count1 += 1\n",
    "\n",
    "            if len(inputs) % 2 != 0:\n",
    "                inputs = inputs[:-1]\n",
    "                \n",
    "            if not len(inputs):\n",
    "                continue\n",
    "            \n",
    "            if random.random() > 0.2:\n",
    "                continue\n",
    "            \n",
    "            index = random.randint(0, len(random_instructions) - 1)\n",
    "            choice = random.choice(random_instructions[index])\n",
    "            manusia = f\"<manusia>: {choice['input']}\"\n",
    "            bot = f\"<bot>: {choice['output']}\"\n",
    "            \n",
    "            if random.random() > 0.5:\n",
    "                inputs.extend([manusia, bot])\n",
    "            else:\n",
    "                inputs = [manusia, bot] + inputs\n",
    "\n",
    "            data = '\\n'.join(inputs).strip()\n",
    "            \n",
    "            if not len(data):\n",
    "                continue\n",
    "                \n",
    "            a = {\n",
    "                'prompt_input': None,\n",
    "                'input': data,\n",
    "                'output': None\n",
    "            }\n",
    "            data_instructions.append(a)\n",
    "        \n",
    "        \n",
    "len(data_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f26c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_all = data_instructions_mixtral + data_instructions + random_combine\n",
    "len(combine_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa583298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(row):\n",
    "    texts = ['<s>']\n",
    "\n",
    "    if 'function_call' in row:\n",
    "        t = row['function_call']\n",
    "        texts.append(f'\\n[FUNCTIONCALL]\\n{t}\\n')\n",
    "\n",
    "    if '<bot>:' in row['input'] and row['output'] is None:\n",
    "        inputs, outputs = [], []\n",
    "        splitted = row['input'].split('<bot>:')\n",
    "        for i in range(len(splitted) - 1):\n",
    "            if i == 0:\n",
    "                human = splitted[i].replace('<manusia>:', '')\n",
    "            else:\n",
    "                try:\n",
    "                    human = splitted[i].split('<manusia>:')[1]\n",
    "                except:\n",
    "                    continue\n",
    "            bot = splitted[i + 1].split('<manusia>:')[0]\n",
    "            inputs.append(human.strip())\n",
    "            outputs.append(bot.strip())\n",
    "    else:\n",
    "        inputs = [row['input']]\n",
    "        outputs = [row['output']]\n",
    "\n",
    "    for u, a in zip(inputs, outputs):\n",
    "        texts.append(f'[INST] {u.strip()} [/INST] {a.strip()}</s> ')\n",
    "\n",
    "    prompt = ''.join(texts)\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99d1e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 198338/198338 [00:02<00:00, 94931.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(combine_all))):\n",
    "    generate_and_tokenize_prompt(combine_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c435d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prepared-combine-multiple-chats.jsonl', 'w') as fopen:\n",
    "    for l in combine_all:\n",
    "        fopen.write(f'{json.dumps(l)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0446c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198338 prepared-combine-multiple-chats.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l prepared-combine-multiple-chats.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f95f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 husein husein 1.3G Dis  25 18:33 prepared-combine-multiple-chats.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh prepared-combine-multiple-chats.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169d219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
