{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882e7626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('openai/whisper-large-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a4ab87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42729"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob('output/*.json'), key = lambda x: int(x.split('-')[1].replace('.json', '')))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff8c3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328G\toutput-audio\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs output-audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f179c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display as ipd\n",
    "# ipd.Audio('output-audio/3-5833-0.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df73b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in tqdm(files):\n",
    "#     with open(f) as fopen:\n",
    "#         data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d996c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp\n",
    "import copy\n",
    "\n",
    "def loop(files):\n",
    "    files, _ = files\n",
    "    results = []\n",
    "    for f in tqdm(files):\n",
    "        try:\n",
    "            with open(f) as fopen:\n",
    "                data = json.load(fopen)\n",
    "        except:\n",
    "            continue\n",
    "        f_split = os.path.split(f)[-1].replace('.json', '')\n",
    "        for i in range(len(data)):\n",
    "            \n",
    "            audio_filename = os.path.join('output-audio', f'{f_split}-{i}.mp3')\n",
    "            if not os.path.exists(audio_filename):\n",
    "                continue\n",
    "            \n",
    "            data[i]['audio_filename'] = audio_filename\n",
    "            data[i]['filename'] = f\n",
    "            data[i]['i'] = i\n",
    "            a = np.array(tokenizer.encode(data[i]['predict_ms'], add_special_tokens = False))\n",
    "            a = a[a != 50257]\n",
    "            data[i]['predict_ms'] = tokenizer.decode(a.tolist() + [50257])\n",
    "            a = np.array(tokenizer.encode(data[i]['predict_en'], add_special_tokens = False))\n",
    "            a = a[a != 50257]\n",
    "            data[i]['predict_en'] = tokenizer.decode(a.tolist() + [50257])\n",
    "            \n",
    "            dense = CountVectorizer(ngram_range = (3,3)).fit_transform([data[i]['predict_ms']]).todense()\n",
    "            repeat_ms = (dense > 3).sum() > 1\n",
    "            data[i]['repeat_ms'] = repeat_ms\n",
    "            \n",
    "            \n",
    "            dense = CountVectorizer(ngram_range = (3,3)).fit_transform([data[i]['predict_en']]).todense()\n",
    "            repeat_en = (dense > 3).sum() > 1\n",
    "            data[i]['repeat_en'] = repeat_en\n",
    "            \n",
    "            results.append(data[i])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d53d9969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1424/1424 [03:38<00:00,  6.51it/s]\n",
      "100%|██████████| 1424/1424 [03:40<00:00,  6.45it/s]\n",
      "100%|██████████| 1424/1424 [03:40<00:00,  6.45it/s]\n",
      " 98%|█████████▊| 1401/1424 [03:40<00:03,  6.13it/s]\n",
      "100%|██████████| 1424/1424 [03:41<00:00,  6.44it/s]\n",
      "100%|██████████| 1424/1424 [03:41<00:00,  6.43it/s]\n",
      " 98%|█████████▊| 1395/1424 [03:41<00:05,  5.52it/s]\n",
      "100%|██████████| 1424/1424 [03:41<00:00,  6.43it/s]\n",
      "100%|██████████| 1424/1424 [03:41<00:00,  6.43it/s]\n",
      "100%|██████████| 1424/1424 [03:41<00:00,  6.42it/s]\n",
      "100%|██████████| 1424/1424 [03:42<00:00,  6.41it/s]\n",
      "100%|██████████| 1424/1424 [03:42<00:00,  6.40it/s]\n",
      "100%|██████████| 1424/1424 [03:42<00:00,  6.39it/s]\n",
      " 99%|█████████▉| 1410/1424 [03:42<00:02,  6.06it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.56it/s]7it/s]\n",
      "100%|██████████| 1424/1424 [03:43<00:00,  6.37it/s]\n",
      "100%|██████████| 1424/1424 [03:44<00:00,  6.36it/s]\n",
      "100%|██████████| 1424/1424 [03:44<00:00,  6.34it/s]\n",
      "100%|██████████| 1424/1424 [03:44<00:00,  6.33it/s]\n",
      "100%|██████████| 1424/1424 [03:44<00:00,  6.33it/s]\n",
      "100%|██████████| 1424/1424 [03:44<00:00,  6.33it/s]\n",
      "100%|██████████| 1424/1424 [03:45<00:00,  6.32it/s]\n",
      "100%|██████████| 1424/1424 [03:45<00:00,  6.32it/s]\n",
      "100%|██████████| 1424/1424 [03:45<00:00,  6.31it/s]\n",
      "100%|██████████| 1424/1424 [03:45<00:00,  6.30it/s]\n",
      "100%|█████████▉| 1423/1424 [03:45<00:00,  6.13it/s]\n",
      "100%|██████████| 1424/1424 [03:46<00:00,  6.30it/s]\n",
      "100%|██████████| 1424/1424 [03:46<00:00,  6.29it/s]\n",
      "100%|██████████| 1424/1424 [03:47<00:00,  6.27it/s]\n",
      "100%|██████████| 1424/1424 [03:47<00:00,  6.26it/s]\n",
      "100%|██████████| 1424/1424 [04:39<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "results = mp.multiprocessing(files, loop, cores = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ff1c25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2221856"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a74ac18c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict_ms': '<|startoftranscript|><|ms|><|transcribe|> anda tahu keuntungan boleh lebih tinggi daripada keuntungan kewangan rumah maka saya tidak akan mencari dalam akaun saya akan mencari ke dalam ethereum atau beberapa crypto punks bergantung pada faktor risiko anda kerana rumah kajang dihantar tidak mengganggu dsr saya sejauh ini jadi sekarang apa posisi saya untuk mendapatkan kewangan ketiga jadi mungkin setelah melihat sekeliling saya menemui seorang penjual yang dapat menutupi perhubungan tetapi bank hanya menerima 70% dari itu saya boleh membayar perbezaan dengan menggunakan wang ini kerana sekali lagi ia menyusahkan saya dan aset tetapi jika anda tidak selesa dengan mencari<|endoftext|>',\n",
       " 'predict_en': \"<|startoftranscript|><|en|><|transcribe|> you know the returns can be higher than the savings of the housing loan interest then i will not put in the account i'll put into ethereum or some crypto punks depending on your risk factor then because of the kajang house being let out it does not affect my dsr as much so now what's my position on getting the third loan so maybe after looking around i found one where the renter can somewhat cover the installment but the bank only approved 70 percent of it i'm okay to pay the difference using this cash because again it somewhat secures me an asset but if you are not<|endoftext|>\",\n",
       " 'score_ms': 11.25,\n",
       " 'score_en': 8.875,\n",
       " 'audio_filename': 'output-audio/1-0-0.mp3',\n",
       " 'filename': 'output/1-0.json',\n",
       " 'i': 0,\n",
       " 'repeat_ms': False,\n",
       " 'repeat_en': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d68a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(results[0]['repeat_ms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d103d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display as ipd\n",
    "# ipd.Audio('output-audio/3-165-0.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d6e575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2221856/2221856 [00:19<00:00, 115335.75it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('pseudolabel.jsonl', 'w') as fopen:\n",
    "    for r in tqdm(results):\n",
    "        r['repeat_ms'] = bool(r['repeat_ms'])\n",
    "        r['repeat_en'] = bool(r['repeat_en'])\n",
    "        fopen.write(f'{json.dumps(r)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "928ccb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 ubuntu ubuntu 2.0G Dec 29 08:11 pseudolabel.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh pseudolabel.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52a94460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41245288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126967242474411d9113e19f4d3ecbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pseudolabel.jsonl:   0%|          | 0.00/2.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/mesolitica/pseudolabel-malaysian-youtube-whisper-large-v3/blob/main/pseudolabel.jsonl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj='pseudolabel.jsonl',\n",
    "    path_in_repo='pseudolabel.jsonl',\n",
    "    repo_id='mesolitica/pseudolabel-malaysian-youtube-whisper-large-v3',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea16df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
