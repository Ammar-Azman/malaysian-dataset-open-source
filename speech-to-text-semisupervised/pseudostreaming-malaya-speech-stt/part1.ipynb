{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3011ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaya-speech-stt-train-whisper-large-v3/resolve/main/output-audio.7z.001\n",
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaya-speech-stt-train-whisper-large-v3/resolve/main/output-audio.7z.002\n",
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaya-speech-stt-train-whisper-large-v3/resolve/main/output-audio.7z.003\n",
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaya-speech-stt-train-whisper-large-v3/resolve/main/output-audio.7z.004\n",
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaya-speech-stt-train-whisper-large-v3/resolve/main/output-audio.7z.005\n",
    "# !wget https://huggingface.co/datasets/mesolitica/pseudolabel-malaya-speech-stt-train-whisper-large-v3/resolve/main/pseudolabel.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc28514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install git+https://github.com/mesolitica/malaya-speech@8fe9cfea37fc32ac63399d9ae5fff22af697f4be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69673182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95910790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/.local/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n",
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 1898\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 1921\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "from transformers.models.gpt2 import modeling_gpt2\n",
    "import malaya\n",
    "from malaya.text.normalization import cardinal\n",
    "import malaya_speech\n",
    "from malaya_speech.utils.subword import merge_sentencepiece_tokens\n",
    "import re\n",
    "import itertools\n",
    "import unicodedata\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = malaya.tokenizer.Tokenizer(hypen = False, parliament = False, time = False, time_pukul = False,\n",
    "                                      temperature = False, distance = False, volume = False, duration = False,\n",
    "                                      weight = False, date = False, money = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b642c7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pada lima belas ogos seribu sembilan ratus empat puluh pihak berikat menyerang perancis selatan serangan ini dipanggil operation dragoon'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_replace(t):\n",
    "    tokenized = tokenizer.tokenize(t)\n",
    "    for i in range(len(tokenized)):\n",
    "        c = cardinal(tokenized[i])\n",
    "        if c != tokenized[i]:\n",
    "            tokenized[i] = c\n",
    "    return ' '.join(tokenized)\n",
    "\n",
    "tokenize_and_replace('pada 15 ogos 1940 pihak berikat menyerang perancis selatan serangan ini dipanggil operation dragoon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db7e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = [\" \", \"a\", \"e\", \"n\", \"i\", \"t\", \"o\", \"u\", \"s\", \"k\", \"r\", \"l\", \"h\", \"d\", \"m\", \"g\", \"y\", \"b\", \"p\", \"w\", \"c\", \"f\", \"j\", \"v\", \"z\", \"0\", \"1\", \"x\", \"2\", \"q\", \"5\", \"3\", \"4\", \"6\", \"9\", \"8\", \"7\"]\n",
    "sr = 16000\n",
    "\n",
    "def preprocessing_text(string):\n",
    "    \n",
    "    string = tokenize_and_replace(string)\n",
    "    string = unicodedata.normalize('NFC', string.lower())\n",
    "    string = ''.join([c if c in vocabs else ' ' for c in string])\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = (\n",
    "        ''.join(''.join(s)[:2] for _, s in itertools.groupby(string))\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba30ef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1611536"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = []\n",
    "\n",
    "with open('pseudolabel.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        f = l['audio_filename']\n",
    "        if not os.path.exists(f):\n",
    "            continue\n",
    "        t = l['predict_ms'][41:-13].strip()\n",
    "        filtered.append((f, t))\n",
    "        \n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988bf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = malaya_speech.force_alignment.transducer.huggingface(model = 'mesolitica/conformer-medium-mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75906265",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d644c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir force-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████▏                                           | 394733/805768 [11:13:32<11:56:03,  9.57it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range((len(filtered) // 2) * 0, (len(filtered) // 2) * 1, 1)):\n",
    "    filename = os.path.join('force-alignment', f'{i}.json')\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        y, _ = malaya_speech.load(filtered[i][0])\n",
    "        p = preprocessing_text(filtered[i][1])\n",
    "        results = model.predict(y, p)\n",
    "        diag = np.diag(results['alignment']).tolist()\n",
    "\n",
    "        subwords_alignment = results['subwords_alignment']\n",
    "\n",
    "\n",
    "        for i in range(len(subwords_alignment)):\n",
    "            subwords_alignment[i]['start'] = float(subwords_alignment[i]['start'])\n",
    "            subwords_alignment[i]['end'] = float(subwords_alignment[i]['end'])\n",
    "            subwords_alignment[i]['score'] = float(subwords_alignment[i]['score'])\n",
    "\n",
    "        d = {\n",
    "            'diag': diag,\n",
    "            'p': p,\n",
    "            'subwords_alignment': subwords_alignment,\n",
    "        }\n",
    "\n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(d, fopen)\n",
    "    except:\n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(False, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
